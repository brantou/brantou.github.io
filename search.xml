<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Babel--有趣的事]]></title>
      <url>%2F2017%2F10%2F31%2Fliterate-devOps%2F</url>
      <content type="text"><![CDATA[1 数据格式化(:wrap) 1.1 json格式化 curl http://httpbin.org/get { "args": {}, "headers": { "Accept": "*/*", "Connection": "close", "Host": "httpbin.org", "User-Agent": "curl/7.47.0" }, "origin": "180.167.20.58", "url": "http://httpbin.org/get"} 1.2 其他格式化 ifconfig docker0 Link encap:Ethernet HWaddr 02:42:00:ea:60:b5 inet addr:172.17.0.1 Bcast:0.0.0.0 Mask:255.255.0.0 UP BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) enp0s5 Link encap:Ethernet HWaddr 00:1c:42:25:d8:fa inet addr:10.211.55.4 Bcast:10.211.55.255 Mask:255.255.255.0 inet6 addr: fe80::e826:f762:2298:e7c2/64 Scope:Link inet6 addr: fdb2:2c26:f4e4:0:5cd3:5c16:3a8c:7539/64 Scope:Global inet6 addr: fdb2:2c26:f4e4:0:ecd3:b41:a84b:4a7d/64 Scope:Global UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:253593 errors:0 dropped:0 overruns:0 frame:0 TX packets:157157 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:280764604 (280.7 MB) TX bytes:14245761 (14.2 MB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:18219 errors:0 dropped:0 overruns:0 frame:0 TX packets:18219 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:10225282 (10.2 MB) TX bytes:10225282 (10.2 MB) 2 变量设置在Header中 ping $host -c 2 $ PING google.com (192.168.83.230) 56(84) bytes of data. 64 bytes from 192.168.83.230: icmp_seq=1 ttl=128 time=9.60 ms 64 bytes from 192.168.83.230: icmp_seq=2 ttl=128 time=25.4 ms --- google.com ping statistics --- packet loss, time 1001ms rtt min/avg/max/mdev = 9.609/17.508/25.408/7.900 ms 覆盖变量 host ,和 session 置为空！ ping $host -c 2 PING baidu.com (111.13.101.208) 56(84) bytes of data. 64 bytes from 111.13.101.208: icmp_seq=1 ttl=128 time=35.5 ms 64 bytes from 111.13.101.208: icmp_seq=2 ttl=128 time=49.2 ms --- baidu.com ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 1002ms rtt min/avg/max/mdev = 35.517/42.361/49.206/6.847 ms 3 结果的预处理(:post) img_path=img_path.replace('[[file:..', '').replace(']]', '')print('&lt;img src="'+img_path+'" /&gt;') @startuml&#10;cli -&#38;gt; serv: auth req&#10;serv --&#38;gt; cli: auth res&#10;@enduml 4 noweb风格的引用(:noweb-ref) df \&#10;|sed '1d' \&#10;|awk '{print $5 &#34; &#34; $6}' | sort -n | tail -1 \&#10;|awk '{print $2}' #!/bin/sh&#10;df \&#10;|sed '1d' \&#10;|awk '{print $5 &#34; &#34; $6}' | sort -n | tail -1 \&#10;|awk '{print $2}' 4.1 the mount point of the fullest disk 4.1.1 query all mounted disks df \ 4.1.2 strip the header row |sed '1d' \ 4.1.3 sort by the percent full |awk '{print $5 &#34; &#34; $6}' | sort -n | tail -1 \ 4.1.4 extract the mount point |awk '{print $2}' Last Updated 2017-11-03 Fri 17:08.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.1.2)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[写Python的新方式]]></title>
      <url>%2F2017%2F08%2F30%2Fob-python-intro%2F</url>
      <content type="text"><![CDATA[Org mode is for keeping notes, maintaining TODO lists, planning projects, and authoring documents with a fast and effective plain-text system. Org-mode 类似于 Markdown , 但是远胜于 Markdown 。 曾有小伙伴说过， Org-mode 是 Markdown 的封神模式， 个人觉得这话一点不夸张， 相比较而言， Markdown 只是一套简洁的文档格式， 而 Org-mode 除了涵盖作为文档格式的简洁之外， 还可用于记笔记，维护 TODO 列表， 工程管理,以及可用于元编程。 对于元编程的支持请阅读我之前的译文， Babel: org-mode的元编程。 所谓的元编程，即是 Org-mode 搭建了一个多语言可以交互执行的环境， 在这个环境中，可选用各语言的特性，来分解执行一个大型任务。 The Babel Fish is small, yellow, and simultaneously translates from one spoken language to another. – The Hitchhiker&rsquo;s Guide to the Galaxy, Douglas Adams Org-mode 对于比较流行的语言都有很好的支持， 而且对于新语言，也可以很容易添加支持，本人就给两种语言添加过支持。 本文章主要讲述 Org-mode 对于 Python 源代码块的支持, Python 相当的流行, 所以在 Org-mode 中被很完美的支持。 Org-mode 中的 Python 源代码块可用于定义函数、过滤器和数据分析、创建图表以及生成可重现的研究论文。 1 配置 这里假设 Python 的开发环境已配置完毕，若是还没配置，请自行google。 Org-mode 已内置在新的 Emacs 中，但是默认情况下， 只有 emacs-lisp 可被执行。 要启用或禁用其他语言, 可通过 Emacs 自定义交互界面来配置 org-babel-load-languages 变量, 或者将代码添加到 init 文件中, 启用python的代码如下所示: (org-babel-do-load-languages 'org-babel-load-languages '((python . t))) 2 Org-mode对于Python源码块的支持 2.1 头参数 2.1.1 语言特定的头参数 :results {output, value}: 默认 value 模式, 即 functional mode, 像函数一样执行，然后返回计算结果。 :preamble: 前导代码，插入到最前面（不常用）。 默认为空。 :return: 要返回的值（仅用于result-type为 value 时，不在 session 模式下;不常用）。 默认值为空，在 Non-session 模式下，使用 return() 返回值。 :python: 执行Python代码的程序名称。 2.1.2 公共头参数 :seesion [name]: 默认非 session 模式。 :var data=data-table: Org-mode 的 table 可被当做列表传递给Python代码块。 :exports {code, results, both, none}: 完全支持 babel 的导出选项。 2.2 Sessions python完全支持 session 模式，包括命名 session 。 在 session 模式下，代码块都运行在同一个长时间运行的 python 的交互式解释器 session 中，就像你在交互式 python 键入的一样。 可以拥有多个 session ，而且它们是完全相互独立。 session 可用于定义函数，设置变量和在源块之间共享代码。 python中的 session 模式与 non-session 模式略有不同，因为在 session 模式下， 你正在与单个“交互式” python session 交互。 在 python 的交互模式中，空行是特殊的：它们表示缩进代码块的结束, 所以会写出一些稍微不同的 python 代码。 另外，在 non-session 模式下，python代码块将被包装在一个函数中， 所以要返回一个值（ :result value mode ），你必须使用一个return语句。 在 session 模式下， python 代码由解释器直接评估，而不是在一个函数的上下文中， 最后一个语句的值将被自动返回，因此不能使用 return 语句。 2.2.1 Session mode # blank lines not OK in indented blocks, and don't use return() # Source block is passed directly to interactive python; # value is value of _ at end. #+begin_src python :session def foo(x): if x>0: return x+1 else: return x-1 foo(1) #+end_src #+RESULTS: : 2 2.2.2 Non-session mode # blank lines OK in indented blocks, and use return() # Entire source block will get indented and used as the body of main() #+begin_src python def foo(x): if x>0: return x+1 else: return x-1 return foo(5) #+end_src #+RESULTS: : 6 最后，如果你使用 matplotlib 的图形功能，同时使用 seesion 模式， 必须显式设置后端, 例如 PDF , PNG 或其他文件导出后端。 见下面示例: #+begin_src python :session :results file import matplotlib matplotlib.use('Agg') import matplotlib.pyplot as plt fig=plt.figure(figsize=(3,2)) plt.plot([1,3,2]) fig.tight_layout() plt.savefig('images/myfig.pdf') 'images/myfig.pdf' # return this to org-mode #+end_src #+RESULTS: [[file:images/myfig.pdf]] 2.3 返回类型 value：=value= 结果是代码块中求值的最后一个表达式的值。 session 模式下使用的python解释器特殊变量“_” 来引用最后一个表达式的值。 output：=output= 结果来自 python 代码打印到 stdout 上任意信息。 3 使用示例 Hello World! #+begin_src python :results output print "Hello, world!" #+end_src #+RESULTS: : Hello, world! 参数 #+NAME: square #+BEGIN_SRC python :var num=5 def square(x): return x*x return square(num) #+END_SRC #+RESULTS: square : 25 #+CALL: square(num=10) #+RESULTS: : 100 文学编程 #+NAME: square #+BEGIN_SRC python def square(x): return x*x #+END_SRC #+NAME: calc-square #+BEGIN_SRC python :var num=5 :noweb strip-export :results output print(square(num)) #+END_SRC #+RESULTS: calc-square : 25 #+CALL: calc-square(num=7) #+RESULTS: : 49 内联调用(Inline calling): 2 加 2 等于 src_python{return(2+2)} 当导出 HTML 或者 LaTeX/PDF 时，如下所示： 2 加 2 等于 4 使用Org-mode的table作为参数 #+tblname: data_table | a | 1 | | b | 2 | | c | 3 | #+begin_src python :var val=1 :var data=data_table # Return row specified by val. # In non-session mode, use return to return results. return(data[val]) #+end_src #+RESULTS: | b | 2 | 绘图 #+begin_src python :results file import matplotlib, numpy matplotlib.use('Agg') import matplotlib.pyplot as plt fig=plt.figure(figsize=(4,2)) x=numpy.linspace(-15,15) plt.plot(numpy.sin(x)/x) fig.tight_layout() plt.savefig('../images/python-matplot-fig.png') return '../images/python-matplot-fig.png' #+end_src #+RESULTS: [[file:../images/python-matplot-fig.png]] 词云 #+BEGIN_SRC python :preamble "# -*- coding: utf-8 -*-" :results value file import jieba.analyse from wordcloud import WordCloud, ImageColorGenerator import numpy as np from PIL import Image import random font_path = '../resource/tyzkaishu.ttf' width = 640 height = 480 text = open('../resource/xiyouji.txt').read() words = jieba.analyse.extract_tags(text, topK=200, withWeight=True) word_freqs = {} for word in words: word_freqs[word[0]] = word[1] mask = np.array(Image.open('../resource/stormtrooper_mask.png')) wordcloud = WordCloud( font_path=font_path, width=width, height=height, mask=mask).generate_from_frequencies(word_freqs) wordcloud.to_file('../images/xiyouji-mask.png') return '../images/xiyouji-mask.png' #+END_SRC #+RESULTS: [[file:../images/xiyouji-mask.png]] 4 前方预警 当把 utf-8 的字符串传给 Python , 需要格外小心。 4.1 传递utf-8字符串到Python #+NAME: unicode_str #+BEGIN_EXAMPLE “this string is not ascii!” #+END_EXAMPLE #+NAME: error-in-passing-var #+BEGIN_SRC python :var data=unicode_str return data #+END_SRC #+RESULTS: error-in-passing-var 上面代码不会生成任何输出, 并在 *Org-Babel Error Output* 的缓冲区中打印以下消息: File &ldquo;&rdquo;, line 3 SyntaxError: Non-ASCII character &rsquo;\xe2&rsquo; in file on line 3, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details 4.2 传递utf-8字符串到Python的变通方法 一个变通方法是使用 :preamble ,如下所示: #+NAME: ok-in-passing-var #+BEGIN_SRC python :preamble "# -*- coding: utf-8 -*-" :var data=unicode_str return data #+END_SRC #+RESULTS: ok-in-passing-var : “this string is not ascii!” 5 参考文档 Python Source Code Blocks in Org Mode Babel: org-mode的元编程 在Org-mode中执行Go代码 Working with source code Babel: active code in Org-mode Last Updated 2017-08-31 Thu 22:25.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.1.2)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[玩转词云]]></title>
      <url>%2F2017%2F08%2F25%2Fpython-jieba-wordcloud%2F</url>
      <content type="text"><![CDATA[1 jieba中文分词 1.1 分词 import jiebaseg_list = jieba.cut(srcWd, cut_all=True)print(u'Full mode:' + u'/ '.join(seg_list))seg_list = jieba.cut(srcWd, cut_all=False)print(u'Default mode:' + u'/ '.join(seg_list))seg_list = jieba.cut_for_search(srcWd)print(u', '.join(seg_list)) Full mode:做/ 最好/ 的/ Python/ 中文/ 分词/ 词组/ 组件 Default mode:做/ 最好/ 的/ Python/ 中文/ 分词/ 组件 做, 最好, 的, Python, 中文, 分词, 组件 Full mode:我/ 目前/ 在/ 学习/ Golang/ 和/ Python/ Default mode:我/ 目前/ 在/ 学习/ Golang/ 和/ Python/ 。 我, 目前, 在, 学习, Golang, 和, Python, 。 1.2 自定义词典 招聘信息收集了很多，但是关键字提取却不是很理想，我查看了jiaba的词典里，基本没有对英文专有名词的支持， 这可苦煞了我，但是jieba支持自定义词典，我来生成英文的专有名词的词典好了。一行一行的加，难为我这个懒人了， 但总有好心人，已经整理好了，试想这个名词是不是招聘网站已经整理好了，而且分门别类的，只需要把它们取回来就好了。 def get_html(url): request = urllib2.Request(url) request.add_header( 'User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36' ) html = urllib2.urlopen(request) return html.read()def get_soup(url): soup = BeautifulSoup(get_html(url), 'lxml') return soup def fetch_lagou(): words = [] url = 'https://www.lagou.com/' soup = get_soup(url) category_list = soup.find_all('div', attrs={'class': 'menu_sub dn'}) for category in category_list: dls = category.find_all('dl') for dl in dls: names = dl.dd.find_all('a') for name in names: words.append(name.text) return wordsdef fetch_zhipin(): words = [] url = 'http://www.zhipin.com/' soup = get_soup(url) job_menu = soup.find('div', attrs={'class': 'job-menu'}) dls = job_menu.find_all('dl') for dl in dls: divs = dl.find_all('div', attrs={'class': 'text'}) for div in divs: names = div.find_all('a') for name in names: words.append(name.text) return words 看来我思维受限了，招聘网站整理的信息都是高频信息，但是广度肯定是不够的，那怎么办呢。 这个时候 stackoverflow 闪现在我的脑海中，没有那个网站里有关技术的广度，能和它匹敌了。 def fetch_stackoverflow(): words = [] for pageNo in range(1, 20): url = 'https://stackoverflow.com/tags?page=%d&amp;amp;tab=popular' % (pageNo) soup = get_soup(url) tags_list = soup.find('div', attrs={'id': 'tags_list'}) trs = tags_list.table.find_all('tr') for tr in trs: tds = tr.find_all('td') for td in tds: words.append(td.a.text) return words 1.3 调整词典 import jiebaimport jieba.analyseprint(', '.join( jieba.analyse.extract_tags(srcWd, allowPOS=('n', 'nz', 'eng', 'vn'))))jieba.load_userdict('../resource/userdict.txt')print(', '.join( jieba.analyse.extract_tags(srcWd, allowPOS=('n', 'nz', 'eng', 'vn')))) 理解能力, 经验, 数据挖掘, 敏锐度, 平台, odps, hadoop, 数据仓库, hive, 建模, 业务, 海量, 能力, 数据, 协作, 优先, 团队, 模型, 计算机, 学科 理解能力, 经验, 数据挖掘, 敏锐度, 平台, odps, hadoop, 数据仓库, hive, 建模, 业务, 海量, 能力, 数据, 协作, 优先, 团队, 模型, 计算机, 学科 1.4 关键词提取 import jieba.analyseprint(', '.join(jieba.analyse.extract_tags(srcWd, allowPOS=())))print(', '.join( jieba.analyse.extract_tags(srcWd, allowPOS=('n', 'nt', 'nz', 'eng', 'vn' ))))wordlst = jieba.analyse.extract_tags( srcWd, withWeight=True, allowPOS=('n', 'nt', 'nz', 'eng', 'vn'))for word in wordlst: print(word[0] + ": " + str(word[1])) import jieba.analyseprint(', '.join(jieba.analyse.textrank(srcWd)))print(', '.join( jieba.analyse.textrank(srcWd, allowPOS=('n', 'nz', 'eng', 'vn')))) 1.5 词性标注 import jiebaimport jieba.posseg as psegjieba.load_userdict('../resource/userdict.txt')words = pseg.cut(srcWd)for word, flag in words: print('%s %s' % (word, flag)) 2 wordcloud词云 2.1 简单词云&#x2013;美国宪法的词云 """Minimal Example===============Generating a square wordcloud from the US constitution using default arguments."""from wordcloud import WordCloud# Read the whole text.text = open('../resource/constitution.txt').read()# Generate a word cloud imagewordcloud = WordCloud(width=640, height=480).generate(text)wordcloud.to_file('../images/constitution-n.png')wordcloud = WordCloud(width=640, height=480, max_font_size=80).generate(text)wordcloud.to_file('../images/constitution-s.png') 2.2 Colored by Group from wordcloud import (WordCloud, get_single_color_func)import matplotlib.pyplot as pltclass SimpleGroupedColorFunc(object): """Create a color function object which assigns EXACT colors to certain words based on the color to words mapping Parameters ---------- color_to_words : dict(str -&amp;gt; list(str)) A dictionary that maps a color to the list of words. default_color : str Color that will be assigned to a word that's not a member of any value from color_to_words. """ def __init__(self, color_to_words, default_color): self.word_to_color = { word: color for (color, words) in color_to_words.items() for word in words } self.default_color = default_color def __call__(self, word, **kwargs): return self.word_to_color.get(word, self.default_color)class GroupedColorFunc(object): """Create a color function object which assigns DIFFERENT SHADES of specified colors to certain words based on the color to words mapping. Uses wordcloud.get_single_color_func Parameters ---------- color_to_words : dict(str -&amp;gt; list(str)) A dictionary that maps a color to the list of words. default_color : str Color that will be assigned to a word that's not a member of any value from color_to_words. """ def __init__(self, color_to_words, default_color): self.color_func_to_words = [(get_single_color_func(color), set(words)) for (color, words) in color_to_words.items()] self.default_color_func = get_single_color_func(default_color) def get_color_func(self, word): """Returns a single_color_func associated with the word""" try: color_func = next( color_func for (color_func, words) in self.color_func_to_words if word in words) except StopIteration: color_func = self.default_color_func return color_func def __call__(self, word, **kwargs): return self.get_color_func(word)(word, **kwargs)text = """The Zen of Python, by Tim PetersBeautiful is better than ugly.Explicit is better than implicit.Simple is better than complex.Complex is better than complicated.Flat is better than nested.Sparse is better than dense.Readability counts.Special cases aren't special enough to break the rules.Although practicality beats purity.Errors should never pass silently.Unless explicitly silenced.In the face of ambiguity, refuse the temptation to guess.There should be one-- and preferably only one --obvious way to do it.Although that way may not be obvious at first unless you're Dutch.Now is better than never.Although never is often better than *right* now.If the implementation is hard to explain, it's a bad idea.If the implementation is easy to explain, it may be a good idea.Namespaces are one honking great idea -- let's do more of those!"""# Since the text is small collocations are turned off and text is lower-casedwc = WordCloud(collocations=False).generate(text.lower())color_to_words = { # words below will be colored with a green single color function '#00ff00': [ 'beautiful', 'explicit', 'simple', 'sparse', 'readability', 'rules', 'practicality', 'explicitly', 'one', 'now', 'easy', 'obvious', 'better' ], # will be colored with a red single color function 'red': [ 'ugly', 'implicit', 'complex', 'complicated', 'nested', 'dense', 'special', 'errors', 'silently', 'ambiguity', 'guess', 'hard' ]}# Words that are not in any of the color_to_words values# will be colored with a grey single color functiondefault_color = 'grey'# Create a color function with single tone# grouped_color_func = SimpleGroupedColorFunc(color_to_words, default_color)# Create a color function with multiple tonesgrouped_color_func = GroupedColorFunc(color_to_words, default_color)# Apply our color functionwc.recolor(color_func=grouped_color_func)wc.to_file('../images/grouped-color.png') 2.3 西游记的词云 import jieba.analysefrom wordcloud import WordCloud, ImageColorGeneratorimport numpy as npfrom PIL import Imageimport randomdef grey_color_func(word, font_size, position, orientation, random_state=None, **kwargs): return "hsl(0, 0%%, %d%%)" % random.randint(60, 100)font_path = '../resource/tyzkaishu.ttf'width = 640height = 480text = open('../resource/xiyouji.txt').read()words = jieba.analyse.extract_tags(text, topK=200, withWeight=True)word_freqs = {}for word in words: word_freqs[word[0]] = word[1]wordcloud = WordCloud( font_path=font_path, width=width, height=height).generate_from_frequencies(word_freqs)wordcloud.to_file('../images/xiyouji.png')mask = np.array(Image.open('../resource/stormtrooper_mask.png'))wordcloud = WordCloud( font_path=font_path, width=width, height=height, mask=mask).generate_from_frequencies(word_freqs)wordcloud.to_file('../images/xiyouji-mask.png')# recolor wordcloudwordcloud.recolor(color_func=grey_color_func, random_state=3)wordcloud.to_file('../images/xiyouji-custom.png')alice_coloring = np.array(Image.open('../resource/alice_color.png'))wordcloud = WordCloud( font_path=font_path, width=width, height=height, background_color="white", mask=alice_coloring, max_font_size=80, random_state=42).generate_from_frequencies(word_freqs)# create coloring from imageimage_colors = ImageColorGenerator(alice_coloring)# recolor wordcloudwordcloud.recolor(color_func=image_colors)wordcloud.to_file('../images/xiyouji-color.png') 2.4 阿里招聘的词云 招聘信息是我使用爬虫趴下来的的，这里只做数据的分析。 # -*- coding: utf-8 -*-import jiebaimport jieba.analysefrom wordcloud import WordCloudimport numpy as npfrom PIL import Imagefrom pymongo import MongoClientfont_path = '../resource/zhengkaishu.ttf'width = 640height = 480client = MongoClient('mongodb://localhost:27017/')jobs = client.jobs.alibabatext = ''for job in jobs.find({u'firstCategory': u'&amp;#25216;&amp;#26415;&amp;#31867;'}): if job.get('requirement'): text += job.get('requirement').replace('&amp;lt;br/&amp;gt;', ' ') + '\n'jieba.load_userdict('../resource/userdict.txt')words = jieba.analyse.extract_tags(text, topK=2000, withWeight=True)word_freqs = {}for word in words: _word = word[0].lower().capitalize() if _word not in word_freqs: word_freqs[_word] = word[1] else: word_freqs[_word] += word[1]mask = np.array(Image.open('../resource/stormtrooper_mask.png'))wordcloud = WordCloud( font_path=font_path, width=width, height=height, mask=mask).generate_from_frequencies(word_freqs)wordcloud.to_file('../images/alibaba-mask.png') Last Updated 2017-08-31 Thu 18:17.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[scrapy模拟登陆知乎]]></title>
      <url>%2F2017%2F08%2F22%2Fscrapy-crawl-zhihu%2F</url>
      <content type="text"><![CDATA[折腾了将近两天，中间数次想要放弃，还好硬着头皮搞下去了，在此分享出来，希望有同等需求的各位能少走一些弯路。 源码放在了github上， 欢迎前往查看。 若是帮你解决了问题，或者给了你启发，不要吝啬给我加一星。 1 工具准备 在开始之前，请确保 scrpay 正确安装，手头有一款简洁而强大的浏览器， 若是你有使用 postman 那就更好了。 scrapy genspider zhihu 使用以上命令生成知乎爬虫,代码如下: # -*- coding: utf-8 -*-import scrapyclass ZhihuSpider(scrapy.Spider): name = 'zhihu' allowed_domains = ['www.zhihu.com'] start_urls = ['http://www.zhihu.com/'] def parse(self, response): pass 有一点切记，不要忘了启用 Cookies, 切记切记 ： # Disable cookies (enabled by default)COOKIES_ENABLED = True 2 模拟登陆 过程如下： 进入登录页，获取 Header 和 Cookie 信息， 完善的 Header 信息能尽量伪装爬虫， 有效 Cookie 信息能迷惑知乎服务端，使其认为当前登录非首次登录，若无有效 Cookie 会遭遇验证码。 在抓取数据之前，请在浏览器中登录过知乎，这样才使得 Cookie 是有效的。 Header 和 Cookie 整理如下: headers = { 'Host': 'www.zhihu.com', 'Connection': 'keep-alive', 'Origin': 'https://www.zhihu.com', 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36', 'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8', 'Accept': '*/*', 'X-Requested-With': 'XMLHttpRequest', 'DNT': 1, 'Referer': 'https://www.zhihu.com/', 'Accept-Encoding': 'gzip, deflate, br', 'Accept-Language': 'zh-CN,zh;q=0.8,en;q=0.6',}cookies = { 'd_c0': '"AHCAtu1iqAmPTped76X1ZdN0X_qAwhjdLUU=|1458699045"', '__utma': '51854390.1407411155.1458699046.1458699046.1458699046.1', '__utmv': '51854390.000--|3=entry_date=20160322=1', '_zap': '850897bb-cba4-4d0b-8653-fd65e7578ac2', 'q_c1': 'b7918ff9a5514d2981c30050c8c732e1|1502937247000|1491446589000', 'aliyungf_tc': 'AQAAAHVgviiNyQsAOhSntJ5J/coWYtad', '_xsrf': 'b12fdca8-cb35-407a-bc4c-6b05feff37cb', 'l_cap_id': '"MDk0MzRjYjM4NjAwNDU0MzhlYWNlODQ3MGQzZWM0YWU=|1503382513|9af99534aa22d5db92c7f58b45f3f3c772675fed"', 'r_cap_id': '"M2RlNDZjN2RkNTBmNGFmNDk2ZjY4NjIzY2FmNTE4NDg=|1503382513|13370a99ee367273b71d877de17f05b2986ce0ef"', 'cap_id': '"NmZjODUxZjQ0NzgxNGEzNmJiOTJhOTlkMTVjNWIxMDQ=|1503382513|dba2e9c6af7f950547474f827ef440d7a2950163"',} 在浏览器中，模拟登陆，抓取登陆请求信息。 从图中可以看到 _xsrf 参数, 这个参数与登陆验证信息无关，但很明显是由登陆页面携带的信息。 Google 了下 xsrf 的含义， 是用于防范 跨站请求伪造 。 整理以上，代码如下： loginUrl = 'https://www.zhihu.com/#signin'siginUrl = 'https://www.zhihu.com/login/email'def start_requests(self): return [ scrapy.http.FormRequest( self.loginUrl, headers=self.headers, cookies=self.cookies, meta={'cookiejar': 1}, callback=self.post_login) ]def post_login(self, response): xsrf = response.css( 'div.view-signin &amp;gt; form &amp;gt; input[name=_xsrf]::attr(value)' ).extract_first() self.headers['X-Xsrftoken'] = xsrf return [ scrapy.http.FormRequest( self.siginUrl, method='POST', headers=self.headers, meta={'cookiejar': response.meta['cookiejar']}, formdata={ '_xsrf': xsrf, 'captcha_type': 'cn', 'email': 'xxxxxx@163.com', 'password': 'xxxxxx', }, callback=self.after_login) ] 3 设置Bearer Token 经过上述步骤登陆成功了，有点小激动，有没有！ 但苦难到此还远没有结束，这个时候尝试抓取最近热门话题，直接返回 code:401 ,未授权的访问。 授权信息未设置，导致了此类错误，莫非遗漏了什么，看来只能在浏览器中追踪请求参数来侦测问题。 在浏览器的请求中，包含了Bearer Token, 而我在scrapy中模拟的请求中未包含此信息，所以我被服务器认定为未授权的。 通过观察发现 Bearer Token 的关键部分，就是 Cookies 中的 z_c0 对应的信息。 z_c0 包含的信息，是在登陆完成时种下的，所以从登陆完成返回的登陆信息里，获取要设置的 Cookies 信息， 然后拼接出 Bearer Token,最后设置到 Header 中。 代码整理如下: def after_login(self, response): jdict = json.loads(response.body) print('after_login', jdict) if jdict['r'] == 0: z_c0 = response.headers.getlist('Set-Cookie')[2].split(';')[0].split( '=')[1] self.headers['authorization'] = 'Bearer ' + z_c0 return scrapy.http.FormRequest( url=self.feedUrl, method='GET', meta={'cookiejar': response.meta['cookiejar']}, headers=self.headers, formdata={ 'action_feed': 'True', 'limit': '10', 'action': 'down', 'after_id': str(self.curFeedId), 'desktop': 'true' }, callback=self.parse) else: print(jdict['error']) 4 获取数据 上述步骤后，数据获取就水到渠成了，为了检测成功与否， 把返回信息写到文件中,而且只获取前五十个,代码如下： feedUrl = 'https://www.zhihu.com/api/v3/feed/topstory'nextFeedUrl = ''curFeedId = 0def parse(self, response): with open('zhihu.json', 'a') as fd: fd.write(response.body) jdict = json.loads(response.body) jdatas = jdict['data'] for entry in jdatas: entry['pid'] = entry['id'] yield entry jpaging = jdict['paging'] self.curFeedId += len(jdatas) if jpaging['is_end'] == False and self.curFeedId &amp;lt; 50: self.nextFeedUrl = jpaging['next'] yield self.next_request(response)def next_request(self, response): return scrapy.http.FormRequest( url=self.nextFeedUrl, method='GET', meta={'cookiejar': response.meta['cookiejar']}, headers=self.headers, callback=self.parse) 获取的数据，采用json格式， 如下所示: 5 写在最后 知乎的数据，只有登录完成之后，才可有效的获取，所以模拟登陆是无法忽略不管的。 所谓的模拟登陆，只是在scrapy中尽量的模拟在浏览器中的交互过程，使服务端无感抓包过程。 请求中附加有效的 Cookies 和 Headers 头信息，可有效的迷惑服务端， 同时在交互的过程中，获取后续请求必要信息和认证信息，使得整个流程能不断先前。 若是你遇到什么问题，尽量提出来，欢迎一起来讨论解决。 源码放在了github上， 欢迎前往查看。 若是帮你解决了问题，或者给了你启发，不要吝啬给我加一星。 Last Updated 2017-08-23 Wed 15:21.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Leetcode-tree]]></title>
      <url>%2F2017%2F07%2F16%2Fleetcode-tree%2F</url>
      <content type="text"><![CDATA[LeetCode 编程训练的积累，目前在努力做题中，日后整理！ 1 binary tree traversal 1.1 level order type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func levelOrder(root *TreeNode) [][]int { if root == nil { return [][]int{} } lo_arr := [][]int{ []int{root.Val}, } llo_arr := levelOrder(root.Left) rlo_arr := levelOrder(root.Right) if len(llo_arr) &amp;gt; 0 || len(rlo_arr) &amp;gt; 0 { var index int for { if index &amp;lt; len(llo_arr) &amp;amp;&amp;amp; index &amp;lt; len(rlo_arr) { lo_arr = append(lo_arr, append(llo_arr[index], rlo_arr[index]...)) } else { break } index += 1 } if len(llo_arr) &amp;gt; index { lo_arr = append(lo_arr, llo_arr[index:]...) } if len(rlo_arr) &amp;gt; index { lo_arr = append(lo_arr, rlo_arr[index:]...) } } return lo_arr} func main() { root := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{ Val: 2, }, Right: &amp;amp;TreeNode{ Val: 3, }, } fmt.Println(levelOrder(root)) root.Left.Left = &amp;amp;TreeNode{Val:4} root.Right.Right = &amp;amp;TreeNode{Val:5} fmt.Println(levelOrder(root))} 1.2 level order bottom &amp;lt;&amp;lt;bt-level-order&amp;gt;&amp;gt;func levelOrderBottom(root *TreeNode) [][]int { lo_arr := levelOrder(root) lob_arr := make([][]int, 0) for index, _ := range lo_arr { lob_arr = append([][]int{lo_arr[index]}, lob_arr...) } return lob_arr} func main() { root := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{ Val: 2, }, Right: &amp;amp;TreeNode{ Val: 3, }, } fmt.Println(levelOrderBottom(root)) root.Left.Left = &amp;amp;TreeNode{Val:4} root.Right.Right = &amp;amp;TreeNode{Val:5} fmt.Println(levelOrderBottom(root))} 1.3 zigzag level order &amp;lt;&amp;lt;bt-level-order&amp;gt;&amp;gt; func zigzagLevelOrder(root *TreeNode) [][]int { lo_arr := levelOrder(root) zlo_arr := make([][]int, 0) for index, _ := range lo_arr { lo := lo_arr[index] if index % 2 == 1 { zlo := make([]int, 0) for index, _ := range lo { zlo = append([]int{lo[index]}, zlo...) } zlo_arr = append(zlo_arr, zlo) } else { zlo_arr = append(zlo_arr, lo) } } return zlo_arr} func main() { root := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{ Val: 2, }, Right: &amp;amp;TreeNode{ Val: 3, }, } fmt.Println(zigzagLevelOrder(root)) root.Left.Left = &amp;amp;TreeNode{Val:4} root.Right.Right = &amp;amp;TreeNode{Val:5} fmt.Println(zigzagLevelOrder(root))} 1.4 inOrder type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func inorderTraversal(root *TreeNode) []int { if root == nil { return []int{} } return append( append(inorderTraversal(root.Left), root.Val), inorderTraversal(root.Right)...)} func main() { root := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{ Val: 2, }, Right: &amp;amp;TreeNode{ Val: 3, }, } fmt.Println(inorderTraversal(root)) root.Left.Left = &amp;amp;TreeNode{Val:4} root.Right.Right = &amp;amp;TreeNode{Val:5} fmt.Println(inorderTraversal(root))} 1.5 preOrder type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func preorderTraversal(root *TreeNode) []int { if root == nil { return []int{} } return append( append([]int{root.Val}, preorderTraversal(root.Left)...), preorderTraversal(root.Right)...)} func main() { root := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{ Val: 2, }, Right: &amp;amp;TreeNode{ Val: 3, }, } fmt.Println(preorderTraversal(root)) root.Left.Left = &amp;amp;TreeNode{Val:4} root.Right.Right = &amp;amp;TreeNode{Val:5} fmt.Println(preorderTraversal(root))} 1.6 postOrder type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func postorderTraversal(root *TreeNode) []int { if root == nil { return []int{} } return append( append(postorderTraversal(root.Left), postorderTraversal(root.Right)...), root.Val)} func main() { root := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{ Val: 2, }, Right: &amp;amp;TreeNode{ Val: 3, }, } fmt.Println(postorderTraversal(root)) root.Left.Left = &amp;amp;TreeNode{Val:4} root.Right.Right = &amp;amp;TreeNode{Val:5} fmt.Println(postorderTraversal(root))} 2 binary tree type TreeNode struct { Val int Left *TreeNode Right *TreeNode} struct TreeLinkNode { int val; TreeLinkNode *left, *right, *next; TreeLinkNode(int x) : val(x), left(NULL), right(NULL), next(NULL) {}}; struct TreeNode { int val; TreeNode *left; TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) {}}; 2.1 max depth type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func max(a, b int) int { if a &amp;gt; b { return a } else { return b }}func maxDepth(root *TreeNode) int { if root == nil { return 0 } return 1 + max(maxDepth(root.Left), maxDepth(root.Right))} func main() { root := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{ Val: 2, }, Right: &amp;amp;TreeNode{ Val: 3, }, } fmt.Println(maxDepth(root)) root.Left.Left = &amp;amp;TreeNode{Val:4} root.Right.Right = &amp;amp;TreeNode{Val:5} fmt.Println(maxDepth(root))} 2.2 paths type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func binaryTreePaths(root *TreeNode) []string { if root == nil { return []string{} } str := fmt.Sprintf("%d", root.Val) if root.Left == nil &amp;amp;&amp;amp; root.Right == nil { return []string{str} } paths := append( binaryTreePaths(root.Left), binaryTreePaths(root.Right)..., ) for index, path := range paths { paths[index] = str + "-&amp;gt;" + path } return paths} func main() { root := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{ Val: 2, }, Right: &amp;amp;TreeNode{ Val: 3, }, } fmt.Println(binaryTreePaths(root)) root.Left.Left = &amp;amp;TreeNode{Val:4} root.Right.Right = &amp;amp;TreeNode{Val:5} fmt.Println(binaryTreePaths(root))} 2.3 isBalanced &amp;lt;&amp;lt;bt-max-depth&amp;gt;&amp;gt;func isBalanced(root *TreeNode) bool { if root == nil { return true } ldepth := maxDepth(root.Left) rdepth := maxDepth(root.Right) ddepth := ldepth - rdepth if ddepth &amp;gt; 1 || ddepth &amp;lt; -1 { return false } return isBalanced(root.Left) &amp;amp;&amp;amp; isBalanced(root.Right)} func main() { root := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{ Val: 2, }, } fmt.Println(isBalanced(root)) root.Left.Left = &amp;amp;TreeNode{Val:4} fmt.Println(isBalanced(root))} 2.4 invert type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func invertTree(root *TreeNode) *TreeNode { if root == nil { return nil } root.Left, root.Right = invertTree(root.Right), invertTree(root.Left) return root} func main() { root := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{ Val: 2, }, Right: &amp;amp;TreeNode{ Val: 3, }, } fmt.Println(invertTree(root)) root.Left.Left = &amp;amp;TreeNode{Val:4} root.Right.Right = &amp;amp;TreeNode{Val:5} fmt.Println(invertTree(root))} 2.5 tilt type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func sumTree(root *TreeNode) int { if root == nil { return 0 } return root.Val + sumTree(root.Left) + sumTree(root.Right)}func abs(num int) int { if num &amp;lt; 0 { return -num } else { return num }}func findTilt(root *TreeNode) int { if root == nil { return 0 } return abs(sumTree(root.Left)-sumTree(root.Right)) + findTilt(root.Left) + findTilt(root.Right)} func main() { root := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{ Val: 2, }, Right: &amp;amp;TreeNode{ Val: 3, }, } fmt.Println(findTilt(root)) root.Left.Left = &amp;amp;TreeNode{Val:4} root.Right.Right = &amp;amp;TreeNode{Val:5} fmt.Println(findTilt(root))} 2.6 construct string func tree2str(t *TreeNode) string { if t == nil { return "" } str := fmt.Sprintf("%d", t.Val) if t.Left == nil &amp;amp;&amp;amp; t.Right == nil { return str } if t.Left != nil { str += fmt.Sprintf("(%s)", tree2str(t.Left)) } else { str += "()" } if t.Right != nil { str += fmt.Sprintf("(%s)", tree2str(t.Right)) } return str} 2.7 symmetric type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func isSymmetric(root *TreeNode) bool { if root == nil { return true } return isMirror(root.Left, root.Right)}func isMirror(lr *TreeNode, rr *TreeNode) bool { if lr == nil &amp;amp;&amp;amp; rr == nil { return true } if lr == nil || rr == nil { return false } if lr.Val != rr.Val { return false } return isMirror(lr.Left, rr.Right) &amp;amp;&amp;amp; isMirror(lr.Right, rr.Left)} func main() { root := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{ Val: 2, }, Right: &amp;amp;TreeNode{ Val: 2, }, } fmt.Println(isSymmetric(root)) root.Left.Left = &amp;amp;TreeNode{Val:4} root.Right.Right = &amp;amp;TreeNode{Val:5} fmt.Println(isSymmetric(root))} 2.8 subtree type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func isSubtree(s *TreeNode, t *TreeNode) bool { if t == nil { return true } if s == nil { return false } if s.Val == t.Val { return isSame(s, t) || isSubtree(s.Left, t) || isSubtree(s.Right, t) } else { return isSubtree(s.Left, t) || isSubtree(s.Right, t) }}func isSame(s *TreeNode, t *TreeNode) bool { if s == nil &amp;amp;&amp;amp; t == nil { return true } if s == nil || t == nil { return false } if s.Val != t.Val { return false } return isSame(s.Left, t.Left) &amp;amp;&amp;amp; isSame(s.Right, t.Right)} func main() { s := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{ Val: 4, Left: &amp;amp;TreeNode{ Val: 1, }, Right: &amp;amp;TreeNode{ Val: 2, }, }, Right: &amp;amp;TreeNode{ Val: 5, }, } t := &amp;amp;TreeNode{ Val: 4, Left: &amp;amp;TreeNode{ Val: 1, }, Right: &amp;amp;TreeNode{ Val: 2, }, } fmt.Println(isSubtree(s, t)) s.Left.Right = &amp;amp;TreeNode{ Val: 0, } fmt.Println(isSubtree(s, t))} 2.9 diameter type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func diameterOfBinaryTree(root *TreeNode) int { if root == nil { return 0 } if root.Left == nil &amp;amp;&amp;amp; root.Right == nil { return 0 } if root.Right == nil { return max(1+maxSide(root.Left), diameterOfBinaryTree(root.Left)) } if root.Left == nil { return max(1+maxSide(root.Right), diameterOfBinaryTree(root.Right)) } return max( max( (2+maxSide(root.Left)+maxSide(root.Right)), diameterOfBinaryTree(root.Left), ), diameterOfBinaryTree(root.Right))}func maxSide(root *TreeNode) int { if root == nil { return 0 } if root.Left == nil &amp;amp;&amp;amp; root.Right == nil { return 0 } return 1 + max(maxSide(root.Left), maxSide(root.Right))}func max(a, b int) int { if a &amp;gt; b { return a } else { return b }} func main() { s := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{ Val: 4, Left: &amp;amp;TreeNode{ Val: 1, }, Right: &amp;amp;TreeNode{ Val: 2, }, }, Right: &amp;amp;TreeNode{ Val: 5, }, } t := &amp;amp;TreeNode{ Val: 4, Left: &amp;amp;TreeNode{ Val: 1, }, Right: &amp;amp;TreeNode{ Val: 2, }, } fmt.Println(diameterOfBinaryTree(s)) fmt.Println(diameterOfBinaryTree(t))} 2.10 count complete tree nodes struct TreeNode { int val; TreeNode *left; TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) {}};class Solution {public: int countNodes(TreeNode* root) { if (root == NULL) { return 0; } int ldepth = this-&amp;gt;getLeftDepth(root); int rdepth = this-&amp;gt;getRightDepth(root); if (ldepth == rdepth) { return this-&amp;gt;pow(2,ldepth) -1; } return countNodes(root-&amp;gt;left) + countNodes(root-&amp;gt;right)+1; } int getLeftDepth(TreeNode *root) { if (root == NULL) { return 0; } return 1+getLeftDepth(root-&amp;gt;left); } int getRightDepth(TreeNode *root) { if (root == NULL) { return 0; } return 1+getRightDepth(root-&amp;gt;right); } int pow(int base, int exp) { int p=1; while (exp&amp;gt;0) { p = p*base; exp = exp- 1; } return p; }}; int main() { TreeNode* p = new TreeNode(5); p-&amp;gt;left = new TreeNode(3); p-&amp;gt;right = new TreeNode(7); Solution s; std::cout &amp;lt;&amp;lt; s.countNodes(p);} 2.11 implement trie type Trie struct { is_end int next map[byte]*Trie}/** Initialize your data structure here. */func Constructor() Trie { var trie Trie trie.next = make(map[byte]*Trie) return trie}/** Inserts a word into the trie. */func (this *Trie) Insert(word string) { byte_arr := []byte(word) this.insert(byte_arr)}func (this *Trie) insert(byte_arr []byte) { if len(byte_arr) &amp;lt; 1 { return } if next_trie, ok := this.next[byte_arr[0]]; ok { if len(byte_arr) &amp;gt; 1 { next_trie.insert(byte_arr[1:]) } else { next_trie.is_end = 1 } } else { trie := Constructor() next_trie := &amp;amp;trie this.next[byte_arr[0]] = next_trie if len(byte_arr) &amp;gt; 1 { next_trie.insert(byte_arr[1:]) } else { next_trie.is_end = 1 } }}/** Returns if the word is in the trie. */func (this *Trie) Search(word string) bool { byte_arr := []byte(word) return this.search(byte_arr)}func (this *Trie) search(byte_arr []byte) bool { if len(byte_arr) &amp;lt; 1 { if len(this.next) == 0 { return true } else { return false } } if next_trie, ok := this.next[byte_arr[0]]; ok { if len(byte_arr) == 1 &amp;amp;&amp;amp; next_trie.is_end == 1 { return true } else { return next_trie.search(byte_arr[1:]) } } else { return false }}/** Returns if there is any word in the trie that starts with the given prefix. */func (this *Trie) StartsWith(prefix string) bool { byte_arr := []byte(prefix) return this.startsWith(byte_arr)}func (this *Trie) startsWith(byte_arr []byte) bool { if len(byte_arr) &amp;lt; 1 { return true } if next_trie, ok := this.next[byte_arr[0]]; ok { return next_trie.startsWith(byte_arr[1:]) } else { return false }}/** * Your Trie object will be instantiated and called as such: * obj := Constructor(); * obj.Insert(word); * param_2 := obj.Search(word); * param_3 := obj.StartsWith(prefix); */ func main() { trie := Constructor() trie.Insert("hello") fmt.Println(trie.Search("hello")) fmt.Println(trie.StartsWith("hello"))} 2.12 merge two binary tree func mergeTrees(t1 *TreeNode, t2 *TreeNode) *TreeNode { if t1 == nil &amp;amp;&amp;amp; t2 == nil { return nil } if t2 == nil { return &amp;amp;TreeNode{ Val: t1.Val, Left: mergeTrees(t1.Left, nil), Right: mergeTrees(t1.Right, nil), } } if t1 == nil { return &amp;amp;TreeNode{ Val: t2.Val, Left: mergeTrees(nil, t2.Left), Right: mergeTrees(nil, t2.Right), } } return &amp;amp;TreeNode{ Val: t1.Val + t2.Val, Left: mergeTrees(t1.Left, t2.Left), Right: mergeTrees(t1.Right, t2.Right), }} func main() { t1 := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{Val: 3}, } t2 := &amp;amp;TreeNode{ Val: 2, Right: &amp;amp;TreeNode{Val: 3}, } fmt.Println(tree2str(mergeTrees(t1, t2)))} 2.13 flatten bt to linked list func flatten(root *TreeNode) { if root == nil { return } flatten(root.Left) flatten(root.Right) if root.Left == nil { return } lr_r := root.Left for { if lr_r.Right == nil { break } lr_r = lr_r.Right } lr_r.Right = root.Right root.Right = root.Left root.Left = nil return} func main() { t := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{Val: 3}, Right: &amp;amp;TreeNode{Val: 5}, } fmt.Println(tree2str(flatten(t)))} 2.14 sum of left leaves func sumOfLeftLeaves(root *TreeNode) int { if root == nil { return 0 } if root.Left == nil &amp;amp;&amp;amp; root.Right == nil { return 0 } if root.Left != nil { if isLeave(root.Left) { return root.Left.Val + sumOfLeftLeaves(root.Right) } else { return sumOfLeftLeaves(root.Left) + sumOfLeftLeaves(root.Right) } } else { return sumOfLeftLeaves(root.Right) }}func isLeave(node *TreeNode) bool { return node.Left == nil &amp;amp;&amp;amp; node.Right == nil} func main() { t := &amp;amp;TreeNode{ Val: 3, Left: &amp;amp;TreeNode{Val: 9}, Right: &amp;amp;TreeNode{ Val: 20, Left: &amp;amp;TreeNode{Val: 15}, Right: &amp;amp;TreeNode{Val: 7}, }, } fmt.Println(sumOfLeftLeaves(t))} 2.15 find bottom left tree value func findBottomLeftValue(root *TreeNode) int { if root == nil { return 0 } lnode_arr := []*TreeNode{root} for { n_lnode_arr := make([]*TreeNode, 0) for index, _ := range lnode_arr { node := lnode_arr[index] if node.Left != nil { n_lnode_arr = append(n_lnode_arr, node.Left) } if node.Right != nil { n_lnode_arr = append(n_lnode_arr, node.Right) } } if len(n_lnode_arr) &amp;gt; 0 { lnode_arr = n_lnode_arr } else { break } } return lnode_arr[0].Val} func main() { t := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{Val: 3}, Right: &amp;amp;TreeNode{ Val: 5, Left: &amp;amp;TreeNode{Val: 10}, }, } fmt.Println(findBottomLeftValue(t))} 2.16 right side view func rightSideView(root *TreeNode) []int { if root == nil { return []int{} } lnode_arr := []*TreeNode{root} rsv_arr := []int{root.Val} for { n_lnode_arr := make([]*TreeNode, 0) for index, _ := range lnode_arr { node := lnode_arr[index] if node.Left != nil { n_lnode_arr = append(n_lnode_arr, node.Left) } if node.Right != nil { n_lnode_arr = append(n_lnode_arr, node.Right) } } if len(n_lnode_arr) &amp;gt; 0 { rsv_arr = append(rsv_arr, n_lnode_arr[len(n_lnode_arr)-1].Val) lnode_arr = n_lnode_arr } else { break } } return rsv_arr} func main() { t := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{Val: 3}, Right: &amp;amp;TreeNode{Val: 5}, } fmt.Println(rightSideView(t))} 2.17 find largest value in each tree row func largestValues(root *TreeNode) []int { if root == nil { return []int{} } lnode_arr := []*TreeNode{root} rmax_arr := []int{root.Val} for { n_lnode_arr := make([]*TreeNode, 0) for index, _ := range lnode_arr { node := lnode_arr[index] if node.Left != nil { n_lnode_arr = append(n_lnode_arr, node.Left) } if node.Right != nil { n_lnode_arr = append(n_lnode_arr, node.Right) } } if len(n_lnode_arr) &amp;gt; 0 { rmax_val := n_lnode_arr[0].Val for index, _ := range n_lnode_arr { node := n_lnode_arr[index] if node.Val &amp;gt; rmax_val { rmax_val = node.Val } } lnode_arr = n_lnode_arr rmax_arr = append(rmax_arr, rmax_val) } else { break } } return rmax_arr} func main() { t := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{Val: 3}, Right: &amp;amp;TreeNode{Val: 5}, } fmt.Println(largestValues(t))} 2.18 most frequent subtree sum func findFrequentTreeSum(root *TreeNode) []int { if root == nil { return []int{} } sum_M := make(map[int]int) collectTreeSum(root, sum_M) var max_count int for _, count := range sum_M { if count &amp;gt; max_count { max_count = count } } ft_sum_arr := make([]int, 0) for sum, count := range sum_M { if count == max_count { ft_sum_arr = append(ft_sum_arr, sum) } } return ft_sum_arr}func collectTreeSum(root *TreeNode, sum_M map[int]int) int { if root == nil { return 0 } sum := collectTreeSum(root.Left, sum_M) + root.Val + collectTreeSum(root.Right, sum_M) sum_M[sum] = sum_M[sum] + 1 return sum} func main() { t := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{Val: 3}, Right: &amp;amp;TreeNode{Val: 5}, } fmt.Println(findFrequentTreeSum(t))} 2.19 construct binary tree from preorder and inorder traversal func buildTree(preorder []int, inorder []int) *TreeNode { if len(preorder) == 0 { return nil } if len(preorder) == 1 { return &amp;amp;TreeNode{ Val: preorder[0], } } rio_index := find(inorder, preorder[0]) return &amp;amp;TreeNode{ Val: preorder[0], Left: buildTree(preorder[1:rio_index+1], inorder[0:rio_index]), Right: buildTree(preorder[rio_index+1:], inorder[rio_index+1:]), }}func find(a []int, x int) int { for index, _ := range a { if a[index] == x { return index } } return -1} func main() { fmt.Println(tree2str(buildTree([]int{1,2,3}, []int{2,1,3}))) fmt.Println(tree2str(buildTree([]int{1,2,4,3,5}, []int{4,2,1,3,5})))} 2.20 construct binary tree from inorder and postorder traversal func buildTree(inorder []int, postorder []int) *TreeNode { if len(inorder) == 0 { return nil } if len(inorder) == 1 { return &amp;amp;TreeNode{Val: inorder[0]} } rio_index := find(inorder, postorder[len(postorder)-1]) return &amp;amp;TreeNode{ Val: postorder[len(postorder)-1], Left: buildTree(inorder[0:rio_index], postorder[0:rio_index]), Right: buildTree(inorder[rio_index+1:], postorder[rio_index:(len(postorder)-1)]), }}func find(a []int, x int) int { for index, _ := range a { if a[index] == x { return index } } return -1} func main() { fmt.Println(tree2str(buildTree([]int{2,1,3}, []int{2,3,1}))) fmt.Println(tree2str(buildTree([]int{4,2,1,3,5}, []int{4,2,5,3,1})))} 2.21 populating next right pointers in each node struct TreeLinkNode { int val; TreeLinkNode *left, *right, *next; TreeLinkNode(int x) : val(x), left(NULL), right(NULL), next(NULL) {}};struct ConnectObj { TreeLinkNode *left_most; TreeLinkNode *right_most; ConnectObj() : left_most(NULL), right_most(NULL) {}};std::deque&amp;lt;ConnectObj&amp;gt;mergeConnect( std::deque&amp;lt;ConnectObj&amp;gt; lc_dq, std::deque&amp;lt;ConnectObj&amp;gt; rc_dq){ for (std::deque&amp;lt;ConnectObj&amp;gt;::iterator it = lc_dq.begin(); it != lc_dq.end(); ++it) { if (it-&amp;gt;right_most == NULL) { it-&amp;gt;right_most = it-&amp;gt;left_most; } } for (std::deque&amp;lt;ConnectObj&amp;gt;::iterator it = rc_dq.begin(); it != rc_dq.end(); ++it) { if (it-&amp;gt;left_most == NULL) { it-&amp;gt;left_most = it-&amp;gt;right_most; } } int min_size = lc_dq.size() &amp;lt; rc_dq.size() ? lc_dq.size() : rc_dq.size(); for (int index=0; index &amp;lt; min_size; index+=1) { if (lc_dq[index].right_most != NULL &amp;amp;&amp;amp; rc_dq[index].left_most != NULL){ lc_dq[index].right_most-&amp;gt;next = rc_dq[index].left_most; } lc_dq[index].right_most = rc_dq[index].right_most; rc_dq[index].left_most = lc_dq[index].left_most; } return lc_dq.size() &amp;gt; rc_dq.size() ? lc_dq : rc_dq;}class Solution {public: void connect(TreeLinkNode *root) { if (root == NULL) { return; } this-&amp;gt;connectHelper(root); return; } std::deque&amp;lt;ConnectObj&amp;gt; connectHelper(TreeLinkNode *root) { std::deque&amp;lt;ConnectObj&amp;gt; conn_dq; if (root == NULL) { return conn_dq; } ConnectObj rc_node; rc_node.left_most = root; rc_node.right_most = root; if ((root-&amp;gt;left == NULL) &amp;amp;&amp;amp; (root-&amp;gt;right == NULL)) { conn_dq.push_back(rc_node); return conn_dq; } std::deque&amp;lt;ConnectObj&amp;gt; lc_dq = connectHelper(root-&amp;gt;left); std::deque&amp;lt;ConnectObj&amp;gt; rc_dq = connectHelper(root-&amp;gt;right); std::deque&amp;lt;ConnectObj&amp;gt; merge_dq = mergeConnect(lc_dq, rc_dq); merge_dq.push_front(rc_node); return merge_dq; }}; int main() { TreeLinkNode* p = new TreeLinkNode(5); p-&amp;gt;left = new TreeLinkNode(3); p-&amp;gt;left-&amp;gt;left = new TreeLinkNode(1); p-&amp;gt;left-&amp;gt;left-&amp;gt;left = new TreeLinkNode(1); p-&amp;gt;left-&amp;gt;right = new TreeLinkNode(2); p-&amp;gt;right = new TreeLinkNode(7); p-&amp;gt;right-&amp;gt;right = new TreeLinkNode(9); Solution s; s.connect(p); TreeLinkNode *left = p; while (left != NULL) { TreeLinkNode *head = left; while (head !=NULL){ std::cout &amp;lt;&amp;lt; head-&amp;gt;val &amp;lt;&amp;lt; " "; head = head-&amp;gt;next; } std::cout &amp;lt;&amp;lt; "\n"; left = left-&amp;gt;left; } return 0;} 2.22 add one row to tree func addOneRow(root *TreeNode, v int, d int) *TreeNode { if d == 1 { return &amp;amp;TreeNode{ Val: v, Left: root, } } if root == nil || d &amp;lt; 2 { return nil } addOneRowHelper(root, v, d) return root}func addOneRowHelper(root *TreeNode, v int, d int) { if root == nil { return } if d == 2 { root.Left = &amp;amp;TreeNode{ Val: v, Left: root.Left, } root.Right = &amp;amp;TreeNode{ Val: v, Right: root.Right, } return } addOneRowHelper(root.Left, v, d-1) addOneRowHelper(root.Right, v, d-1) return} func main() { root := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{Val: 3}, Right: &amp;amp;TreeNode{Val: 4}, } fmt.Println(tree2str(addOneRow(root, 2, 1))) fmt.Println(tree2str(addOneRow(root, 2, 2)))} 2.23 lowest common ancestor of a bt class Solution {public: TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) { if (root == NULL || p == root || q == root) { return root; } TreeNode *left = lowestCommonAncestor(root-&amp;gt;left, p, q); TreeNode *right = lowestCommonAncestor(root-&amp;gt;right, p, q); if (left != NULL &amp;amp;&amp;amp; right != NULL) { return root; } if (left != NULL) { return left; } if (right != NULL) { return right; } return NULL; }}; int main() { TreeNode* p = new TreeNode(5); p-&amp;gt;left = new TreeNode(3); p-&amp;gt;left-&amp;gt;left = new TreeNode(1); p-&amp;gt;left-&amp;gt;left-&amp;gt;left = new TreeNode(0); p-&amp;gt;left-&amp;gt;right = new TreeNode(2); p-&amp;gt;right = new TreeNode(7); p-&amp;gt;right-&amp;gt;right = new TreeNode(9); Solution s; std::cout &amp;lt;&amp;lt; s.lowestCommonAncestor(p, p-&amp;gt;left-&amp;gt;left, p-&amp;gt;right-&amp;gt;right)-&amp;gt;val; std::cout &amp;lt;&amp;lt; s.lowestCommonAncestor(p, p-&amp;gt;left-&amp;gt;left, p-&amp;gt;left-&amp;gt;right)-&amp;gt;val; return 0;} 2.24 serialize and deserialize bt &amp;lt;&amp;lt;bt-node-def-cpp&amp;gt;&amp;gt;int find_bracket_end(string str, int b_start) { std::stack&amp;lt;char&amp;gt; b_stack; int b_end=0; for (int index = b_start; index &amp;lt; str.size(); index += 1) { char c = str[index]; switch (c) { case '(': b_stack.push(c); break; case ')': b_stack.pop(); break; default: break; } if (b_stack.empty()==true) { b_end = index; break; } } return b_end;}string tree2str(TreeNode* t) { if (t == NULL) { return ""; } ostringstream os; os &amp;lt;&amp;lt; t-&amp;gt;val; if (t-&amp;gt;left == NULL &amp;amp;&amp;amp; t-&amp;gt;right == NULL) { return os.str(); } if (t-&amp;gt;left != NULL) { os &amp;lt;&amp;lt; "(" &amp;lt;&amp;lt; tree2str(t-&amp;gt;left) &amp;lt;&amp;lt; ")"; } else { os &amp;lt;&amp;lt; "()"; } if (t-&amp;gt;right != NULL) { os &amp;lt;&amp;lt; "(" &amp;lt;&amp;lt; tree2str(t-&amp;gt;right) &amp;lt;&amp;lt; ")"; } return os.str();}TreeNode* str2tree(string str) { if (str == "" || str == "()") { return NULL; } int b_start = str.find("("); if (b_start &amp;lt; 0) { int num = std::atoi(str.c_str()); return new TreeNode(num); } string num_str = str.substr(0, b_start); int num = std::atoi(num_str.c_str()); TreeNode* root = new TreeNode(num); int b_end = find_bracket_end(str, b_start); if (b_end-b_start &amp;gt; 1) { root-&amp;gt;left = str2tree(str.substr(b_start+1, b_end)); } b_start = b_end+1; if (b_start &amp;lt; str.size() &amp;amp;&amp;amp; str[b_start]=='('){ b_end = find_bracket_end(str, b_start); if (b_end-b_start &amp;gt; 1) { root-&amp;gt;right = str2tree(str.substr(b_start+1, b_end)); } } return root;}class Codec {public: // Encodes a tree to a single string. string serialize(TreeNode* root) { return tree2str(root); } // Decodes your encoded data to tree. TreeNode* deserialize(string data) { return str2tree(data); }}; using namespace std;int main() { TreeNode* p = new TreeNode(5); p-&amp;gt;left = new TreeNode(3); p-&amp;gt;left-&amp;gt;left = new TreeNode(1); p-&amp;gt;left-&amp;gt;left-&amp;gt;left = new TreeNode(1); p-&amp;gt;left-&amp;gt;right = new TreeNode(2); p-&amp;gt;right = new TreeNode(7); p-&amp;gt;right-&amp;gt;right = new TreeNode(9); Codec codec; string encode_str =codec.serialize(p); std::cout &amp;lt;&amp;lt; encode_str &amp;lt;&amp;lt; '\n'; TreeNode* np = codec.deserialize(encode_str); encode_str = codec.serialize(np); std::cout &amp;lt;&amp;lt; encode_str &amp;lt;&amp;lt; '\n'; return 0;} 2.25 average of levels in binary tree func averageOfLevels(root *TreeNode) []float64 { lo_arr := levelOrder(root) aveOfLevels := make([]float64, 0) for index, _ := range lo_arr { lo := lo_arr[index] var sum int for _, val := range lo { sum += val } ave := float64(sum) / float64(len(lo)) aveOfLevels = append(aveOfLevels, ave) } return aveOfLevels} func main() { root := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{ Val: 2, }, Right: &amp;amp;TreeNode{ Val: 3, }, } fmt.Println(averageOfLevels(root)) root.Left.Left = &amp;amp;TreeNode{Val:4} root.Right.Right = &amp;amp;TreeNode{Val:5} fmt.Println(averageOfLevels(root))} 2.26 TODO house robber III 3 bst 3.1 BSTIterator struct TreeNode { int val; TreeNode *left; TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) {}};struct Node { int val; Node *next; Node(int x) : val(x), next(NULL) {}};Node* convertBST2SortedLst(TreeNode *lct,TreeNode *pn, TreeNode *rct) { Node *lhead = NULL; if (lct != NULL) { lhead = convertBST2SortedLst(lct-&amp;gt;left, lct, lct-&amp;gt;right); } Node *pln = new Node(pn-&amp;gt;val); Node *rhead = NULL; if (rct != NULL){ rhead = convertBST2SortedLst(rct-&amp;gt;left, rct, rct-&amp;gt;right); } Node *head = NULL; if (lhead != NULL) { pln-&amp;gt;next = rhead; head = lhead; while (lhead-&amp;gt;next != NULL) { lhead = lhead-&amp;gt;next; } lhead-&amp;gt;next = pln; } else { pln-&amp;gt;next = rhead; head = pln; } return head;}class BSTIterator { Node* head;public: BSTIterator(TreeNode *root) { if (root != NULL) { head = convertBST2SortedLst(root-&amp;gt;left, root, root-&amp;gt;right); } else { head = NULL; } } /** @return whether we have a next smallest number */ bool hasNext() { if (this-&amp;gt;head != NULL) { return true; } else { return false; } } /** @return the next smallest number */ int next() { if (this-&amp;gt;head== NULL) { return 0; } Node *oldHead = head; head = head-&amp;gt;next; int num = oldHead-&amp;gt;val; delete oldHead; oldHead = NULL; return num; } ~BSTIterator(){ Node *oldHead = NULL; while (head != NULL){ oldHead = head; head = head-&amp;gt;next; delete oldHead; oldHead = NULL; } }};/** * Your BSTIterator will be called like this: * BSTIterator i = BSTIterator(root); * while (i.hasNext()) cout &amp;lt;&amp;lt; i.next(); */ int main() { TreeNode* p = new TreeNode(5); p-&amp;gt;left = new TreeNode(3); p-&amp;gt;right = new TreeNode(7); BSTIterator i = BSTIterator(p); while (i.hasNext()) std::cout &amp;lt;&amp;lt; i.next(); return 0;} 3.2 to greater tree type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func convertBST(root *TreeNode) *TreeNode { if root == nil { return nil } return convertBSTHelper(root, 0)}func convertBSTHelper(root *TreeNode, upper int) *TreeNode { if root == nil { return nil } if root.Left == nil &amp;amp;&amp;amp; root.Right == nil { root.Val += upper return root } if root.Right != nil { minNode := findMinBST(root.Right) root.Right = convertBSTHelper(root.Right, upper) root.Val += minNode.Val } else { root.Val += upper } if root.Left != nil { root.Left = convertBSTHelper(root.Left, root.Val) } return root}func findMinBST(root *TreeNode) *TreeNode { if root == nil || root.Left == nil { return root } return findMinBST(root.Left)} func main() { root := &amp;amp;TreeNode{ Val: 0, Left: &amp;amp;TreeNode{ Val: -1, Left: &amp;amp;TreeNode{ Val: -3, }, }, Right: &amp;amp;TreeNode{ Val: 2, Right: &amp;amp;TreeNode{ Val: 4, }, }, } fmt.Println(convertBST(root)) fmt.Println(root.Left) fmt.Println(root.Left.Left) fmt.Println(root.Right.Right)} 3.3 validate type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func isValidBST(root *TreeNode) bool { if root == nil { return true } return isValidLeftBST(root.Left, root.Val) &amp;amp;&amp;amp; isValidRightBST(root.Right, root.Val)}func isValidLeftBST(root *TreeNode, upper int) bool { if root == nil { return true } if root.Val &amp;gt;= upper { return false } return isValidLeftBST(root.Left, root.Val) &amp;amp;&amp;amp; isValidSubBST(root.Right, root.Val, upper)}func isValidRightBST(root *TreeNode, lower int) bool { if root == nil { return true } if root.Val &amp;lt;= lower { return false } return isValidRightBST(root.Right, root.Val) &amp;amp;&amp;amp; isValidSubBST(root.Left, lower, root.Val)}func isValidSubBST(root *TreeNode, lower int, upper int) bool { if root == nil { return true } if root.Val &amp;gt;= upper || root.Val &amp;lt;= lower { return false } return isValidSubBST(root.Left, lower, root.Val) &amp;amp;&amp;amp; isValidSubBST(root.Right, root.Val, upper)} func main() { root := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{ Val: 2, }, Right: &amp;amp;TreeNode{ Val: 3, }, } fmt.Println(isValidBST(root)) root = &amp;amp;TreeNode{ Val: 2, Left: &amp;amp;TreeNode{ Val: 1, }, Right: &amp;amp;TreeNode{ Val: 3, }, } fmt.Println(isValidBST(root))} 3.4 find mode type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func findMode(root *TreeNode) []int { if root == nil { return []int{} } modes := collect(root) if len(modes) &amp;lt; 1 { return modes } for i := 1; i &amp;lt; len(modes); i += 1 { for j := i; j &amp;gt; 0; j -= 1 { if modes[j] &amp;lt; modes[j-1] { modes[j], modes[j-1] = modes[j-1], modes[j] } } } var max_count int var count int var pre int n_modes := make([]int, 0) for index, mode := range modes { if index == 0 { max_count = 1 pre = mode count = 1 n_modes = append(n_modes, mode) continue } if mode == pre { count += 1 } if mode != pre { pre = mode count = 1 } if count == max_count { n_modes = append(n_modes, mode) } if count &amp;gt; max_count { max_count = count n_modes = []int{mode} } } return n_modes}func collect(root *TreeNode) []int { if root == nil { return []int{} } return append(append(collect(root.Left), root.Val), collect(root.Right)...)} func main() { root := &amp;amp;TreeNode{ Val: 0, Left: &amp;amp;TreeNode{ Val: -1, Left: &amp;amp;TreeNode{ Val: -1, }, }, Right: &amp;amp;TreeNode{ Val: 2, Right: &amp;amp;TreeNode{ Val: 2, }, }, } fmt.Println(findMode(root))} 3.5 convert sorted array to bst func sortedArrayToBST(nums []int) *TreeNode { if len(nums) == 0 { return nil } if len(nums) == 1 { return &amp;amp;TreeNode{ Val: nums[0], } } if len(nums) == 2 { return &amp;amp;TreeNode{ Val: nums[1], Left: &amp;amp;TreeNode{ Val: nums[0], }, } } mid := len(nums) / 2 return &amp;amp;TreeNode{ Val: nums[mid], Left: sortedArrayToBST(nums[:mid]), Right: sortedArrayToBST(nums[mid+1:]), }} func main() { fmt.Println(tree2str(sortedArrayToBST([]int{1,2,3}))) fmt.Println(tree2str(sortedArrayToBST([]int{1,2,3,4,5,6}))) fmt.Println(tree2str(sortedArrayToBST([]int{1,2,3,4,5,6,7,8})))} 3.6 lowest common ancestor struct TreeNode { int val; TreeNode *left; TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) {}};class Solution {public: TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) { if (root == NULL) { return NULL; } if (p-&amp;gt;val &amp;gt; q-&amp;gt;val) { TreeNode *tmp = p; p=q; q=tmp; } if (root-&amp;gt;val&amp;gt;p-&amp;gt;val &amp;amp;&amp;amp; root-&amp;gt;val&amp;lt;q-&amp;gt;val) { return root; } if (root-&amp;gt;val &amp;lt; p-&amp;gt;val) { return lowestCommonAncestor(root-&amp;gt;right, p, q); } if (root-&amp;gt;val &amp;gt; q-&amp;gt;val) { return lowestCommonAncestor(root-&amp;gt;left, p, q); } if (root-&amp;gt;val == p-&amp;gt;val) { return root; } if (root-&amp;gt;val == q-&amp;gt;val) { return root; } return NULL; }}; int main() { TreeNode* p = new TreeNode(5); p-&amp;gt;left = new TreeNode(3); p-&amp;gt;right = new TreeNode(7); Solution s; std::cout &amp;lt;&amp;lt; s.lowestCommonAncestor(p, p-&amp;gt;left, p-&amp;gt;right)-&amp;gt;val;} 3.7 recover binary search tree type TreeNode struct { Val int Left *TreeNode Right *TreeNode}type RecoverNode struct { Pre *TreeNode Ppre *TreeNode Is_recover int Illegal *TreeNode}type traversalFunc func(*TreeNode)func recoverTree(root *TreeNode) { if root == nil { return } rNode := &amp;amp;RecoverNode{} tfunc := func(rnode *RecoverNode) traversalFunc { return func(node *TreeNode) { recoverFunc(node, rnode) } }(rNode) inorderTraversal(root, tfunc) if rNode.Is_recover == 0 &amp;amp;&amp;amp; rNode.Illegal != nil { rNode.Pre.Val, rNode.Illegal.Val = rNode.Illegal.Val, rNode.Pre.Val }}func inorderTraversal(root *TreeNode, tfunc traversalFunc) { if root == nil { return } inorderTraversal(root.Left, tfunc) tfunc(root) inorderTraversal(root.Right, tfunc)}func recoverFunc(node *TreeNode, rnode *RecoverNode) { if node == nil { return } if rnode.Is_recover == 1 { return } if rnode.Pre == nil { rnode.Pre = node return } if node.Val &amp;lt; rnode.Pre.Val { if rnode.Illegal == nil { rnode.Illegal = rnode.Pre } else { rnode.Illegal.Val, node.Val = node.Val, rnode.Illegal.Val rnode.Is_recover = 1 } } else { if rnode.Illegal != nil { if rnode.Illegal.Val &amp;lt; node.Val { rnode.Illegal.Val, rnode.Pre.Val = rnode.Pre.Val, rnode.Illegal.Val rnode.Is_recover = 1 } } } rnode.Ppre = rnode.Pre rnode.Pre = node} func main() { s := &amp;amp;TreeNode{ Val: 2, Left: &amp;amp;TreeNode{ Val: 3, }, Right: &amp;amp;TreeNode{ Val: 1, }, } fmt.Println(tree2str(s)) recoverTree(s) fmt.Println(tree2str(s))} 3.8 delete node type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func deleteNode(root *TreeNode, key int) *TreeNode { if root == nil { return nil } if root.Val == key { if root.Left == nil || root.Right == nil { if root.Left != nil { return root.Left } else if root.Right != nil { return root.Right } else { return nil } } else { successor := treeMinimum(root.Right) root.Val = successor.Val root.Right = deleteNode(root.Right, successor.Val) } } if root.Val &amp;lt; key { root.Right = deleteNode(root.Right, key) } else { root.Left = deleteNode(root.Left, key) } return root}func treeMinimum(node *TreeNode) *TreeNode { if node.Left != nil { return treeMinimum(node.Left) } else { return node }} func main() { s := &amp;amp;TreeNode{ Val: 2, Left: &amp;amp;TreeNode{ Val: 1, }, Right: &amp;amp;TreeNode{ Val: 3, }, } fmt.Println(tree2str(s)) s = deleteNode(s, 1) fmt.Println(tree2str(s))} 3.9 convert sorted list to bst type ListNode struct { Val int Next *ListNode}type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func sortedListToBST(head *ListNode) *TreeNode { if head == nil { return nil } length := getListLength(head) return sortedListToBSTHelper(head, length)}func getListLength(head *ListNode) int { if head == nil { return 0 } return 1 + getListLength(head.Next)}func getListNth(head *ListNode, nth int) *ListNode { if head == nil { return nil } if nth &amp;lt; 1 { return head } return getListNth(head.Next, nth-1)}func sortedListToBSTHelper(head *ListNode, length int) *TreeNode { if length &amp;lt; 1 { return nil } if length == 1 { return &amp;amp;TreeNode{ Val: head.Val, } } if length == 1 { return &amp;amp;TreeNode{ Val: head.Val, Right: &amp;amp;TreeNode{ Val: head.Next.Val, }, } } mid := length / 2 mid_node := getListNth(head, mid) return &amp;amp;TreeNode{ Val: mid_node.Val, Left: sortedListToBSTHelper(head, mid), Right: sortedListToBSTHelper(mid_node.Next, length-1-mid), }} func main() { sortedLst := &amp;amp;ListNode{ Val: 1, Next: &amp;amp;ListNode{ Val:2, Next: &amp;amp;ListNode{ Val:3, }, }, } fmt.Println(tree2str(sortedListToBST(sortedLst)))} 3.10 kth smallest elemen type KthNode struct { K int Val int}type traversalFunc func(*TreeNode)func kthSmallest(root *TreeNode, k int) int { if root == nil { return 0 } kNode := &amp;amp;KthNode{K: k} tfunc := func(knode *KthNode) traversalFunc { return func(node *TreeNode) { kthFunc(node, knode) } }(kNode) inorderTraversal(root, tfunc) return kNode.Val}func inorderTraversal(root *TreeNode, tfunc traversalFunc) { if root == nil { return } inorderTraversal(root.Left, tfunc) tfunc(root) inorderTraversal(root.Right, tfunc)}func kthFunc(node *TreeNode, kn *KthNode) { if node == nil &amp;amp;&amp;amp; kn.K == 0 { return } kn.K -= 1 if kn.K == 0 { kn.Val = node.Val } return} func main() { t := &amp;amp;TreeNode{ Val: 3, Left: &amp;amp;TreeNode{Val: 2}, Right: &amp;amp;TreeNode{Val: 5}, } fmt.Println(kthSmallest(t,1)) fmt.Println(kthSmallest(t,2)) fmt.Println(kthSmallest(t,3))} 3.11 unique bst func numTrees(n int) int { if n &amp;lt; 1 { return 1 } ctl_arr := make([]int, n+1) ctl_arr[0] = 1 ctl_arr[1] = 1 for i := 2; i &amp;lt; n+1; i += 1 { for j := 0; j &amp;lt; i; j += 1 { ctl_arr[i] += ctl_arr[j] * ctl_arr[i-j-1] } } return ctl_arr[n]} func main() { for _, n := range list{ fmt.Println(numTrees(n)) }} 3.12 unique bst II func generateTrees(n int) []*TreeNode { if n == 0 { return []*TreeNode{} } tree_arr := []*TreeNode{ &amp;amp;TreeNode{ Val: 1, }, } for i := 2; i &amp;lt;= n; i += 1 { ng_tree_arr := make([]*TreeNode, 0) for index, _ := range tree_arr { tree := tree_arr[index] ng_tree_arr = append(ng_tree_arr, genTreesHelper(tree, i)...) } tree_arr = ng_tree_arr } return tree_arr}func genTreesHelper(root *TreeNode, greater int) []*TreeNode { if root == nil { return []*TreeNode{} } cr := cloneTree(root) right := cr var parent *TreeNode tree_arr := make([]*TreeNode, 0) for { if right != nil { rval := right.Val node := &amp;amp;TreeNode{ Val: greater, Left: right, } if parent != nil { parent.Right = node } else { cr = node } tree_arr = append(tree_arr, cr) cr = cloneTree(root) parent = getNode(cr, rval) right = parent.Right } else { parent.Right = &amp;amp;TreeNode{Val: greater} tree_arr = append(tree_arr, cr) break } } return tree_arr}func cloneTree(root *TreeNode) *TreeNode { if root == nil { return nil } return &amp;amp;TreeNode{ Val: root.Val, Left: cloneTree(root.Left), Right: cloneTree(root.Right), }}func getNode(root *TreeNode, val int) *TreeNode { if root == nil { return nil } if root.Val == val { return root } if root.Val &amp;lt; val { return getNode(root.Right, val) } else { return getNode(root.Left, val) }} func main() { for _, n := range list{ tree_arr := generateTrees(n) fmt.Println(n, len(tree_arr)) }} Last Updated 2017-07-16 Sun 15:30.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Leetcode-array]]></title>
      <url>%2F2017%2F07%2F16%2Fleetcode-array%2F</url>
      <content type="text"><![CDATA[type Interval struct { Start int End int} 1 best time to buy and sell stock func maxProfit(prices []int) int { if len(prices) &amp;lt; 1 { return 0 } var mp int min_p := prices[0] for _, price := range prices { if price-min_p &amp;gt; mp { mp = price - min_p } if price &amp;lt; min_p { min_p = price } } return mp} 2 best time to buy and sell stock II func maxProfit(prices []int) int { if len(prices) &amp;lt; 1 { return 0 } var mp, pre_p, buy_p int var status string // buy sell for index, price := range prices { if index == 0 { pre_p = price buy_p = price status = "buy" continue } if price &amp;gt; pre_p &amp;amp;&amp;amp; status == "sell" { buy_p = pre_p status = "buy" } if pre_p &amp;gt; price &amp;amp;&amp;amp; status == "buy" { mp += pre_p - buy_p status = "sell" } pre_p = price } if pre_p &amp;gt; buy_p &amp;amp;&amp;amp; status == "buy" { mp += pre_p - buy_p } return mp} 3 plus one func plusOne(digits []int) []int { var carry int carry = 1 for index := len(digits) - 1; index &amp;gt;= 0; index -= 1 { if carry+digits[index] == 10 { carry = 1 digits[index] = 0 } else { digits[index] += carry carry = 0 } if carry == 0 { break } } if carry == 1 { return append([]int{1}, digits...) } return digits} 4 pascal's triangle func generate(numRows int) [][]int { pt_arr := make([][]int, 0) if numRows &amp;lt; 1 { return pt_arr } pt_arr = append(pt_arr, []int{1}) if numRows == 1 { return pt_arr } pt_arr = append(pt_arr, []int{1, 1}) if numRows &amp;lt; 3 { return pt_arr } for i := 3; i &amp;lt;= numRows; i += 1 { pt := make([]int, i) pre_pt := pt_arr[i-2] var pre int for index, _ := range pre_pt { if index == 0 { pt[index] = pre_pt[index] pre = pre_pt[index] continue } if index == len(pre_pt)-1 { pt[index] = pre + pre_pt[index] pt[index+1] = pre_pt[index] continue } pt[index] = pre + pre_pt[index] pre = pre_pt[index] } pt_arr = append(pt_arr, pt) } return pt_arr} func main() { fmt.Println(generate(3))} 5 pascal's triangle II func getRow(rowIndex int) []int { rowIndex += 1 pt_row := make([]int, rowIndex) if rowIndex &amp;lt; 1 { return pt_row } pt_row[0] = 1 if rowIndex == 1 { return pt_row } pt_row[1] = 1 for i := 3; i &amp;lt;= rowIndex; i += 1 { ptr := pt_row[0:i] pre_ptr := pt_row[0 : i-1] var pre int for index, _ := range pre_ptr { if index == 0 { pre = pre_ptr[index] continue } if index == len(pre_ptr)-1 { ptr[index+1] = pre_ptr[index] ptr[index] = pre + pre_ptr[index] continue } pre_num := pre_ptr[index] ptr[index], pre = pre+pre_num, pre_num } } return pt_row} func main() { fmt.Println(getRow(4))} 6 array partition I func min(a, b int) int { if a &amp;gt; b { return b } else { return a }}func arrayPairSum(nums []int) int { sort.Ints(nums) var p_sum int for index := 0; index &amp;lt; len(nums); index += 2 { p_sum += min(nums[index], nums[index+1]) } return p_sum} 7 find all numbers disappeared in an array func findDisappearedNumbers(nums []int) []int { if len(nums) &amp;lt; 1 { return nums } dis_nums := make([]int, 0) var pre, pre_index int for index, num := range nums { if index+1 != num &amp;amp;&amp;amp; num != 0 { pre = num pre_index = index break } } if pre == 0 { return dis_nums } for i := 0; i &amp;lt; len(nums); i += 1 { if nums[pre-1] != pre &amp;amp;&amp;amp; nums[pre-1] != 0 { nums[pre-1], pre = pre, nums[pre-1] continue } if nums[pre-1] == 0 { nums[pre-1] = pre } nums[pre_index] = 0 for index, num := range nums { if index+1 != num &amp;amp;&amp;amp; num != 0 { pre = num pre_index = index break } } } nums[pre-1] = pre for index, num := range nums { if index+1 != num { dis_nums = append(dis_nums, index+1) } } return dis_nums} func findDisappearedNumbers(nums []int) []int { marks := make([]int, 0) for _, num := range nums { marks[num-1] = 1 } dis_nums := make([]int, 0) for index, mark := range marks { if mark == 0 { dis_nums = append(dis_nums, index+1) } } return dis_nums} func main() { fmt.Println(findDisappearedNumbers([]int{4,3,2,7,8,2,3,1}))} 8 two sum func twoSum(nums []int, target int) []int { indices := make([]int, 0) for i := 0; i &amp;lt; len(nums); i += 1 { fir := nums[i] for j := i+1; j &amp;lt; len(nums); j +=1 { secd := nums[j] if fir + secd == target { indices = append(indices, i) indices = append(indices, j) break } } } return indices} /** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */func addTwoNumbers(l1 *ListNode, l2 *ListNode) *ListNode { var carry int var sum_head, sum_curr *ListNode for { if l1 == nil &amp;amp;&amp;amp; l2 == nil { if carry &amp;gt; 0 { sum_node := &amp;amp;ListNode{ Val: carry, Next: nil, } if sum_head != nil { sum_curr.Next = sum_node sum_curr = sum_node } else { sum_head = sum_node sum_curr = sum_node } } break } var sum int if l1 != nil &amp;amp;&amp;amp; l2 != nil { sum = l1.Val + l2.Val + carry l1, l2 = l1.Next, l2.Next } else if l2 == nil { sum = l1.Val + carry l1 = l1.Next } else if l1 == nil { sum = l2.Val + carry l2 = l2.Next } if sum &amp;gt; 9 { carry = 1 sum -= 10 } else { carry = 0 } sum_node := &amp;amp;ListNode{ Val: sum, Next: nil, } if sum_head != nil { sum_curr.Next = sum_node sum_curr = sum_node } else { sum_head = sum_node sum_curr = sum_node } } return sum_head} type ListNode struct { Val int Next *ListNode}func make_list(vals []int) *ListNode{ var lst, lst_c *ListNode for _, val := range vals { node := &amp;amp;ListNode{ Val: val, Next: nil, } if lst != nil { lst_c.Next = node lst_c = node } else { lst = node lst_c = node } } return lst}func print_list(lst *ListNode) { var str string for { if lst == nil { break } str += fmt.Sprintf("%d,", lst.Val) lst = lst.Next } str = strings.Trim(str, ",") fmt.Printf("[%s]", str)}func main() { l1 := make_list([]int{2,4,3}) l2 := make_list([]int{5,6,4}) sum_lst := addTwoNumbers(l1,l2) print_list(sum_lst)} 9 two sum II - input array is sorted func twoSum(nums []int, target int) []int { indices := make([]int, 0) for i := 0; i &amp;lt; len(nums); i += 1 { fir := nums[i] for j := i + 1; j &amp;lt; len(nums); j += 1 { secd := nums[j] if fir+secd == target { indices = append(indices, i+1) indices = append(indices, j+1) break } } } return indices} 10 remove duplicates from sorted array func removeDuplicates(nums []int) int { if (len(nums)) &amp;lt;2 { return len(nums) } pre := nums[0] size := 1 for _, num := range nums { if pre != num { pre = num nums[size] = num size++ } } return size} 11 remove duplicates from sorted array II func removeDuplicates(nums []int) int { if (len(nums)) &amp;lt; 3 { return len(nums) } size := 2 pp_num := nums[0] p_num := nums[1] nums_size := len(nums) for i := 2; i &amp;lt; nums_size; i++ { if nums[i] == p_num &amp;amp;&amp;amp; p_num == pp_num { continue } pp_num = p_num p_num = nums[i] nums[size] = nums[i] size++ } return size} 12 remove element func removeElement(nums []int, val int) int { var size int for index, num := range nums { if index == 0 { if num == val { size = 0 } else { size = 1 } continue } if num != val { nums[size] = num size += 1 } } return size} 13 majority element func majorityElement(nums []int) int { num_M := make(map[int]int) for _, num := range nums { time := num_M[num] num_M[num] = time + 1 } var mt_num, max_times int for num, time := range num_M { if time &amp;gt; max_times { mt_num = num max_times = time } } return mt_num} 14 DONE shortest unsorted continuous subarray State "DONE" from "STARTED" [2017-07-17 Mon 23:32] func findUnsortedSubarray(nums []int) int { n_nums := make([]int, len(nums)) copy(n_nums, nums) sort.Ints(n_nums) var start, end int for index, _ := range nums { if nums[index] != n_nums[index] { start = index break } } for index := len(nums) - 1; index &amp;gt;= 0; index -= 1 { if nums[index] != n_nums[index] { end = index + 1 break } } return end - start} 15 reshape the matrix func matrixReshape(nums [][]int, r int, c int) [][]int { if len(nums) &amp;lt; 1 || len(nums[0]) &amp;lt; 1 { return [][]int{} } or := len(nums) oc := len(nums[0]) if or*oc != r*c { return nums } f_nums := make([]int, 0) for index, _ := range nums { row := nums[index] f_nums = append(f_nums, row...) } n_nums := make([][]int, r) for i := 0; i &amp;lt; r; i += 1 { row := make([]int, c) for j := 0; j &amp;lt; c; j += 1 { row[j] = f_nums[i*c+j] } n_nums[i] = row } return n_nums} 16 search insert position func searchInsert(nums []int, target int) int { for index, num := range nums { if num == target { return index } if num &amp;gt; target { return index } } return len(nums)} 17 merge sorted array func merge(nums1 []int, m int, nums2 []int, n int) { if m == 0 { for i := 0; i &amp;lt; n; i += 1 { nums1[i] = nums2[i] } return } if n == 0 { return } n1_index := m - 1 n2_index := n - 1 index := m + n - 1 for { if n1_index &amp;lt; 0 || n2_index &amp;lt; 0 { break } if nums1[n1_index] &amp;gt; nums2[n2_index] { nums1[index] = nums1[n1_index] n1_index -= 1 index -= 1 } else { nums1[index] = nums2[n2_index] n2_index -= 1 index -= 1 } } if n2_index &amp;gt;= 0 { for i := 0; i &amp;lt;= n2_index; i += 1 { nums1[i] = nums2[i] } } return} 18 maximum product of three numbers func max(a, b int) int { if a &amp;gt; b { return a } else { return b }}func maximumProduct(nums []int) int { sort.Ints(nums) size := len(nums) return max(nums[size-1]*nums[size-2]*nums[size-3], nums[0]*nums[1]*nums[size-1])} 19 maximum average subarray I func findMaxAverage(nums []int, k int) float64 { var max_average float64 for index := 0; index &amp;lt;= len(nums)-k; index += 1 { var sub_sum int for j := 0; j &amp;lt; k; j += 1 { sub_sum += nums[index+j] } average := float64(sub_sum) / float64(k) if index == 0 { max_average = average continue } if max_average &amp;lt; average { max_average = average } } return max_average} 20 move zeroes func moveZeroes(nums []int) { for index, num := range nums { if num == 0 { continue } for j := index; 0 &amp;lt; j; j -= 1 { if nums[j-1] == 0 { nums[j-1], nums[j] = nums[j], nums[j-1] } else { break } } } return} func main() { nums := []int{0, 1, 0, 3, 12} moveZeroes(nums) fmt.Println(nums)} 21 can place flowers func canPlaceFlowers(flowerbed []int, n int) bool { if len(flowerbed) &amp;lt; 1 &amp;amp;&amp;amp; n &amp;gt; 0 { return false } if n == 0 { return true } if len(flowerbed) &amp;lt; n { return false } if len(flowerbed) == 1 { if flowerbed[0] == 0 &amp;amp;&amp;amp; n == 1 { return true } else { return false } } for index, _ := range flowerbed { if flowerbed[index] == 1 { continue } switch index { case 0: if flowerbed[index+1] == 0 { flowerbed[index] = 1 n -= 1 } case len(flowerbed) - 1: if flowerbed[index-1] == 0 { flowerbed[index] = 1 n -= 1 } default: if flowerbed[index-1] == 0 &amp;amp;&amp;amp; flowerbed[index+1] == 0 { flowerbed[index] = 1 n -= 1 } } if n &amp;lt; 1 { return true } } return false} 22 contains duplicate func containsDuplicate(nums []int) bool { num_M := make(map[int]bool) for _, num := range nums { num_M[num] = true } return len(nums) &amp;gt; len(num_M)} 23 contains duplicate II func containsNearbyDuplicate(nums []int, k int) bool { num_M := make(map[int]bool) for index, num := range nums { if index &amp;gt; k { delete(num_M, nums[index-k-1]) } if num_M[num] { return true } num_M[num] = true } return false} 24 contains duplicate III func abs(x int) int { if x &amp;lt; 0 { return -x } else { return x }}func getQuot(i, w int) int { if i &amp;lt; 0 { return (i+1)/w - 1 } else { return i / w }}func containsNearbyAlmostDuplicate(nums []int, k int, t int) bool { if t &amp;lt; 0 { return false } num_M := make(map[int]int) w := t + 1 for index, num := range nums { quot := getQuot(num, w) if _, ok := num_M[quot]; ok { return true } if pre_num, ok := num_M[quot-1]; ok &amp;amp;&amp;amp; abs(num-pre_num) &amp;lt; w { return true } if pre_num, ok := num_M[quot+1]; ok &amp;amp;&amp;amp; abs(num-pre_num) &amp;lt; w { return true } num_M[quot] = num if index &amp;gt;= k { delete(num_M, getQuot(nums[index-k], w)) } } return false} 25 k-diff pairs in an array func findPairs(nums []int, k int) int { sort.Ints(nums) var base_index, pair_size int for { for i := base_index + 1; i &amp;lt; len(nums); i += 1 { if nums[i]-nums[base_index] &amp;gt; k { break } if nums[i]-nums[base_index] == k { pair_size += 1 break } } old_bi := base_index for i := base_index + 1; i &amp;lt; len(nums); i += 1 { if nums[i]-nums[base_index] &amp;gt; 0 { base_index = i break } } if old_bi == base_index { break } if base_index == len(nums)-1 { break } } return pair_size} 26 best time to buy and sell stock II func maxProfit(prices []int) int { if len(prices) &amp;lt; 1 { return 0 } var mp, pre_p, buy_p int var status string // buy sell for index, price := range prices { if index == 0 { pre_p = price buy_p = price status = "buy" continue } if price &amp;gt; pre_p &amp;amp;&amp;amp; status == "sell" { buy_p = pre_p status = "buy" } if pre_p &amp;gt; price &amp;amp;&amp;amp; status == "buy" { mp += pre_p - buy_p status = "sell" } pre_p = price } if pre_p &amp;gt; buy_p &amp;amp;&amp;amp; status == "buy" { mp += pre_p - buy_p } return mp} 27 DONE maximum subarray State "DONE" from "WAITING" [2017-07-18 Tue 23:30] func maxSubArray(nums []int) int { if len(nums) &amp;lt; 1 { return 0 } size := len(nums) max_sum := nums[0] pre_sum := nums[0] for i := 1; i &amp;lt; size; i += 1 { if pre_sum &amp;gt; 0 { pre_sum = nums[i] + pre_sum } else { pre_sum = nums[i] } if pre_sum &amp;gt; max_sum { max_sum = pre_sum } } return max_sum} 28 missing number func missingNumber(nums []int) int { var sum int for _, num := range nums { sum += num } size := len(nums) return size*(size+1)/2 - sum} 29 max consecutive ones func findMaxCntecutiveOnes(nums []int) int { var cnt, max_cnt int for _, num := range nums { if num == 0 { if cnt &amp;gt; max_cnt { max_cnt = cnt } cnt = 0 } if num == 1 { cnt += 1 } } if cnt &amp;gt; max_cnt { max_cnt = cnt } return max_cnt} 30 rotate array func reverse(nums []int) { size := len(nums) mid := size / 2 for i := 0; i &amp;lt; mid; i += 1 { nums[i], nums[size-i-1] = nums[size-i-1], nums[i] }}func rotate(nums []int, k int) { size := len(nums) if size == 1 { return } k = k % size reverse(nums[0 : size-k]) reverse(nums[size-k : size]) reverse(nums)} func main() { arr := []int{1,2,3,4,5,6,7} rotate(arr, 3) fmt.Println(arr)} 31 find peak element func findPeakElement(nums []int) int { if len(nums) &amp;lt; 1 { return -1 } if len(nums) == 1 { return 0 } var pe int size := len(nums) for i := 0; i &amp;lt; size; i += 1 { switch i { case 0: if nums[0] &amp;gt; nums[1] { return 0 } case size - 1: if nums[size-1] &amp;gt; nums[size-2] { return size - 1 } default: if nums[i-1] &amp;lt; nums[i] &amp;amp;&amp;amp; nums[i] &amp;gt; nums[i+1] { return i } } } return -1} 32 maximum product subarray func max(a, b int) int { if a &amp;gt; b { return a } else { return b }}func min(a, b int) int { if a &amp;gt; b { return b } else { return a }}func maxProduct(nums []int) int { if len(nums) &amp;lt; 1 { return 0 } size := len(nums) maxp_sub_arr := make([]int, size) ng_maxp_sub_arr := make([]int, size) maxp_sub_arr[0] = nums[0] if maxp_sub_arr[0] &amp;lt; 0 { ng_maxp_sub_arr[0] = maxp_sub_arr[0] } else { ng_maxp_sub_arr[0] = 1 } for i := 1; i &amp;lt; size; i += 1 { if nums[i] == 0 { continue } if maxp_sub_arr[i-1] == 0 { maxp_sub_arr[i] = nums[i] if nums[i] &amp;lt; 0 { ng_maxp_sub_arr[i] = maxp_sub_arr[i] } else { ng_maxp_sub_arr[i] = 1 } } if nums[i] &amp;gt; 0 { maxp_sub_arr[i] = max(nums[i]*maxp_sub_arr[i-1], nums[i]) ng_maxp_sub_arr[i] = nums[i] * ng_maxp_sub_arr[i-1] } if nums[i] &amp;lt; 0 { maxp_sub_arr[i] = nums[i] * ng_maxp_sub_arr[i-1] ng_maxp_sub_arr[i] = min(nums[i]*maxp_sub_arr[i-1], nums[i]) } } maxp := maxp_sub_arr[0] for _, subp := range maxp_sub_arr { if subp &amp;gt; maxp { maxp = subp } } return maxp} func main() { fmt.Println(maxProduct([]int{2,3,-2,4,0,-3,-4}))} 33 minimum size subarray sum func minSubArrayLen(s int, nums []int) int { if len(nums) &amp;lt; 0 { return 0 } var sub_sum, msub_arl, sub_arl int size := len(nums) msub_arl = size + 1 for index, num := range nums { if sub_sum+num &amp;lt; s { sub_sum += num sub_arl += 1 continue } if sub_sum+num &amp;gt;= s { for { if sub_arl &amp;lt; 1 { break } del_num := nums[index-sub_arl] sub_sum -= del_num sub_arl -= 1 if sub_sum+num &amp;lt; s { sub_sum += num sub_arl += 1 break } } if sub_arl+1 &amp;lt; msub_arl { msub_arl = sub_arl + 1 } } } if msub_arl == size+1 { msub_arl = 0 } return msub_arl} func main() { fmt.Println(minSubArrayLen(15, []int{5,1,3,5,10,7,4,9,2,8}))} 34 array nesting func arrayNesting(nums []int) int { anl_arr := make([]int, len(nums)) var max_anl int for _, num := range nums { if anl_arr[num] &amp;gt; 0 { continue } var anl int next_num := num for { anl_arr[next_num] = 1 anl += 1 next_num = nums[next_num] if next_num == num { break } } if anl &amp;gt; max_anl { max_anl = anl } } return max_anl} func main() { fmt.Println(arrayNesting([]int{5,4,0,3,1,6,2}))} 35 triangle func min(a, b int) int { if a &amp;lt; b { return a } else { return b }}func minimumTotal(triangle [][]int) int { pre_nums := triangle[0] trg_size := len(triangle) for i := 1; i &amp;lt; trg_size; i += 1 { nums := triangle[i] n_size := len(nums) for j, _ := range nums { switch j { case 0: nums[0] += pre[0] case n_size - 1: nums[n_size-1] += pre_nums[n_size-2] default: nums[j] += min(pre_nums[j-1], pre_nums[j]) } } pre_nums = nums } min_total := pre_nums[0] for _, num := range pre_nums { if num &amp;lt; min_total { min_total = num } } return min_total} 36 subsets func subsets(nums []int) [][]int { if len(nums) &amp;lt; 1 { return [][]int{[]int{}} } sub_sets := subsets(nums[1:]) sets := sub_sets num := nums[0] for _, set := range sub_sets { nset := append([]int{num}, set...) sets = append(sets, nset) } return sets} 37 subsets II type Item struct { Num int Count int}func subsetsWithDup(nums []int) [][]int { num_M := make(map[int]int) for _, num := range nums { num_M[num] += 1 } items := make([]*Item, 0) for num, count := range num_M { item := &amp;amp;Item{ Num: num, Count: count, } items = append(items, item) } return subsets(items)}func subsetsHelper(item *Item, sub_sets [][]int) [][]int { sets := sub_sets for _, set := range sub_sets { var _count int for { if _count == item.Count { break } set = append([]int{item.Num}, set...) sets = append(sets, set) _count += 1 } } return sets}func subsets(items []*Item) [][]int { if len(items) &amp;lt; 1 { return [][]int{[]int{}} } return subsetsHelper(items[0], subsets(items[1:]))} 38 search in rotated sorted array func search(nums []int, target int) int { start, end := 0, len(nums)-1 for start &amp;lt;= end { mid := start + (end-start)/2 if nums[mid] == target { return mid } if start == end { break } if (nums[start] &amp;lt;= nums[mid] &amp;amp;&amp;amp; (target &amp;lt; nums[start] || nums[mid] &amp;lt; target)) || (nums[mid] &amp;lt;= nums[end] &amp;amp;&amp;amp; (target &amp;gt;= nums[mid] &amp;amp;&amp;amp; nums[end] &amp;gt;= target)) { start = mid + 1 continue } if (nums[start] &amp;lt;= nums[mid] &amp;amp;&amp;amp; (target &amp;gt;= nums[start] &amp;amp;&amp;amp; nums[mid] &amp;gt;= target)) || (nums[mid] &amp;lt;= nums[end] &amp;amp;&amp;amp; (target &amp;lt; nums[mid] || nums[end] &amp;lt; target)) { end = mid - 1 continue } } return -1} 39 search in rotated sorted array II func search(nums []int, target int) bool { start, end := 0, len(nums)-1 for start &amp;lt;= end { if nums[start] == nums[end] { if nums[start] == target { return true } dup_num := nums[start] for { if start == end || nums[start] != dup_num { break } start++ } for { if start == end || nums[end] != dup_num { break } end-- } } mid := start + (end-start)/2 if nums[mid] == target { return true } if start == end { break } if (nums[start] &amp;lt;= nums[mid] &amp;amp;&amp;amp; (target &amp;lt; nums[start] || nums[mid] &amp;lt; target)) || (nums[mid] &amp;lt;= nums[end] &amp;amp;&amp;amp; (target &amp;gt;= nums[mid] &amp;amp;&amp;amp; nums[end] &amp;gt;= target)) { start = mid + 1 continue } if (nums[start] &amp;lt;= nums[mid] &amp;amp;&amp;amp; (target &amp;gt;= nums[start] &amp;amp;&amp;amp; nums[mid] &amp;gt;= target)) || (nums[mid] &amp;lt;= nums[end] &amp;amp;&amp;amp; (target &amp;lt; nums[mid] || nums[end] &amp;lt; target)) { end = mid - 1 continue } } return false} 40 search a 2d matrix func searchMatrix(matrix [][]int, target int) bool { length := len(matrix) if length &amp;lt; 1 { return false } start, end := 0, length-1 width := len(matrix[0]) for start &amp;lt;= end { if start == end { break } mid := start + (end-start)/2 if matrix[mid][0] &amp;gt; target { end = mid - 1 } else if matrix[mid][0] &amp;lt; target { if target &amp;gt; matrix[mid][width-1] { start = mid + 1 } else { start = mid break } } else { return true } } return binary_search(matrix[start], target) != -1}func binary_search(nums []int, target int) int { start, end := 0, len(nums)-1 for start &amp;lt;= end { mid := start + (end-start)/2 if nums[mid] &amp;gt; target { end = mid - 1 } else if nums[mid] &amp;lt; target { start = mid + 1 } else { return mid } } return -1} 41 sort colors func sortColors(nums []int) { colors := make([]int, 3) for _, num := range nums { colors[num] += 1 } var base int for color, count := range colors { for count &amp;gt; 0 { nums[base] = color count-- base++ } } return} 42 set matrix zeroes func setZeroes(matrix [][]int) { length := len(matrix) if length &amp;lt; 1 { return } width := len(matrix[0]) row_M := make(map[int]bool, length) col_M := make(map[int]bool, width) for i := 0; i &amp;lt; length; i++ { for j := 0; j &amp;lt; width; j++ { if matrix[i][j] == 0 { row_M[i] = true col_M[j] = true } } } if len(row_M) &amp;gt; 0 { for row, _ := range row_M { for i := 0; i &amp;lt; width; i++ { matrix[row][i] = 0 } } } if len(col_M) &amp;gt; 0 { for col, _ := range col_M { for i := 0; i &amp;lt; length; i++ { matrix[i][col] = 0 } } } return} 43 unique paths func uniquePaths(m int, n int) int { if m &amp;lt; 2 { return m } matrix := make([][]int, 2) matrix[0] = make([]int, n) matrix[1] = make([]int, n) for i := 0; i &amp;lt; n; i++ { matrix[0][i] = 1 } matrix[1][0] = 1 pre_row := matrix[0] curr_row := matrix[1] for i := 1; i &amp;lt; m; i++ { for j := 1; j &amp;lt; n; j++ { curr_row[j] = curr_row[j-1] + pre_row[j] } pre_row, curr_row = curr_row, pre_row } return pre_row[n-1]} 44 unique paths II func uniquePathsWithObstacles(obstacleGrid [][]int) int { m := len(obstacleGrid) if m &amp;lt; 1 { return 0 } n := len(obstacleGrid[0]) if n &amp;lt; 1 { return 0 } if obstacleGrid[0][0] == 1 { return 0 } matrix := make([][]int, 2) matrix[0] = make([]int, n) matrix[1] = make([]int, n) for i := 0; i &amp;lt; n; i++ { if obstacleGrid[0][i] == 1 { break } matrix[0][i] = 1 } if m &amp;gt; 1 &amp;amp;&amp;amp; obstacleGrid[1][0] == 0 { matrix[1][0] = 1 } pre_row := matrix[0] curr_row := matrix[1] for i := 1; i &amp;lt; m; i++ { for j := 0; j &amp;lt; n; j++ { if obstacleGrid[i][j] == 0 { if j &amp;gt; 0 { curr_row[j] = curr_row[j-1] + pre_row[j] } else { curr_row[j] = pre_row[j] } } else { curr_row[j] = 0 } } pre_row, curr_row = curr_row, pre_row } return pre_row[n-1]} 45 spiral matrix func spiralOrder(matrix [][]int) []int { m := len(matrix) if m &amp;lt; 1 { return []int{} } n := len(matrix[0]) row_start := 0 row_end := m col_start := 0 col_end := n so_arr := make([]int, 0, m*n) for { for i := col_start; i &amp;lt; col_end; i++ { so_arr = append(so_arr, matrix[row_start][i]) } row_start += 1 if row_start == row_end { break } for i := row_start; i &amp;lt; row_end; i++ { so_arr = append(so_arr, matrix[i][col_end-1]) } col_end -= 1 if col_start == col_end { break } for i := col_end - 1; i &amp;gt;= col_start; i-- { so_arr = append(so_arr, matrix[row_end-1][i]) } row_end -= 1 if row_start == row_end { break } for i := row_end - 1; i &amp;gt;= row_start; i-- { so_arr = append(so_arr, matrix[i][col_start]) } col_start += 1 if col_start == col_end { break } } return so_arr} 46 spiral matrix II func generateMatrix(n int) [][]int { if n == 0 { return [][]int{} } matrix := make([][]int, n) for i := 0; i &amp;lt; n; i++ { matrix[i] = make([]int, n) } row_start := 0 row_end := n col_start := 0 col_end := n num := 1 for { for i := col_start; i &amp;lt; col_end; i++ { matrix[row_start][i] = num num += 1 } row_start += 1 if row_start == row_end { break } for i := row_start; i &amp;lt; row_end; i++ { matrix[i][col_end-1] = num num += 1 } col_end -= 1 if col_start == col_end { break } for i := col_end - 1; i &amp;gt;= col_start; i-- { matrix[row_end-1][i] = num num += 1 } row_end -= 1 if row_start == row_end { break } for i := row_end - 1; i &amp;gt;= row_start; i-- { matrix[i][col_start] = num num += 1 } col_start += 1 if col_start == col_end { break } } return matrix} 47 merge intervals func merge(intervals []Interval) []Interval { size := len(intervals) if size &amp;lt; 2 { return intervals } sort.Slice(intervals, func(i, j int) bool { return intervals[i].Start &amp;lt; intervals[j].Start }) merge_intervals := make([]Interval, 0) interval := intervals[0] for i := 1; i &amp;lt; size; i++ { if interval.End &amp;gt;= intervals[i].Start { if interval.End &amp;lt; intervals[i].End { interval.End = intervals[i].End } } else { merge_intervals = append(merge_intervals, interval) interval = intervals[i] } } if interval.Start != intervals[0].Start { merge_intervals = append(merge_intervals, interval) } if len(merge_intervals) &amp;lt; 1 { merge_intervals = append(merge_intervals, interval) } return merge_intervals} 48 jump game class Solution {public: bool canJump(vector&amp;lt;int&amp;gt;&amp;amp; nums) { if (nums.size() &amp;lt; 2) { return true; } if (nums[0]==0) { return false; } deque&amp;lt;int&amp;gt; position_deq; set&amp;lt;int&amp;gt; position_set; position_deq.push_back(0); position_set.insert(0); while (position_deq.size()&amp;gt;0) { int position = position_deq.front(); position_deq.pop_front(); if (nums[position] &amp;gt; 0) { for (int i = 1; i &amp;lt;= nums[position]; i++) { int new_position = position +i; if (new_position == nums.size()-1) { return true; } if (nums[new_position]&amp;gt;0 &amp;amp;&amp;amp; position_set.find(new_position) != position_set.end()) { position_deq.push_back(new_position); } } } } return false; }}; func canJump(nums []int) bool { size := len(nums) var i, reach int for ; i &amp;lt; size &amp;amp;&amp;amp; i &amp;lt;= reach; i++ { if i+nums[i] &amp;gt; reach { reach = i + nums[i] } } return i == size} 49 search for a range func searchRange(nums []int, target int) []int { target_index := binary_search(nums, target) if target_index == -1 { return []int{-1, -1} } start_index := target_index for { s_index := binary_search(nums[:start_index], target) if s_index == -1 { break } start_index = s_index } end_index := target_index for { e_index := binary_search(nums[end_index+1:], target) if e_index == -1 { break } end_index += 1 + e_index } return []int{start_index, end_index}}func binary_search(nums []int, target int) int { start, end := 0, len(nums)-1 for start &amp;lt;= end { mid := start + (end-start)/2 if nums[mid] &amp;gt; target { end = mid - 1 } else if nums[mid] &amp;lt; target { start = mid + 1 } else { return mid } } return -1} 50 rotate image func rotate(matrix [][]int) { if len(matrix) &amp;lt; 2 { return } size := len(matrix) for i := 0; i &amp;lt; size-1; i++ { var tmp int matrix[i][size-1], tmp = matrix[0][i], matrix[i][size-1] matrix[size-1][size-i-1], tmp = tmp, matrix[size-1][size-i-1] matrix[size-i-1][0], tmp = tmp, matrix[size-i-1][0] matrix[0][i] = tmp } if size-2 &amp;gt; 0 { sub_matrix := make([][]int, 0, size-2) for i := 1; i &amp;lt; size-1; i++ { sub_matrix = append(sub_matrix, matrix[i][1:size-1]) } rotate(sub_matrix) } return} 51 valid triangle number func triangleNumber(nums []int) int { if len(nums) &amp;lt; 3 { return 0 } sort.Ints(nums) size := len(nums) var count int for i := 0; i &amp;lt; size-2; i++ { for j := i + 1; j &amp;lt; size-1; j++ { for k := j + 1; k &amp;lt; size; k++ { if nums[i]+nums[j] &amp;lt;= nums[k] { break } count++ } } } return count} 52 TODO task scheduler func leastInterval(tasks []byte, n int) int {} 53 DONE word search State "DONE" from "TODO" [2017-07-24 Mon 00:27] struct Coord { int x; int y; char letter; int seq_num; int dir;};struct CoordComp { bool operator() (const Coord&amp;amp; lhs, const Coord&amp;amp; rhs) const { if (lhs.x&amp;lt;rhs.x) { return true; } else if (lhs.x&amp;gt;rhs.x) { return false; } else { return lhs.y&amp;lt;rhs.y; } }};class Solution {public: bool exist(vector&amp;lt;vector&amp;lt;char&amp;gt;&amp;gt;&amp;amp; board, string word) { for (int i=0; i &amp;lt; board.size(); i++) { for (int j=0; j &amp;lt; board[i].size(); j++) { if (board[i][j]==word[0]) { Coord coord={i,j,word[0],0,0}; stack&amp;lt;Coord&amp;gt; coord_stk; set&amp;lt;Coord,CoordComp&amp;gt; coord_set; coord_stk.push(coord); coord_set.insert(coord); while (coord_stk.size()&amp;gt;0) { Coord coord = coord_stk.top(); if (coord.seq_num == word.size()-1) { return true; } coord_stk.pop(); coord_set.erase(coord); int x, y; x = coord.x; y = coord.y; for (int dir=coord.dir; dir&amp;lt;4; dir++) { if (dir == 0 &amp;amp;&amp;amp; y &amp;gt; 0 &amp;amp;&amp;amp; board[x][y-1]==word[coord.seq_num+1]) { coord.dir = 1; coord_stk.push(coord); coord_set.insert(coord); Coord next_coord={x,y-1,word[coord.seq_num+1],coord.seq_num+1,0}; if (coord_set.find(next_coord) == coord_set.end()) { coord_stk.push(next_coord); coord_set.insert(next_coord); } break; } if (dir == 1 &amp;amp;&amp;amp; x &amp;gt; 0 &amp;amp;&amp;amp; board[x-1][y]==word[coord.seq_num+1]) { coord.dir = 2; coord_stk.push(coord); coord_set.insert(coord); Coord next_coord={x-1,y,word[coord.seq_num+1],coord.seq_num+1,0}; if (coord_set.find(next_coord) == coord_set.end()) { coord_stk.push(next_coord); coord_set.insert(next_coord); } break; } if (dir == 2 &amp;amp;&amp;amp; y &amp;lt; board[x].size()-1 &amp;amp;&amp;amp; board[x][y+1]==word[coord.seq_num+1]) { coord.dir = 3; coord_stk.push(coord); coord_set.insert(coord); Coord next_coord={x,y+1,word[coord.seq_num+1],coord.seq_num+1,0}; if (coord_set.find(next_coord) == coord_set.end()) { coord_stk.push(next_coord); coord_set.insert(next_coord); } break; } if (dir == 3 &amp;amp;&amp;amp; x &amp;lt; board.size()-1 &amp;amp;&amp;amp; board[x+1][y]==word[coord.seq_num+1]) { coord.dir = 4; coord_stk.push(coord); coord_set.insert(coord); Coord next_coord={x+1,y,word[coord.seq_num+1],coord.seq_num+1,0}; if (coord_set.find(next_coord) == coord_set.end()) { coord_stk.push(next_coord); coord_set.insert(next_coord); } break; } } } } } } return false; }}; 54 TODO next permutation func nextPermutation(nums []int) {} 55 TODO 4sum func fourSum(nums []int, target int) [][]int {} 56 TODO 3sum closest func threeSumClosest(nums []int, target int) int {} 57 TODO 3sum func threeSum(nums []int) [][]int {} 58 DONE Image Smoother State "DONE" from "STARTED" [2017-09-20 Wed 10:27] func imageSmoother(M [][]int) [][]int { m := len(M) n := len(M[0]) if m == 0 || n == 0 { return [][]int{} } dirs := [][]int{ []int{0, 1}, []int{0, -1}, []int{1, 0}, []int{-1, 0}, []int{-1, -1}, []int{1, 1}, []int{-1, 1}, []int{1, -1}} sM := make([][]int, m) for i := 0; i &amp;lt; m; i += 1 { ar := make([]int, n) for j := 0; j &amp;lt; n; j += 1 { sum := M[i][j] cnt := 1 for k := 0; k &amp;lt; len(dirs); k += 1 { x := i + dirs[k][0] y := j + dirs[k][1] if x &amp;lt; 0 || x &amp;gt; m-1 || y &amp;lt; 0 || y &amp;gt; n-1 { continue } sum += M[x][y] cnt++ } ar[j] = sum / cnt } sM[i] = ar } return sM} 59 DONE Longest Continuous Increasing Subsequence State "DONE" from [2017-09-20 Wed 22:35] func findLengthOfLCIS(nums []int) int { if len(nums) &amp;lt; 1 { return 0 } var length, sub_length int pre_num := nums[0] for _, num := range nums { if num &amp;gt; pre_num { sub_length += 1 } else { if sub_length &amp;gt; length { length = sub_length } sub_length = 1 } pre_num = num } if sub_length &amp;gt; length { length = sub_length } return length} 60 DONE Non-decreasing Array State "DONE" from "STARTED" [2017-09-21 Thu 09:50] func checkPossibility(nums []int) bool { var cnt int for i := 0; i &amp;lt; len(nums)-1; i += 1 { if nums[i] &amp;gt; nums[i+1] { if i == 0 || nums[i-1] &amp;lt;= nums[i+1] { nums[i] = nums[i+1] } else { nums[i+1] = nums[i] } cnt += 1 } if cnt &amp;gt; 1 { return false } } return true} 61 Find All Duplicates in an Array func findDuplicates(nums []int) []int { marks := make([]int, len(nums)) for _, num := range nums { marks[num-1] += 1 } dups_nums := make([]int, 0) for index, mark := range marks { if mark &amp;gt; 1 { dups_nums = append(dups_nums, index+1) } } return dups_nums} 62 TODO Beautiful Arrangement func countArrangement(N int) int {} 63 TODO Beautiful Arrangement II func constructArray(n int, k int) []int {} Last Updated 2017-09-21 Thu 23:14.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.1.2)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[在Org-mode中执行Go代码]]></title>
      <url>%2F2017%2F06%2F12%2Fgo-source-code-block-in-org%2F</url>
      <content type="text"><![CDATA[在未使用 org-mode 前，学习和实验Go的特性（例如 context ）的步骤如下： 打开终端 跳转到学习示例目录下 创建子目录，例如 context , 然后跳入子目录， 创建 main.go 文件 编写简单的示例代码 编译和运行代码示例,若出错调试，返回上个步骤 上面的过程有些可精简，例如在IDE中，目录跳转可在对话框中完成，代码的编写，编译和运行都可在IDE中完成。 在IDE中流程如下： 在学习示例目录下，创建一个新的示例工程 编写简单的示例代码, 编译和运行 在IDE中，整个流程精简了很多。 作为语言使用者，我们可能需要把实验过的示例代码留存，以便能应用在日后的开发中。 上面的两个流程，都会根据实验的包或者语言特性，创建相应的子目录，经过这样的处理，代码示例都聚合到了一起，方便了翻阅和修改。 示例代码的执行结果，大多是直接输出到终端的，你要验证原有示例代码的执行结果，你必须要重新执行代码，因为执行结果并没有留存。 若是这个示例代码，是很久之前的，可能是一年以前的， 这个时候你看到代码的时候，可能会时一脸懵逼。 这个时候你会想，为什么当时没有多留些信息，让我知道，为什么做这个示例，以及这段代码完成了什么功能。 Org-mode 简单配置后， 可完美的解决以上问题，代码留存，执行结果留存，文学编程（在编码过程中书写文档）。 上图展示了一个子问题的各个部分，问题描述，解决方案，代码，以及代码的执行结果。 子问题对应 Org-mode 中的子目录，然后所有问题都可聚合在一个 Org-mode 文档中。 现在流程可简化为： 跳转到 Org-mode 文档中 创建子目录，书写解决方案，编码实现 借助 Org-mode 强大的特性，可很容易的复用代码以及查询。 对于 Org-mode 不熟悉的，可先浏览Org-mode的主页。 Org-mode 通过 Babel 执行代码，对此不熟悉的读者， 可阅读我之前翻译的文档。 1 ob-go Babel 可执行多种语言的代码， 但官方的收录的语言支持中，没有Go。 但Go是如此的炙手可热，没有官方支持，肯定也会有先行者实现支持。 感谢 pope 在 ob-C 实现了ob-go , 实现了 Babel 对于Go的支持。 1.1 简介 ob-go 使 Org-babel 可执行Go代码。 与解释语言可直接执行不同，Go需要先编译为可执行文件，然后运行。 Go代码通过 go run 命令编译和运行。 若代码中没有 main 函数，默认情况下，代码会被包裹在简单的 main 函数中。 若 :package 选项没设置并且代码中没有声明 package ， 则 main package 被声明。 示例如下，代码被执行，执行结果被回写到 buffer 中。 #+BEGIN_SRC go :imports "fmt" fmt.Println("Hello, org-mode") #+END_SRC #+RESULTS: : Hello, org-mode 使用快捷键 C-c C-v v 可查看被扩展后的代码。 1.2 Go特定的头参数(Header Arguments) 除了 Babel 的常规头参数之外，下面是一些Go语言特定的头文件。 :args传递命令行参数到代码编译后的可执行文件，传递超过多参数，需要使用 list 。 :flags传递给 go run 或者 go build 的flags(未使用成功)。 :main若没设置 no ， 代码将会被包裹在 main 函数中。默认 yes 。 :imports为代码提供 imports 的快捷支持。 当处理 main 函数时，应该使用这个选项。 要 import 多个包，请使用 list 。 :package设置当前代码块 tangle 时的包名。 需要： :main no 。 若没设置，同时代码中没有包名声明， main 包将被声明。 :varob-go 支持 Babel 的变量，不过目前还不完备。 2 配置 这里假设Go的开发环境已经配置完毕，同时你的机器上的 Emacs 和 Org-mode 都是最近的版本，对于 Babel 都是完整支持的。 由于 ob-go 没有并入 Org-mode 所以需要单独配置。 步骤如下： M-x find-library ob-C , 找到的目录 org-plus-contrib 新建 ob-go.el , 然后把 github中代码 复制到新建的文件中 配置 org-babel-load-languages, 如下： (org-babel-do-load-languages&#10; &#39;org-babel-load-languages&#10; &#39;((python . t)&#10; (C . t)&#10; (go . t)&#10; (emacs-lisp . t)&#10; (shell . t))) 3 编码流程 最近在 LeetCode 上做编程训练，这里就以解决上面的问题的流程来做说明。 在LeetCode页面上，仔细阅读和理解问题，这里以 Merge Two Binary Trees 为例 跳转到 leetcode.org ， 创建 merge two binary trees 子目录 创建名为 merge-two-bt 的Go代码块 通过快捷键 C-c ' 打开Go语言特定的编辑模式buffer中,然后编码。 在编码过程完成后， C-c ' 完成并关闭编辑buffer；或者对自己编辑不满意， C-c C-k 取消编辑并关闭编辑buffer。 把定义好的代码块整合到一起，然后执行(完整代码)。 4 使用示例 4.1 导入多个包 #+BEGIN_SRC go :imports '("fmt" "time") fmt.Println("当前时间：", time.Now()) #+END_SRC #+RESULTS: : 当前时间： 2017-06-12 18:04:20.562355811 +0800 CST 4.2 命令行参数传递 #+BEGIN_SRC go :imports '("fmt" "os") :args '("bable" "golang") fmt.Println(os.Args[1], os.Args[2]) #+END_SRC #+RESULTS: : bable golang 4.3 多入参 #+NAME: sum #+BEGIN_SRC go :imports "fmt" :var a=12 b=13 fmt.Println(a+b) #+END_SRC #+RESULTS: : 25 #+call: sum(a=22,b=23) #+RESULTS: : 45 4.4 代码组织 #+NAME: min #+BEGIN_SRC go func min(a, b int) int { if a &gt; b { return b } else { return a } } #+END_SRC #+NAME: get-min #+BEGIN_SRC go :var a=0 b=0 :imports "fmt" :noweb strip-export &lt;&lt;min&gt;&gt; func main() { fmt.Println(min(a,b)) } #+END_SRC #+call: get-min(27, 23) #+RESULTS: : 23 5 总结 Org-mode于我来说，就是一个神器，打破了我对一个编辑器的认知，打破了我对一个信息收集器的认知。 Org-mode依托于强大的 Emacs, 借助于 Babel, 使文档和代码无缝的结合在了一起, 一会编码，一会记录， 一会调试，一会执行。 不失为，学习语言，尝试新工具的不二神器。 再来一段Go代码: #+BEGIN_SRC go :imports "fmt" fmt.Println("Goodbye, Gopher!") #+END_SRC Last Updated 2017-08-30 Wed 23:02.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Go的测试覆盖率]]></title>
      <url>%2F2017%2F05%2F24%2Fgo-cover-story%2F</url>
      <content type="text"><![CDATA[测试覆盖率是一个术语，用于统计通过运行程序包的测试多少代码得到执行。 如果执行测试套件导致80％的语句得到了运行，则测试覆盖率为80％。 计算测试覆盖率的通常方法是埋点二进制可执行文件。 例如，GNU gcov 在二进制文件中设置执行分支断点。 当每个分支执行时，断点被清除，并且分支的目标语句被标记为“被覆盖”。 这种方法是成功和广泛使用的。 Go的早期测试覆盖工具甚至以相同的方式工作。但它有问题。 由于分析二进制文件的执行是很困难的，所以很难实现。 它还需要将执行跟踪绑定回源代码的可靠方法，这也可能是困难的。 那里的问题包括不正确的调试信息和诸如内联功能的问题, 使分析变得复杂。 最重要的是，这种方法非常不具有可移植性。 对于每个机器架构需要重新编写，在某种程度上,可能对于每个操作系统都需要重新编写，因为从系统到系统的调试支持差异很大。 Go 1.2 的发布引入了一个 test coverage 的新工具， 它采用了一种不寻常的方式来生成覆盖率统计数据，这种方法建立在Godoc的技术的基础上。 1 Go的测试覆盖率 对于Go的新测试覆盖工具，采取了一种避免动态调试的不同方法。 想法很简单：在编译之前重写包的源代码，以埋点，编译和运行修改的源，并转储统计信息。 重写很容易编排，因为 go的工具链 控制从源到测试到执行的整个流程。 示例代码如下： func Size(a int) string { switch { case a &amp;lt; 0: return "negative" case a == 0: return "zero" case a &amp;lt; 10: return "small" case a &amp;lt; 100: return "big" case a &amp;lt; 1000: return "huge" } return "enormous"} 测试代码如下： type Test struct { in int out string}var tests = []Test{ {-1, "negative"}, {5, "small"},}func TestSize(t *testing.T) { for i, test := range tests { size := Size(test.in) if size != test.out { t.Errorf("#%d: Size(%d)=%s; want %s", i, test.in, size, test.out) } }} 执行代码覆盖率测试如下： cd ../src/cover/size/go test -covercd - PASS coverage: 42.9% of statements ok _/home/parallels/program/org/github-pages/source/src/cover/size 0.001s /home/parallels/program/org/github-pages/source/_posts 启用测试覆盖后，/go test/ 运行 cover 工具，在编译之前重写源代码。 以下是重写后的 Size 函数： func Size(a int) string { GoCover.Count[0] = 1 switch { case a &amp;lt; 0: GoCover.Count[2] = 1 return "negative" case a == 0: GoCover.Count[3] = 1 return "zero" case a &amp;lt; 10: GoCover.Count[4] = 1 return "small" case a &amp;lt; 100: GoCover.Count[5] = 1 return "big" case a &amp;lt; 1000: GoCover.Count[6] = 1 return "huge" } GoCover.Count[1] = 1 return "enormous"} 上面示例的每个可执行部分用赋值语句进行注解，赋值语句用于在运行时做统计。 计数器与 cover 工具生成的第二个只读数据结构记录的语句的原始源位置相关联。 测试运行完成后，收集计数器，通过查看设置的数量的来计算百分比。 虽然分配注解看起来可能很昂贵，但是它被编译为单个“移动”指令。 因此，其运行时开销不大，运行典型（或更实际）测试时只增加约3％开销。 这使得把测试覆盖率作为标准开发流程的一部分是合情合理的。 2 查看结果 上面的例子的测试覆盖率很差。 为了探索具体为什么，需要 go test 写一个 coverage profile ， 这是一个保存收集的统计信息的文件，以便能详细地研究覆盖的细节。 这很容易做：使用 -coverprofile 标志来指定输出的文件： cd ../src/cover/size/go test -coverprofile=size_coverage.out 注： -coverprofile 标志自动设置 -cover 来启用覆盖率分析。 测试与以前一样运行，但结果保存在文件中。 要研究它们，需要运行 test coverage tool 。 一开始，可以要求 覆盖率 按函数分解，虽然在当前情况下没有太多意义，因为只有一个函数： cd ../src/cover/size/go tool cover -func=size_coverage.out 查看的更有趣的方式是获取 覆盖率信息注释的源代码 的HTML展示。 该显示由 -html 标志调用： cd ../src/cover/size/go tool cover -html=size_coverage.out 运行此命令时，浏览器将弹出窗口，已覆盖（绿色），未覆盖（红色）和 未埋点（灰色）。 下面是一个屏幕截图： 有了这个信息页，问题变得很明显：上面忽略了几个 case 的测试！ 可以准确地看出具体是哪一个，这样可以轻松地提高的测试覆盖率。 3 热力图 源代码级方式来测试覆盖率的一大优点在于，可以很容易用不同的方式对代码进行埋点处理。 例如，不仅可以检测是否已执行了一个语句，而且还可以查询执行了多少次。 go test 命令接受 -covermode 标志将覆盖模式设置为三种设置之一： set: 每个语句是否执行？ count: 每个语句执行了几次？ atomic: 类似于 count, 但表示的是并行程序中的精确计数 set 是默认设置，上面示例已经看到了。 只有运行并行算法需要精确的计数时，才需要进行 atomic 设置。 它使用来自 sync/atomic 包的原子操作，这可能会相当昂贵。 然而，对于大多数情况， count 模式工作正常，并且像默认设置模式一样非常快。 下面来试试一个标准包， fmt 格式化包语句执行的计数。 进行测试并写出 coverage profile ，以便能够很好地进行信息的呈现。 go test -covermode=count -coverprofile=../src/cover/count.out fmt 这比以前的例子好的测试覆盖率。 （覆盖率不受覆盖模式的影响）可以显示函数细节： go tool cover -func=../src/cover/count.out HTML输出产生了巨大的回报： go tool cover -html=../src/cover/count.out pad 函数如下所示： 注意绿色的强度是如何变化。 最明亮的绿色的代表较高的执行数; 较少灰暗的绿色代表较低的执行数。 甚至可以将鼠标悬停在语句上，以便在弹出的 tool tip 中提示实际计数。 test coverage 产生了关于函数执行的大量信息，在分析中很有用的信息。 4 基础块 你可能已经注意到，上一个示例中/ 有关于闭合大括号中间的行的计数/ 不是你所期望的那样。 这是因为一直以来 test coverage 都不是一个不精确的科学。 这里发生的很值得解释。 我们希望覆盖注解由程序中的分支划分，当二进制文件在传统方法中被调用时，它们是分开的。 不过，通过重写源代码很难做到这一点，因为分支没有明确展示在源代码中。 覆盖注解的作用是是埋点，通常由大括号来限定。 一般来说，使之工作正常是非常困难的。 所使用的算法的处理结果是闭合括号看起来像属于它配对的块，而开放大括号看起来像属于块之外。 一个更有趣的结果出现在如下的一个表达式中： f() &amp;amp;&amp;amp; g() 没有试图单独调用对f和g的调用，无论事实如何，它们总是看起来像是运行相同的次数。 公平来说，即使gcov在这里也有麻烦。 该工具使机制正确，但呈现是基于行的，因此可能会错过一些细微差别。 5 总结 这是关于 Go 1.2 test coverage 故事。 具有有趣实现的新工具不仅可以实现测试覆盖率的统计，而且易于解释，甚至可以提取 profile 信息。 测试是软件开发和的重要组成部分，/test coverage/ 为测试策略添加一个简单的标准。 走向前， test 和 cover 。 Last Updated 2017-05-25 Thu 16:59.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[数组，切片：‘append’的机制]]></title>
      <url>%2F2017%2F05%2F24%2Fgo-array-slice-string%2F</url>
      <content type="text"><![CDATA[编程语言最常见的特征之一是数组的概念。 数组看起来像简单的东西，但是在将它添加到语言中时，必须回答许多问题，例如： 固定的size，还是可变的size? size是类型的一部分吗? 多维数组看起来是什么样子的？ 空数组代表了什么含义？ 以上问题的如何解答，影响着数组在语言中的定位，仅仅是语言的特性还是其设计的核心部分。 在Go的早期发展中，在设计感觉正确之前，花了大约一年时间来决定这些问题的答案。 关键的一步是引入了 切片 ，其建立在固定大小的数组之上，并提供灵活的，可扩展的数据结构。 不过，到目前为止，Go的新手经常会在 切片 的工作方式上遇到问题， 也许是因为来自其他语言的经验使他们戴着有色眼镜来看待 切片 。 在这篇文章中，将尝试清除混淆。 将通过构建代码来解释 append 内置函数的工作原理以及为什么它如此的工作。 1 数组 数组是Go中的重要组成部分，但像建筑的基础一样，它们通常隐藏在更可见的组件之下。 这里先简要介绍一下它们，然后再继续讨论 切片 更有趣，强大和突出的特性。 数组在Go程序中不常见，因为数组的大小是其类型的一部分，这限制了其表达力。 var buffer [256]byte 该声明声明了变量 buffer ，其中包含256个字节。 缓冲区的类型包括其大小 [256]byte 。 512字节的数组将是 [512]byte , 是不同的类型。 与数组关联的数据就是这样的：一个元素数组。 显然， buffer 在内存中看起来像这样， buffer: byte byte byte ... 256 times ... byte byte byte 也就是说，变量除了保存256字节的数据之外,没有其他的。 可以使用熟悉的索引语法， buffer[0]，buffer[1]等一直到buffer[255]来访问它的元素。 （索引范围0到255涵盖256个元素） 尝试使用超出该范围的值对buffer进行索引时，会导致程序崩溃。 内置的函数 len ，它返回数组和 切片 以及其他一些数据类型的元素个数。 对于数组，len返回是很清楚明确的。 在上面的例子中， len(buffer) 返回固定值256。 Go的数组是值类型。 数组变量表示整个数组; 它不是指向第一个数组元素的指针（如C中的情况）。 这意味着，当分配或传递数组值时，将产生出其内容的副本。 （为了避免复制，可以传递一个指向数组的指针，但是这是一个指向数组的指针，而不是一个数组）。 思考数组的一种方法是将其作为一种结构体，但是使用索引而不是命名字段：fixed-size的复合值。 数组有特定的使用场景 &#x2013; 矩阵变换就是很好的例子 - 但是在Go中最常通常的用途就是用作一个 切片 的存储空间。 2 切片: slice header 切片是很容易使用，但是要很好地使用它们，必须明确了解它是什么以及它能做什么。 切片是描述与切片变量本身分开存储的数组连续部分的数据结构。 切片不是数组。 切片描述一个数组的一个片段。 给定上一节的 buffer 数组变量，可以通过对数组进行切片来创建描述元素100到150 （确切地说，包括100到149）的切片： var slice []byte = buffer[100:150] 变量 slice 具有类型 []byte ，读作 slice of bytes ， 并被初始化为数组从元素100（包括）到150（排他）的切片。 更惯用的语法，删除类型，由初始化表达式来设置类型： var slice = buffer[100:150] 在函数中可使用更短的声明形式： slice := buffer[100:150] 这个 slice 变量究竟是什么？ 这不完全是一个完整的故事， 但是现在可把切片看作一个有两个元素的小数据结构：一个长度和一个指向数组元素的指针。 你可想到，其实幕后就是如此构造： type sliceHeader struct { Length int ZerothElement *byte}slice := sliceHeader{ Length: 50, ZerothElement: &amp;amp;buffer[100],} 当然这只是一个示例。 尽管这段代码片段已表明 sliceHeader 结构对程序员是不可见的， 元素指针的类型取决于元素的类型，但这给出了机制的共同之处。 当目前为止只做了数组的切片操作，但是切片上也可作切片操作： slice2 := slice[5:10] 像以前一样，这个操作创建一个新的切片，在这种情况下，原始切片的元素5到9（包括），意味着原始阵列的元素105到109。 slice2变量的底层sliceHeader结构如下所示： slice2 := sliceHeader{ Length: 5, ZerothElement: &amp;amp;buffer[105],} 注：此 header 仍然指向相同的底层数组，存储在 buffer 变量中。 也可以二次切片，也就是说切片并将结果存储回原来的切片结构。 slice = slice[5:10] 经过上面的二次切片，slice变量的sliceHeader结构与slice2变量的一样。 可能会经常看到二次切片，例如截断切片。 此语句删除了我们的切片的第一个和最后一个元素： slice = slice[1:len(slice)-1] 经过上面的而且切片后， sliceHeader 如下所示： slice := sliceHeader{ Length: 3, ZerothElement: &amp;amp;buffer[104],} 你会经常听到有经验的Go程序员谈论 slice header ，因为它真的是存储在切片变量中。 例如，当你调用将切片作为参数的函数（如bytes.IndexRune）时，该 header 就是传递给该函数的参数。 在下面调用中， slice 是入参，但事实上却是 slice header 。 slashPos := bytes.IndexRune(slice, '/') 在 slice header 中还有一个数据项，会在下面讨论，但首先看看当你使用 slice 编程时， slice header 的存在意味着什么。 3 切片作为函数的入参 很重要的一点，一个slice包含一个指针，但它本身就是一个值。 是一个保存指针和长度的结构体的值, 不是指向结构体的指针。 当在前面的例子中调用 IndexRune 时，传递了一个 slice header 的副本。 这样的方式有重要的副作用。 思考下面这个简单的函数： func AddOneToEachElement(slice []byte) { for i := range slice { slice[i]++ }} 迭代一个切片的索引（使用范围循环），增加其元素。 调用如下： func main() { var buffer [256]byte slice := buffer[10:20] for i := 0; i &amp;lt; len(slice); i++ { slice[i] = byte(i) } fmt.Println("before", slice) AddOneToEachElement(slice) fmt.Println("after", slice)} 即使 slice header 通过值传递， header 包含指向数组元素的指针，因此原始 header 和传递给该函数的标题的副本都描述相同的数组。 因此，当函数返回时，可以通过原始 slice 变量看到被修改的元素。 slice header 真的只是传递了副本，如下所示： func SubtractOneFromLength(slice []byte) []byte { slice = slice[0 : len(slice)-1] return slice}func main() { var buffer [256]byte slice := buffer[10:20] fmt.Println("Before: len(slice) =", len(slice)) newSlice := SubtractOneFromLength(slice) fmt.Println("After: len(slice) =", len(slice)) fmt.Println("After: len(newSlice) =", len(newSlice))} 这里看到一个slice参数的内容可以被一个函数修改，但是它的 header 不能。 存储在 slice 变量中的长度不会通过对函数的调用进行修改，因为函数传递了 slice header 的副本，而不是原始的变量。 因此，如果要编写一个修改 header 的函数，那么必须将其作为结果参数返回，就像上面所做的那样。 slice 变量不变，但返回的值具有新的长度，然后将其存储在 newSlice 中。 4 切片指针：Method receivers 另外一个通过函数调用修改 slice header 的方式时传递 header 的指针。下面上买示例的一个变种： func PtrSubtractOneFromLength(slicePtr *[]byte) { slice := *slicePtr *slicePtr = slice[0 : len(slice)-1]}func main() { var buffer [256]byte slice := buffer[10:20] fmt.Println("Before: len(slice) =", len(slice)) PtrSubtractOneFromLength(&amp;amp;slice) fmt.Println("After: len(slice) =", len(slice))} 这个例子看起来很笨拙，特别是处理了需要一个额外的间接引用，但这是对于指向slice的指针而言，常见的处理方式。 对于修改 slice 使用指针 receiver 是惯用的。 假设现在希望在一个切片上有一个方法，以最后的斜杠截断它。 可以这样写： type path []bytefunc (p *path) TruncateAtFinalSlash() { i := bytes.LastIndex(*p, []byte("/")) if i &amp;gt;= 0 { *p = (*p)[0:i] }}func main() { pathName := path("/usr/bin/tso") // Conversion from string to path. pathName.TruncateAtFinalSlash() fmt.Printf("%s\n", pathName)} 如果运行此示例，将看到它正常工作，更新调用者中的切片。 另一方面，如果想写一个路径的方法，在路径中的ASCII字母（忽略非英文名称）转变为大写，该方法调用者可以是一个值， 因为值 receiver 仍将指向相同的底层阵列。 type path []bytefunc (p path) ToUpper() { for i, b := range p { if 'a' &amp;lt;= b &amp;amp;&amp;amp; b &amp;lt;= 'z' { p[i] = b + 'A' - 'a' } }}func main() { pathName := path("/usr/bin/tso") pathName.ToUpper() fmt.Printf("%s\n", pathName)} 这里， ToUpper 方法在for范围构造中使用两个变量来捕获索引和切片元素。 这种形式的循环避免了在身体中多次使用 p[i] 。 5 容量 下面函数扩展整数切片： func Extend(slice []int, element int) []int { n := len(slice) slice = slice[0 : n+1] slice[n] = element return slice} 调用如下： func main() { var iBuffer [10]int slice := iBuffer[0:0] for i := 0; i &amp;lt; 20; i++ { slice = Extend(slice, i) fmt.Println(slice) }} 观察切片怎么增长直到&#x2026; 现在是时候谈谈 slice header 的第三个字段：它的容量。 除了数组指针和长度之外，slice头还存储其容量： type sliceHeader struct { Length int Capacity int ZerothElement *byte} 容量字段记录底层数组实际有多少空间; 它是长度可以达到的最大值。 试图将切片超越其容量，将超出数组的极限，并将触发 panic 。 上面示例中 slice 初始语句如下： slice := iBuffer[0:0] 它的 header 如下所示： slice := sliceHeader{ Length: 0, Capacity: 10, ZerothElement: &amp;amp;iBuffer[0],} 容量字段等于底层数组的长度减去切片的第一个元素在数组中的索引值。如果需要查询切片的容量，请使用内置函数 cap ： if cap(slice) == len(slice) { fmt.Println("slice is full!")} 6 Make 如果想要超越其容量，那怎么办？ 不能这么做！ 根据定义，容量是增长的极限。 但是可以通过分配一个新数组，复制数据和修改切片来指向新数组来实现相同的结果。 可以使用内置函数来重新分配一个更大的数组，然后分割它，但是更简单的是使用 make 内置函数。 它分配一个新数组，并创建一个 slice header 来描述它。 make 函数有三个参数：slice的类型，它的初始长度和它的容量，容量是分配保存slice数据的数组的长度。 这个调用创建一个长度为10的片段，还有5个（15-10）的空间，你可以通过运行它看到： slice := make([]int, 10, 15)fmt.Printf("len: %d, cap: %d\n", len(slice), cap(slice)) 下面代码将 int slice 的容量加倍，但是它的长度保持不变： slice := make([]int, 10, 15)fmt.Printf("len: %d, cap: %d\n", len(slice), cap(slice))newSlice := make([]int, len(slice), 2*cap(slice))for i := range slice { newSlice[i] = slice[i]}slice = newSlicefmt.Printf("len: %d, cap: %d\n", len(slice), cap(slice)) 运行此代码之后，在另一个重新分配之前，切片有了更多的空间。 当创建切片时，长度和容量通常是一样的。 该内置函数有一个这种常见情况的缩写。 length参数默认为容量，此您可以将其设置为相同的值。 gophers := make([]Gopher, 10) gophers slice 有相同的长度和容量，都为10。 7 复制 上面的示例中，当切片的容量加倍时，需要写了一个循环来将旧数据复制到新的切片。 Go有一个内置的函数 copy ，使这更容易。 它的参数是两个切片，它将数据从右边的参数复制到左边的参数。 示例重写为使用 copy ： newSlice := make([]int, len(slice), 2*cap(slice))copy(newSlice, slice) copy 函数很智能。 它只复制它可以复制，会关注两个 slice 参数的长度。 换句话说，它复制的元素的数量是两个切片中长度的最小值。 此外，copy返回一个整数值，复制的元素数量，虽然并不总是需要检查。 当源和目的地有重叠时，/copy/ 函数也可以正确的，这意味着它可以用于在单个切片中移动项目。 以下是使用 copy 将值插入片段中间的方法。 // Insert inserts the value into the slice at the specified index,// which must be in range.// The slice must have room for the new element.func Insert(slice []int, index, value int) []int { // Grow the slice by one element. slice = slice[0 : len(slice)+1] // Use copy to move the upper part of the slice out of the way and open a hole. copy(slice[index+1:], slice[index:]) // slice[index:] &amp;#31561;&amp;#20215;&amp;#20110; slice[index:len(slice)] // Store the new value. slice[index] = value // Return the result. return slice} 上面函数有几件事要注意。 首先，当然，它必须返回更新的切片，因为它的长度已经改变。 其次，它使用方便的速记。表达式： slice[i:] 等价于： slice[i:len(slice)] 此外，虽然还没有使用技巧，但也可以省略一个切片表达式的第一个元素; 它默认为零。因此 slice[:] 仅仅代表 slice 自身， 这在切片化数组时很有用。下面表达式切片整个数组： array[:] 调用 Insert 函数如下: func main() { slice := make([]int, 10, 20) // Note capacity &amp;gt; length: room to add element. for i := range slice { slice[i] = i } fmt.Println(slice) slice = Insert(slice, 5, 99) fmt.Println(slice)} 8 Append： 示例 往前回顾下，写的一个 Extend 函数，它将一个切片扩展。 然而，它是错误的，因为如果切片的容量太小，该函数将崩溃。 （ Insert 示例有相同的问题。） 现在已经准备好了修复这些的知识，所以现在重新编写一个强大的 Extend 实现。 func Extend(slice []int, element int) []int { n := len(slice) if n == cap(slice) { // Slice is full; must grow. // We double its size and add 1, so if the size is zero we still grow. newSlice := make([]int, len(slice), 2*len(slice)+1) copy(newSlice, slice) slice = newSlice } slice = slice[0 : n+1] slice[n] = element return slice} 在上面情况下，函数返回切片尤为重要，因为当它重新分配生成的切片时，会指向一个完全不同的数组。 下面这段代码，用于说明切片填满时会发生什么： func main() { slice := make([]int, 0, 5) for i := 0; i &amp;lt; 10; i++ { slice = Extend(slice, i) fmt.Printf("len=%d cap=%d slice=%v\n", len(slice), cap(slice), slice) fmt.Println("address of 0th element:", &amp;amp;slice[0]) }} 注意当初始数组5被填满时的重新分配。 当分配新数组时，第零个元素的地址和容量都会发生变化。 以强大的Extend功能为指导，可以编写一个更好的功能，能支持多个元素来扩展切片。 为此，当调用函数时，使用Go的原生特性将函数的参数列表转换为切片。 也就是说，使用Go的可变参数列表。 函数命名为 Append 。 对于第一个版本，重复调用Extend，以使可变函数参数的机制清晰明了。 Append的签名： func Append(slice []int, items ...int) []int Append 需要一个参数，一个 slice ，后跟零个或多个 int 参数。 就 Append 的实现而言，这些参数正好是int的切片，可以看到： // Append appends the items to the slice.// First version: just loop calling Extend.func Append(slice []int, items ...int) []int { for _, item := range items { slice = Extend(slice, item) } return slice} 注意范围循环遍历items参数的元素，暗含了类型[]int。 还要注意使用空白标识符来舍弃循环中的索引，在这种情况下不需要这个索引。 Append 使用如下： func main() { slice := []int{0, 1, 2, 3, 4} fmt.Println(slice) slice = Append(slice, 5, 6, 7, 8) fmt.Println(slice)} 不仅可以 append 元素，还可以 append 另外一个切片，如下所示： slice1 := []int{0, 1, 2, 3, 4}slice2 := []int{55, 66, 77}fmt.Println(slice1)slice1 = Append(slice1, slice2...) // The '...' is essential!fmt.Println(slice1) 当然， Append 函数优化实现如下： // Append appends the elements to the slice.// Efficient version.func Append(slice []int, elements ...int) []int { n := len(slice) total := len(slice) + len(elements) if total &amp;gt; cap(slice) { // Reallocate. Grow to 1.5 times the new size, so we can still grow. newSize := total*3/2 + 1 newSlice := make([]int, total, newSize) copy(newSlice, slice) slice = newSlice } slice = slice[:total] copy(slice[n:], elements) return slice} 注意使用 copy 两次，一次将切片数据移动到新分配的内存，然后将附加的切片数据复制到旧数据的末尾。 行为和上面快速实现一样： slice1 := []int{0, 1, 2, 3, 4}slice2 := []int{55, 66, 77}fmt.Println(slice1)slice1 = Append(slice1, slice2...) // The '...' is essential!fmt.Println(slice1) 9 Append：内建函数 目前我们 get 到了 append 内置函数设计的动机了。 它完全和上面定义的/Append/ 示例的函数有同样的功能，同等效率，但它适用于任何切片类型。 Go的一个弱点是任何通用类型的操作都必须由运行时提供。 有一天可能会改变，但是现在，为了使切片更容易使用，Go提供了一个内置的通用 append 函数。 它与上面的int切片版本相同，但适用于任何切片类型。 记住，由于 slice header 总是通过调用 append 来更新，所以需要在调用后保存返回的切片。 实际上，编译器不会让你调用 append 而不保存结果。 使用示例如下： // Create a couple of starter slices.slice := []int{1, 2, 3}slice2 := []int{55, 66, 77}fmt.Println("Start slice: ", slice)fmt.Println("Start slice2:", slice2)// Add an item to a slice.slice = append(slice, 4)fmt.Println("Add one item:", slice)// Add one slice to another.slice = append(slice, slice2...)fmt.Println("Add one slice:", slice)// Make a copy of a slice (of int).slice3 := append([]int(nil), slice...)fmt.Println("Copy a slice:", slice3)// Copy a slice to the end of itself.fmt.Println("Before append to self:", slice)slice = append(slice, slice...)fmt.Println("After append to self:", slice) 请仔细考虑该例子的最后一行内容，以了解切片的设计如何使这个简单的调用成功。 10 Nil 另外，通过新学习到的知识，可以看到一个零切片的表示形式。 当然，它是 slice header 的零值： sliceHeader{ Length: 0, Capacity: 0, ZerothElement: nil,} 或者 sliceHeader{} 关键的细节之处就是元素指针为 nil 。 切片被创建 array[0:0] 长度为0，但是元素指针不为空，所以不是一个 nil 切片。 应该清楚的是，一个空切片可以增长（假设它具有非零容量），但是一个 nil 切片没有数组将数值填入，并且永远不会增长，甚至连一个元素都不能。 也就是说，/nil/ 切片在功能上等同于零长度切片，即使它没有指向。 它的长度为零，并可以附加到分配。 例如，上面示例中的一行，通过追加到一个 nil 切片来复制一个切片。 11 字符串 在切片的上下文中,这里简要介绍一下Go的字符串部分。 字符串实际上非常简单：它只是只读字节的切片，有一点源于语言的额外的语法支持。 因为它们是只读的，所以不需要容量（你也不能扩展它们），但是大多数情况下，可以像只读字节片一样对待它们。 对于初学者，可以对它们进行索引以访问单个字节 slash := "/usr/ken"[0] // yields the byte value '/'. 可以分割一个字符串来获取一个子字符串： usr := "/usr/ken"[0:4] // yields the string "/usr" 现在应该清楚了，当裁剪一个字符串时，幕后发生了什么。 也可以用正常的字节切片，并通过简单的转换创建一个字符串： str := string(slice) 反向转换也是可以的： slice := []byte(usr) 字符串下面的数组从视图中隐藏; 除了通过字符串之外，没有办法访问其内容。 这意味着当我们进行这些转换之一时，必须复制数组。 在这些转换中的任何一个之后，对字节片下面的数组的修改不会影响相应的字符串。 字符串这种切片式设计的一个重要结果是创建子字符串非常高效。 所有需要发生的事情是创建一个两个字的字符串头。 由于字符串是只读的，原始字符串和由slice操作生成的字符串可以安全地共享相同的数组。 一个历史备注：字符串的最早实现始终被分配，但是当切片被添加到语言中时， 它们提供了一个有效的字符串处理模型。 一些基准测试结果都展示出巨大的加速。 当然，还有更多的字符串知识，一个 单独的博客文章 更深入地介绍了它们。 12 总结 要了解切片是如何工作的，它有助于了解它们是如何实现的。 有一些数据结构， slice header ，即与切片变量相关联的条目， 该 header 描述了单独分配的数组的一部分。 当我们传递切片值时， header 被复制，但它指向的数组始终是共享的。 一旦了解它们如何工作，切片就变得不仅易于使用，而且功能强大而富有表现力， 特别是在 copy 和 append 内置函数的帮助下。 13 延伸阅读 在Go里面有很多关于切片的使用场景。 如前所述 Slice Tricks" Wiki page页面有很多示例。 Go Slices博客文章使用清晰的图表描述了内存布局细节。 Russ Cox的Go Data Structures文章包括对片的讨论以及Go的其他内部数据结构。 有更多的材料可用，但是了解切片的最佳方式是使用它们。 Last Updated 2017-05-27 Sat 10:38.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Go的HTTP tracing]]></title>
      <url>%2F2017%2F05%2F24%2Fgo-http-trace%2F</url>
      <content type="text"><![CDATA[在Go 1.7中，引入了 HTTP tracing ，这是在HTTP客户端请求的整个生命周期中收集细粒度信息的工具。 由 net/http/httptrace 包提供 HTTP tracing 的支持。 收集的信息可用于调试延迟问题，服务监控，编写自适应系统等。 1 HTTP事件 httptrace包提供了许多钩子，用于在HTTP往返期间收集各种事件的信息。 这些事件包括： 连接创建 连接复用 DNS 查询 将请求写入网路 读取响应 2 跟踪事件 可以通过将包含钩子函数的 *httptrace.ClientTrace 放在请求的 context.Context 中来启用 HTTP tracing 。 http.RoundTripper 通过查找 context 的 *httptrace.ClientTrace , 并调用相关的钩子函数报告内部事件。 追踪范围限于请求的 context ，用户应在 context 上下文之前放置一个 *httptrace.ClientTrace ， 然后才能启动请求。 func main() { req, _ := http.NewRequest("GET", "https://google.com", nil) trace := &amp;amp;httptrace.ClientTrace{ GotConn: func(connInfo httptrace.GotConnInfo) { fmt.Printf("Got Conn: %+v\n", connInfo) }, DNSDone: func(dnsInfo httptrace.DNSDoneInfo) { fmt.Printf("DNS Info: %+v\n", dnsInfo) }, } req = req.WithContext(httptrace.WithClientTrace(req.Context(), trace)) _, err := http.DefaultTransport.RoundTrip(req) if err != nil { log.Fatal(err) }} DNS Info: {Addrs:[{IP:192.168.83.230 Zone:}] Err:&lt;nil&gt; Coalesced:false} Got Conn: {Conn:0xc42001ce00 Reused:false WasIdle:false IdleTime:0s} 在 round trip 中，/http.DefaultTransport/ 会在事件发生时调用每个钩子。 一旦DNS查找完成，将打印DNS信息。 当与请求的主机建立连接时，它将类似地打印连接信息。 3 跟踪http.Client 跟踪机制旨在跟踪单个http.Transport.RoundTrip的生命周期中的事件。 但是，客户端可以进行多次往返，以完成HTTP请求。 例如，在URL重定向的情况下，注册的钩子将被调用多次，客户端遵循HTTP重定向，进行多个请求。 用户有职责在 http.Client 级别识别这些事件。 下面的示例使用 http.RoundTripper wrapper 来标识当前的请求。 package mainimport ( "fmt" "log" "net/http" "net/http/httptrace")// transport is an http.RoundTripper that keeps track of the in-flight// request and implements hooks to report HTTP tracing events.type transport struct { current *http.Request}// RoundTrip wraps http.DefaultTransport.RoundTrip to keep track// of the current request.func (t *transport) RoundTrip(req *http.Request) (*http.Response, error) { t.current = req return http.DefaultTransport.RoundTrip(req)}// GotConn prints whether the connection has been used previously// for the current request.func (t *transport) GotConn(info httptrace.GotConnInfo) { fmt.Printf("Connection reused for %v? %v\n", t.current.URL, info.Reused)}func main() { t := &amp;amp;transport{} req, _ := http.NewRequest("GET", "https://google.com", nil) trace := &amp;amp;httptrace.ClientTrace{ GotConn: t.GotConn, } req = req.WithContext(httptrace.WithClientTrace(req.Context(), trace)) client := &amp;amp;http.Client{Transport: t} if _, err := client.Do(req); err != nil { log.Fatal(err) }} 上面示例从 google.com 重定向到 www.google.com， 输出如下： Connection reused for https://google.com? false Connection reused for https://www.google.com.hk/?gfe_rd=cr&amp;ei=olwkWd3BAa-M8Qfjs73IBA? false net/http包中的 Transport 支持跟踪 HTTP/1 和 HTTP/2 的 request。 如果你是自定义 http.RoundTripper 实现的作者，则可以通过检查 *httptest.ClientTrace 的请求 context 来支持跟踪，并在事件发生时调用相关的钩子。 4 总结 对于那些有兴趣调试HTTP请求延迟和编写工具来进行出站流量的网络调试的人来说， HTTP tracing 是一个有价值的补充。 通过启用这个新工具，希望看到来自社区的HTTP调试，基准测试和可视化工具，如httpstat。 Last Updated 2017-05-24 Wed 00:02.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Go的竞态探测器]]></title>
      <url>%2F2017%2F05%2F23%2Fgo-race-detector%2F</url>
      <content type="text"><![CDATA[Race conditions 是最隐晦和难以捉摸的编程错误之一。 通常，在代码部署到生产之后很长时间才会发作，而且通常会导致很神秘的故障。 Go的并发机制使得编写干净并发代码变得容易，但它们并不能防止 /Race conditions/。 需要谨慎，勤勉和测试。 工具很有帮助。 Go 1.1引入竞态探测器，一个用于在Go代码中查找 Race conditions 的新工具。 它基于 C/C++ ThreadSanitizer运行库 ，此库被用于检测Google内部代码库和Chromium中的许多错误。 该技术于2012年9月与Go集成; 此后，它已经应用到了标准库中。 它现在已经成为持续建设过程的一部分，在这些过程中，它们会随着时间的推移而捕捉到产生的 Race conditions 。 1 工作原理 竞态探测器集成在go工具链中。 当设置了-race命令行标志时，编译器将使用访问内存的时间和方式的代码记录下来,用于设置所有内存访问， 而运行时库会监视对共享变量的不同步访问。 当检测到这种“racy”行为时，会打印一个警告。 由于其设计，竞态探测器只能在运行代码实际触发时才能检测到竞争条件，这意味着需要在真实的工作负载下运行启用探测器。 然而，启用竞态探测的可执行文件可能使用十倍的CPU和内存，因此始终启用探测器是不切实际的。 出于这个困境的一个办法是在启用竞态探测的情况下运行一些测试。 负载测试和集成测试是很好的候选者，因为它们往往会执行代码的并发部分。 另外的可选途径：生产工作负载环境中, 在运行的服务器池中, 部署单个启用竞态探测的实例。 2 使用 竞态探测器与Go工具链完全集成。 要启用竞态检测器的情况下,构建代码，只需将 -race 标志添加到命令行： go test -race mypkg // test the packagego run -race mysrc.go // compile and run the programgo build -race mycmd // build the commandgo install -race mypkg // install the package 3 示例 3.1 Timer.Reset 当前例子是竞态探测器发现的实际bug的简化版本。 在使用定时器, 0到1秒的随机时间间隔之后打印消息。 打印过程反复进行了五秒钟。 使用 time.AfterFunc 为第一条消息创建一个 Timer ，然后使用 Reset 方法调度下一条消息，每次都复用原有 Timer 。 func main() { runtime.GOMAXPROCS(runtime.NumCPU()) start := time.Now() var t *time.Timer t = time.AfterFunc(randomDuration(), func() { fmt.Println(time.Now().Sub(start)) t.Reset(randomDuration()) }) time.Sleep(5 * time.Second)}func randomDuration() time.Duration { return time.Duration(rand.Int63n(1e9))} 这似乎是合理的代码，但在某些情况下，它以令人惊讶的方式失败： panic: runtime error: invalid memory address or nil pointer dereference [signal 0xb code=0x1 addr=0x8 pc=0x41e38a] goroutine 4 [running]: time.stopTimer(0x8, 0x12fe6b35d9472d96) src/pkg/runtime/ztime_linux_amd64.c:35 +0x25 time.(*Timer).Reset(0x0, 0x4e5904f, 0x1) src/pkg/time/sleep.go:81 +0x42 main.func·001() race.go:14 +0xe3 created by time.goFunc src/pkg/time/sleep.go:122 +0x48 发生了什么？ 启用竞态探测器的然后在运行一次： ================== WARNING: DATA RACE Read at 0x00c420084018 by goroutine 7: main.main.func1() /tmp/babel-27165ee_/go-src-27165GUv.go:17 +0x17c Previous write at 0x00c420084018 by main goroutine: main.main() /tmp/babel-27165ee_/go-src-27165GUv.go:18 +0x17a Goroutine 7 (running) created at: time.goFunc() /home/parallels/.gvm/gos/go1.8/src/time/sleep.go:170 +0x51 ================== Found 1 data race(s) exit status 66 竞态探测器展示出问题根源：来自不同 goroutines 对变量 t 有不同步读和写。 如果初始定时器时间间隔非常小，则定时器函数可能会在主 goroutine 赋值到 t 之前触发，因此对 t.Reset 的调用发生在 nil 上。 修复这个 race condition 问题，可通过读写发生在一个 goroutine 中： func main() { runtime.GOMAXPROCS(runtime.NumCPU()) start := time.Now() reset := make(chan bool) var t *time.Timer t = time.AfterFunc(randomDuration(), func() { fmt.Println(time.Now().Sub(start)) reset &amp;lt;- true }) for time.Since(start) &amp;lt; 5*time.Second { &amp;lt;-reset t.Reset(randomDuration()) }}func randomDuration() time.Duration { return time.Duration(rand.Int63n(1e9))} 主 goroutine 完全负责设置和重置定时器 t ，通过一个新的重置 channel 传达重置定时器的信号，然后以线程安全的方式重置定时器。 最简单但不相对不那么高效的方式是避免复用timer。 3.2 ioutil.Discard ioutil包的 Discard 实现了接口 io.Writer , 但是忽略了所有写给它的数据。 可认为如 dev/null 一般：发送你需要读取而不需要存储的数据的一个地方。 它通常与 /io.Copy 一起使用，清空reader，如下所示： io.Copy(ioutil.Discard, reader) 回到2011年7月，Go团队注意到，以这种方式使用Discard效率不高：Copy功能在每次调用时内部都会分配一个 32kB 的缓冲区， 但是当与 Discard 一起使用时，缓冲区完全没必要，因为只是丢弃读取到的数据。 他们认为这种惯用的复制和丢弃不应该那么昂贵。修复此问题的方式，就是给 Writer 实现方法 ReadFrom,如下所示： writer.ReadFrom(reader) Go团队向 Discard 的底层类型添加了一个ReadFrom方法，该类型具有内部缓冲区，该缓冲区在其所有用户之间共享。 var blackHole [4096]byte // shared bufferfunc (devNull) ReadFrom(r io.Reader) (n int64, err error) { readSize := 0 for { readSize, err = r.Read(blackHole[:]) n += int64(readSize) if err != nil { if err == io.EOF { return n, nil } return } }} 这次修复依旧没能解决问题，因为用户自定义的 /Reader/，可能在读的过程中，执行写操作，这个时候共享的缓冲区就造成数据污染。 type trackDigestReader struct { r io.Reader h hash.Hash}func (t trackDigestReader) Read(p []byte) (n int, err error) { n, err = t.r.Read(p) // &amp;#36825;&amp;#37324;&amp;#30340;p&amp;#23601;&amp;#26159;&amp;#20195;&amp;#34920;&amp;#30340;&amp;#23601;&amp;#26159;balckHode t.h.Write(p[:n]) return}tdr := trackDigestReader{r: file, h: sha1.New()}io.Copy(ioutil.Discard, tdr) 最终还是通过为每次使用的 ioutil.Discard 添加唯一的缓冲区，来消除共享缓冲区的 Race condition 。 4 总结 竞态探测器是检查并发程序正确性的强大工具。 它不会呈现虚假问题，所以请认真地对待。 还在等什么？现在就对你的代码运行“go test -race”吧！ Last Updated 2017-05-23 Tue 22:17.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Golang的并发模式：Context]]></title>
      <url>%2F2017%2F05%2F19%2Fgo-concurrency-patterns-context%2F</url>
      <content type="text"><![CDATA[在go服务端，每个传入的 request 都在自己的 goroutine 中做后续处理。 request handlers 经常启动其他 goroutines 以访问后端，如数据库和rpc服务。 服务于 request 的一组常用典型的 goroutines 访问特定的请求值，例如最终用户的身份，授权令牌和请求的截止日期。 当 request 被取消或触发超时时，在该 request 上工作的所有 goroutine 应该快速退出，以便系统可以回收所使用的任何资源。 在google内部，开发了一个 context 包，可以轻松地跨越api边界,传递请求范围值，取消信号和截止日期到 request 所涉及的所有 goroutine 。 该包是开源的被称作 context。 本文介绍了如何使用该包并提供了一个完整的工作示例。 1 context context 包的核心就是 context 类型(这里的描述是精简的，详情可见godoc)： // a context carries a deadline, cancelation signal, and request-scoped values// across api boundaries. its methods are safe for simultaneous use by multiple// goroutines.type Context interface { // done returns a channel that is closed when this context is canceled // or times out. Done() &amp;lt;-chan struct{} // err indicates why this context was canceled, after the done channel // is closed. Err() error // deadline returns the time when this context will be canceled, if any. Deadline() (deadline time.time, ok bool) // value returns the value associated with key or nil if none. Value(key interface{}) interface{}} Done 方法返回一个 channel ，用于发送取消信号(代表 Context 已关闭)到运行时函数：当 channel 关闭时，函数应该放弃后续流程并返回。 Err 方法返回一个错误，指出为什么 context 被取消。 管道和取消文章更详细地讨论了 done channel 的惯用法。 由于 Done channel 只接收的原因，/Context/ 没有取消方法：接收取消信号的函数通常不应当具备发送信号的功能。 特别是，当父操作启动子操作的 goroutines 时，这些子操作不应该能够取消父操作。 相反， WithCancel 函数（如下所述）提供了一种取消新的 Context 值的方法。 Context 可以安全地同时用于多个 goroutines 。 代码可以将单个 Context 传递给任意数量的 goroutine ，并能发送取消该Context的信号到所有的关联的 goroutine 。 Deadline 方法允许功能确定是否应该开始工作; 如果剩下的时间太少，可能不值得。 代码中也可能会使用截止时间来为I/O操作设置超时。 Value 允许 Context 传送请求数据。 该数据必须能安全的同时用于多个 goroutine 。 2 Context的衍生 context/包提供了从现有 /Context 衍生出新的 Context 的函数。 这些 Context 形成一个树状的层级结构：当一个 Context 被取消时，从它衍生出的所有 Context 也被取消。 Background 是任何Context树的根; 它永远不会被取消： // Background returns an empty Context. It is never canceled, has no deadline,// and has no values. Background is typically used in main, init, and tests,// and as the top-level Context for incoming requests.func Background() Context WithCancel 和 WithTimeout 返回衍生出的 Context ，衍生出的子 Context 可早于父 Context 被取消。 与传入的 request 相关联的上下文通常在请求处理程序返回时被取消。 WithCancel 也可用于在使用多个副本时取消冗余请求。 WithTimeout 对设置后台服务器请求的最后期限很有用： // WithCancel returns a copy of parent whose Done channel is closed as soon as // parent.Done is closed or cancel is called. func WithCancel(parent Context) (ctx Context, cancel CancelFunc) // A CancelFunc cancels a Context. type CancelFunc func() // WithTimeout returns a copy of parent whose Done channel is closed as soon as // parent.Done is closed, cancel is called, or timeout elapses. The new // Context's Deadline is the sooner of now+timeout and the parent's deadline, if // any. If the timer is still running, the cancel function releases its // resources. func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)// WithDeadline returns a copy of the parent context with the deadline adjusted// to be no later than d. If the parent's deadline is already earlier than d,// WithDeadline(parent, d) is semantically equivalent to parent. The returned// context's Done channel is closed when the deadline expires, when the returned// cancel function is called, or when the parent context's Done channel is// closed, whichever happens first.//// Canceling this context releases resources associated with it, so code should// call cancel as soon as the operations running in this Context complete.func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc) WithValue 提供了一种将请求范围内的值与 Context 相关联的方法： // WithValue returns a copy of parent whose Value method returns val for key.func WithValue(parent Context, key interface{}, val interface{}) Context 注： 使用context的Value相关方法只应该用于在程序和接口中传递的和请求相关的元数据，不要用它来传递一些可选的参数； 掌握如何使用 context 包的最佳方法是通过一个真实完整的示例。 3 Context使用的简单示例 简单的示例，更容易理解 Context 各衍生函数适用的场景，而且编辑本文档使用的是 Org-mode, 在编辑的过程中，即可执行(对org-mode感兴趣的人，可在评论里联系我)。 这里的代码，来源于 context 的godoc。 3.1 WithCancel WithCancel 的示例, 演示如何使用可取消 context 来防止 goroutine 泄漏。 示例函数的结尾，由gen启动的goroutine将返回而不会发送泄漏。 package mainimport ( "context" "fmt")func main() { // gen generates integers in a separate goroutine and // sends them to the returned channel. // The callers of gen need to cancel the context once // they are done consuming generated integers not to leak // the internal goroutine started by gen. gen := func(ctx context.Context) &amp;lt;-chan int { dst := make(chan int) n := 1 go func() { for { select { case &amp;lt;-ctx.Done(): return // returning not to leak the goroutine case dst &amp;lt;- n: n++ } } }() return dst } ctx, cancel := context.WithCancel(context.Background()) defer cancel() // cancel when we are finished consuming integers for n := range gen(ctx) { fmt.Println(n) if n == 5 { break } }} 3.2 WithDeadline WithDeadline 的示例,通过一个截止日期的 Context 来告知一个阻塞的函数，一旦它到了最终期限，就放弃它的工作。 package mainimport ( "context" "fmt" "time")func main() { d := time.Now().Add(50 * time.Millisecond) ctx, cancel := context.WithDeadline(context.Background(), d) // Even though ctx will be expired, it is good practice to call its // cancelation function in any case. Failure to do so may keep the // context and its parent alive longer than necessary. defer cancel() select { case &amp;lt;-time.After(1 * time.Second): fmt.Println("overslept") case &amp;lt;-ctx.Done(): fmt.Println(ctx.Err()) }} 3.3 Withtimeount WithTimeount 的示例, 传递具有超时的 Context 以告知阻塞函数，它将在超时过后丢弃其工作。 package mainimport ( "context" "fmt" "time")func main() { // Pass a context with a timeout to tell a blocking function that it // should abandon its work after the timeout elapses. ctx, cancel := context.WithTimeout(context.Background(), 50*time.Millisecond) defer cancel() select { case &amp;lt;-time.After(1 * time.Second): fmt.Println("overslept") case &amp;lt;-ctx.Done(): fmt.Println(ctx.Err()) // prints "context deadline exceeded" }} 3.4 WithValue WithValue 的简单示例代码： package mainimport ( "context" "fmt")func main() { type favContextKey string f := func(ctx context.Context, k favContextKey) { if v := ctx.Value(k); v != nil { fmt.Println("found value:", v) return } fmt.Println("key not found:", k) } k := favContextKey("language") ctx := context.WithValue(context.Background(), k, "Go") f(ctx, k) f(ctx, favContextKey("color"))} 4 示例：Google Web Search 示例是一个HTTP服务器，通过将查询“golang”转发到 Google Web Search API 并渲染查询结果, 来处理 "/search？q=golang＆timeout=1s" 之类的URL。 timeout参数告诉服务器在该时间过去之后取消请求。 示例代码被拆分为三个包： server 提供了 main 函数和 "/search" 的处理函数。 userip 提供了从 request 提取用户ip地址和关联一个 Context 的函数。 google 提供了把搜索字段发送的 Google 的 Search 函数。 4.1 server 服务器通过为 golang 提供前几个 Google 搜索结果来处理像 "search？q=golang" 之类的请求。 它注册 /handleSearch 来处理 "search"。 处理函数创建一个名为ctx的 /Context ，并在处理程序返回时,一并被取消。 如果 request 包含超时URL参数，则超时时会自动取消上下文： func handleSearch(w http.ResponseWriter, req *http.Request) { // ctx is the Context for this handler. Calling cancel closes the // ctx.Done channel, which is the cancellation signal for requests // started by this handler. var ( ctx context.Context cancel context.CancelFunc ) timeout, err := time.ParseDuration(req.FormValue("timeout")) if err == nil { // The request has a timeout, so create a context that is // canceled automatically when the timeout expires. ctx, cancel = context.WithTimeout(context.Background(), timeout) } else { ctx, cancel = context.WithCancel(context.Background()) } defer cancel() // Cancel ctx as soon as handleSearch returns.} 处理程序从 request 中提取查询关键字，并通过调用 userip 包来提取客户端的IP地址。 后端请求需要客户端的IP地址，因此handleSearch将其附加到ctx： // Check the search query.query := req.FormValue("q")if query == "" { http.Error(w, "no query", http.StatusBadRequest) return}// Store the user IP in ctx for use by code in other packages.userIP, err := userip.FromRequest(req)if err != nil { http.Error(w, err.Error(), http.StatusBadRequest) return}ctx = userip.NewContext(ctx, userIP) 处理程序使用ctx和查询关键字调用 google.Search ： // Run the Google search and print the results.start := time.Now()results, err := google.Search(ctx, query)elapsed := time.Since(start)if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) return} 如果搜索成功，处理程序将渲染返回结果： if err := resultsTemplate.Execute(w, struct { Results google.Results Timeout, Elapsed time.Duration}{ Results: results, Timeout: timeout, Elapsed: elapsed,}); err != nil { log.Print(err) return} 4.2 userip userip包提供从请求中提取用户IP地址并将其与 Context 相关联的函数。 Context 提供了 key-value 映射的 map ，其中 key 和 value 均为 interface{} 类型。 key 类型必须支持相等性， value 必须是多个 goroutine 安全的。 userip 这样的包会隐藏 map 的细节，并提供强类型访问特定的 Context 值。 为了避免关键字冲突， userip 定义了一个不导出的类型 key ，并使用此类型的值作为 Context 的关键字： // The key type is unexported to prevent collisions with context keys defined in// other packages.type key int// userIPkey is the context key for the user IP address. Its value of zero is// arbitrary. If this package defined other context keys, they would have// different integer values.const userIPKey key = 0 FromRequest 从 http.Request 中提取一个 userIP 值： func FromRequest(req *http.Request) (net.IP, error) { ip, _, err := net.SplitHostPort(req.RemoteAddr) if err != nil { return nil, fmt.Errorf("userip: %q is not IP:port", req.RemoteAddr) } userIP := net.ParseIP(ip) if userIP == nil { return nil, fmt.Errorf("userip: %q is not IP:port", req.RemoteAddr) } return userIP, nil} NewContext返回一个带有userIP的新Context： func NewContext(ctx context.Context, userIP net.IP) context.Context { return context.WithValue(ctx, userIPKey, userIP)} FromContext 从 Context 中提取 userIP ： func FromContext(ctx context.Context) (net.IP, bool) { // ctx.Value returns nil if ctx has no value for the key; // the net.IP type assertion returns ok=false for nil. userIP, ok := ctx.Value(userIPKey).(net.IP) return userIP, ok} 4.3 google google.Search 函数向 Google Web Search API 发出HTTP请求，并解析JSON编码结果。 它接受Context参数ctx，并且在ctx.Done关闭时立即返回。 Google Web Search API请求包括搜索查询和用户IP作为查询参数： func Search(ctx context.Context, query string) (Results, error) { // Prepare the Google Search API request. req, err := http.NewRequest("GET", "https://ajax.googleapis.com/ajax/services/search/web?v=1.0", nil) if err != nil { return nil, err } q := req.URL.Query() q.Set("q", query) // If ctx is carrying the user IP address, forward it to the server. // Google APIs use the user IP to distinguish server-initiated requests // from end-user requests. if userIP, ok := userip.FromContext(ctx); ok { q.Set("userip", userIP.String()) } req.URL.RawQuery = q.Encode() // Issue the HTTP request and handle the response.} Search 使用一个辅助函数 httpDo 来发出HTTP请求, 如果在处理请求或响应时关闭 ctx.Done ，取消 httpDo 。 Search 将传递闭包给 httpDo 来处理HTTP响应： var results Resultserr = httpDo(ctx, req, func(resp *http.Response, err error) error { if err != nil { return err } defer resp.Body.Close() // Parse the JSON search result. // https://developers.google.com/web-search/docs/#fonje var data struct { ResponseData struct { Results []struct { TitleNoFormatting string URL string } } } if err := json.NewDecoder(resp.Body).Decode(&amp;amp;data); err != nil { return err } for _, res := range data.ResponseData.Results { results = append(results, Result{Title: res.TitleNoFormatting, URL: res.URL}) } return nil})// httpDo waits for the closure we provided to return, so it's safe to// read results here.return results, err httpDo 函数发起HTTP请求，并在新的 goroutine 中处理其响应。 如果在 goroutine 退出之前关闭了ctx.Done，它将取消该请求： func httpDo(ctx context.Context, req *http.Request, f func(*http.Response, error) error) error { // Run the HTTP request in a goroutine and pass the response to f. tr := &amp;amp;http.Transport{} client := &amp;amp;http.Client{Transport: tr} c := make(chan error, 1) go func() { c &amp;lt;- f(client.Do(req)) }() select { case &amp;lt;-ctx.Done(): tr.CancelRequest(req) &amp;lt;-c // Wait for f to return. return ctx.Err() case err := &amp;lt;-c: return err }} 5 适配Context到已有代码 许多服务器框架提供用于承载请求范围值的包和类型。 可以定义 Context 接口的新实现，以便使得现有的框架和期望Context参数的代码进行适配。 例如，Gorilla的 github.com/gorilla/context 包允许处理程序通过提供从HTTP请求到键值对的映射来将数据与传入的请求相关联。 在 gorilla.go 中，提供了一个 Context 实现，其 Value 方法返回与 Gorilla 包中的特定HTTP请求相关联的值。 其他软件包提供了类似于 Context 的取消支持。 例如，Tomb 提供了一种杀死方法，通过关闭死亡 channel 来发出取消信号。 Tomb还提供了等待 goroutine 退出的方法，类似于sync.WaitGroup。 在 tomb.go 中，提供一个 Context 实现，当其父 Context 被取消或提供的 Tomb 被杀死时，该 Context 被取消。 6 总结 在Google，我们要求Go程序员通过 Context 参数作为传入和传出请求之间的呼叫路径上每个函数的第一个参数。 这允许由许多不同团队开发的Go代码进行良好的互操作。 它提供对超时和取消的简单控制，并确保安全证书等关键值正确转移Go程序。 希望在 Context 上构建的服务器框架应该提供 Context 的实现，以便在它们的包之间和期望 Context 参数的包之间进行适配。 客户端库将接受来自调用代码的 Context 。 通过为请求范围的数据和取消建立通用接口， Context 使得开发人员更容易地共享用于创建可扩展服务的代码。 Last Updated 2017-05-23 Tue 15:30.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Golang的并发模式：管道和撤销]]></title>
      <url>%2F2017%2F05%2F17%2Fgo-concurrency-patterns-pipelines%2F</url>
      <content type="text"><![CDATA[Go的并发原语可轻松构建有效利用I/O和多CPU的流水线管道。本文介绍了这种管道的示例，突出描述失败时的细微之处，并介绍了优雅地处理故障的技术。 1 什么是管道？ Go没有对于管道的正式定义，它只是并发模式中的一种。 非正式的，管道就是通过 channel 连接的一系列片段，其中每个片段是一组功能相同的 goroutine 。 在每个片段， goroutine 完成如下功能： 通过 inbound channel 从上流片段接受数据 在数据上执行计算，通常产生新数据 把新数据通过 outbound channel 传到下流片段 每个片段都有任意数量的 inbound 和 outbound channel ， 当然第一个和最后一个排除在外，因为前者只有 outbound channel, 后者只有 inbound channel 。 第一片段有时称为 source 或 producer ; 最后阶段，/sink/ 或 consumer 。 从一个简单的示例管道开始，解释思路和技巧。 之后，呈现一个更加现实的例子。 2 平方数示例 当前示例，管道包含三个片段。 第一个片段 gen , 把整数数组转换成一个可取出整数的 channel 。 gen 函数启动 goroutine 发生数据到 channel ,发送完成后关闭 channel: func gen(nums ...int) &amp;lt;-chan int { out := make(chan int) go func() { for _, n := range nums { out &amp;lt;- n } close(out) }() return out} 第二个片段 sq ，从一个 channel 中接收整数，并返回一个可取出每个接收的整数的平方的 channel 。 在 inbound channel 关闭后，此片段已将所有值发送到下游，然后关闭 outbound channel : func sq(in &amp;lt;-chan int) &amp;lt;-chan int { out := make(chan int) go func() { for n := range in { out &amp;lt;- n * n } close(out) }() return out} main 函数 设置流水线并运行最后一个片段：从第二片段接收值并打印，直到 channel 关闭： func main() { // Set up the pipeline. c := gen(2, 3) out := sq(c) // Consume the output. fmt.Println(&amp;lt;-out) // 4 fmt.Println(&amp;lt;-out) // 9} 由于 sq 的 inbound channel 和 outbound channel 具有相同的类型，因此可以迭代使用任意次数。 重写 main ，使其像其他片段,循环从 inbound channel 取出数据： func main() { // Set up the pipeline and consume the output. for n := range sq(sq(gen(2, 3))) { fmt.Println(n) // 16 then 81 }} 3 扇出，扇入 多个函数从相同的 channel 读取，直到该 channel 关闭; 这被称为扇出。 这提供了在一组 worker 之间分配工作以并行化CPU使用和 I/O 的方式。 一个函数可以从多个输入接收数据，并进行数据处理，直到所有的输入 channel 多路复合到单个 channel 上，当所有输入都关闭时，复合的 channel 关闭。 这被称为扇入。 改变的管道流程, 运行两个 sq 的实例，每个实例从相同的输入 channel 读取(扇出)。 引入新的函数 merge 以演示扇入： func main() { in := gen(2, 3) // Distribute the sq work across two goroutines that both read from in. c1 := sq(in) c2 := sq(in) // Consume the merged output from c1 and c2. for n := range merge(c1, c2) { fmt.Println(n) // 4 then 9, or 9 then 4 }} merge 函数将 channel 列表转换为单个通道，为每个 inbound channel 启动一个 goroutine , 来将 inbound channel 值复制到唯一 outbound channel 。 一旦所有的输出 goroutines 都已经启动后, 再启动一个 goroutine , 待所有的 channel 发送完成后来关闭 outbound channel 。 往一个 closed channel 发送数据将会 panic ，所以要确保所有的发送都是在 channel 关闭之前完成的。 sync.WaitGroup 提供了一种简单的同步方法: func merge(cs ...&amp;lt;-chan int) &amp;lt;-chan int { var wg sync.WaitGroup out := make(chan int) // Start an output goroutine for each input channel in cs. output // copies values from c to out until c is closed, then calls wg.Done. output := func(c &amp;lt;-chan int) { for n := range c { out &amp;lt;- n } wg.Done() } wg.Add(len(cs)) for _, c := range cs { go output(c) } // Start a goroutine to close out once all the output goroutines are // done. This must start after the wg.Add call. go func() { wg.Wait() close(out) }() return out} 4 稍作停顿 管道函数有如下模式： 当所有发送操作完成时，片段关闭其 outbound channel 。 片段不断接收来自 inbound channel 的值，直到这些 channel 关闭。 该模式允许每个接收片段使用 range loop ， 以确保所有值都已成功发送到下游后退出所有 goroutine 。 但是在实际管道应用中，片段并不总是能够收到所有 inbound 值。 有时这是被设计：接收者可能只需要一个子集来进行后续处理。 更常见的情况是，由于 inbound 值显示在早期片段引入了错误，因此片段应该早早的退出。 在以上任一情况下，接收者不必等待剩余的值到达，并且我们希望较早的片段停止生成稍后片段不需要的值。 在上面的管道示例中，如果片段无法使用所有 inbound 值，则尝试发送这些值的 goroutines 将无限期地阻塞下去： func main() { in := gen(2, 3) // Distribute the sq work across two goroutines that both read from in. c1 := sq(in) c2 := sq(in) // Consume the first value from output. out := merge(c1, c2) fmt.Println(&amp;lt;-out) // 4 or 9 return // Since we didn't receive the second value from out, // one of the output goroutines is hung attempting to send it.} 这是一个资源泄漏： goroutines 消耗内存和运行时资源， goroutine 栈中的堆引用使数据不被垃圾回收。 goroutines 不被垃圾收集机制回收; 它们必须自己退出。 即使下游片段没能接收所有 inbound 值，管道的上游片段也可能需要提前退出。 执行此操作的一种方法是将 outbound channel 更改为具有缓冲区。 缓冲区可以保存固定数量的值; 如果缓冲区中有空间，则发送立即完成 ： c := make(chan int, 2) // buffer size 2c &amp;lt;- 1 // succeeds immediatelyc &amp;lt;- 2 // succeeds immediatelyc &amp;lt;- 3 // blocks until another goroutine does &amp;lt;-c and receives 1 在创建 channel 时，若是知道将要发送的数据量，缓冲区可以简化代码。 例如，可重写 gen 拷贝整数到 channel 的缓冲区中， 避免 goroutine 创建: func gen(nums ...int) &amp;lt;-chan int { out := make(chan int, len(nums)) for _, n := range nums { out &amp;lt;- n } close(out) return out} 回到管道中阻塞的 goroutine ，可以考虑为 merge 返回的 outbound channel 添加一个缓冲区： func merge(cs ...&amp;lt;-chan int) &amp;lt;-chan int { var wg sync.WaitGroup out := make(chan int, 1) // enough space for the unread inputs // ... the rest is unchanged ...} 虽然上面的代码不再阻塞，但上面的代码依赖于当前是知道将要接收到多少数据的和要往下流发送多少数据。 这样的代码不健壮，如果 gen 接收的数据多于 1 ， 或者下流只接收一部分值，那么将会永久的阻塞 ~goroutine~。 固定长度的缓存不可取，相应的在代码中需要为下流片段提供一种通用的方法，来通知上流片段它们将停止接收输入。 5 明确取消 当 main 函数决定不再从上游片段/outbound channel/ 接收数据时， 它需要告诉上流片段的 goroutine 终止发送操作。 下面的代码演示了如何通知, 通过往称为 done 的 channel 上发送值来实现。 发送两个值，因为有两个被阻止的发送者： func main() { runtime.GOMAXPROCS(runtime.NumCPU()) in := gen(2, 3) // Distribute the sq work across two goroutines that both read from in. c1 := sq(in) c2 := sq(in) // Consume the first value from output. done := make(chan struct{}, 2) out := merge(done, c1, c2) fmt.Println(&amp;lt;-out) // 4 or 9 // Tell the remaining senders we're leaving. done &amp;lt;- struct{}{} done &amp;lt;- struct{}{} fmt.Println(&amp;lt;-out) // 4 or 9 go func() { time.Sleep(2*time.Second) }() return} 发送 goroutines 使用 select 语句替换其发送操作，该语句在发送发生时或从 done 接收到值时继续进行。 done 值类型是空结构体，因为该值无关紧要：它只是接收事件，表示应该放弃后续发送。 输出 goroutine 在其 inbound channel 上继续循环，因此上游片段不被阻塞。 func merge(done &amp;lt;-chan struct{}, cs ...&amp;lt;-chan int) &amp;lt;-chan int { var wg sync.WaitGroup out := make(chan int) // Start an output goroutine for each input channel in cs. output // copies values from c to out until c is closed, then calls wg.Done. output := func(name string, c &amp;lt;-chan int) { defer func(){ fmt.Println("[goroutine ruturn][", name, "]") wg.Done() }() for n := range c { fmt.Println("[IN LOOP][BEFORE select][", name, "]") select { case out &amp;lt;- n: fmt.Println("[IN LOOP][FROM c][", name, "]") case &amp;lt;-done: fmt.Println("[IN LOOP][FROM done][", name, "]") return } } fmt.Println("[AFTER LOOP][", name, "]") } wg.Add(len(cs)) for index, c := range cs { name := fmt.Sprintf("goroutine %d", index) go output(name, c) } // Start a goroutine to close out once all the output goroutines are // done. This must start after the wg.Add call. go func() { wg.Wait() fmt.Println("[AFTER WAIT]") close(out) }() return out} 上面的方法有一个问题：每个下游接收者都需要知道潜在阻塞的上游发送者的数量， 并安排在提前返回时向这些发送者发信号。 跟踪这些计数是乏味和容易出错的。 其实我们需要一种方法来告诉未知的无限数量的 goroutine 停止往下游发送它们的值。 在 Go 中，可以通过关闭 channel 来执行此操作， 因为关闭 channel 上的接收操作都是立刻完成的，产生相应数据类型的零值。 这意味着 main 函数可以通过关闭 done channel 来解除所有发件人的阻塞。 这个关闭操作实际上是发送者的广播信号。 重新编排管道函数， 添加 done channel 的延迟关闭函数 ， 从而使 main 函数的所有返回路径都会发出信号，以使管道片段退出。 func main() { runtime.GOMAXPROCS(runtime.NumCPU()) // Set up a done channel that's shared by the whole pipeline, // and close that channel when this pipeline exits, as a signal // for all the goroutines we started to exit. done := make(chan struct{}) defer close(done) in := gen(done, 2, 3) // Distribute the sq work across two goroutines that both read from in. c1 := sq(done, in) c2 := sq(done, in) // Consume the first value from output. out := merge(done, c1, c2) fmt.Println(&amp;lt;-out) // 4 or 9 // done will be closed by the deferred call.} 现在每个管道片段可以在 channel 关闭后轻松的返回， merge 中的 output routine 不用担心 inbound channel 的数据，因为 当 done channel 关闭时，上游发送者会停止数据的发送。 output 通过 defer 语句确保在所有返回路径上调用 wg.Done : func merge(done &amp;lt;-chan struct{}, cs ...&amp;lt;-chan int) &amp;lt;-chan int { var wg sync.WaitGroup out := make(chan int) // Start an output goroutine for each input channel in cs. output // copies values from c to out until c or done is closed, then calls // wg.Done. output := func(c &amp;lt;-chan int) { defer wg.Done() for n := range c { select { case out &amp;lt;- n: case &amp;lt;-done: return } } } wg.Add(len(cs)) for _, c := range cs { go output(c) } // Start a goroutine to close out once all the output goroutines are // done. This must start after the wg.Add call. go func() { wg.Wait() close(out) }() return out} 类型的， sq 可在 done 关闭后直接返回。 sq 通过 defer 语句确保在所有返回路径上关闭 out channel ： func sq(done &amp;lt;-chan struct{}, in &amp;lt;-chan int) &amp;lt;-chan int { out := make(chan int) go func() { defer close(out) for n := range in { select { case out &amp;lt;- n * n: case &amp;lt;-done: return } } }() return out} gen 大体和 sq 类型， 在 done 返回， 通过 defer 语句确保 out channel 关闭： func gen(done &amp;lt;-chan struct{}, nums ...int) &amp;lt;-chan int { out := make(chan int) go func() { defer close(out) for _, n := range nums { select { case out &amp;lt;- n: case &amp;lt;-done: return } } }() return out} 管道构建的指导方针： 当所有发送操作完成时，片段关闭其 outbound channel 。 片段持续从 inbound channel 中接收值，直到这些 channel 关闭或发件人被取消阻塞。 管道有两种方式能解除发送者的阻塞： 确保所有发送的值都有足够的缓冲区, 有足够的缓冲区就不会阻塞了。 当接收方放弃从 channel 接收数据时，显式地发送信号来解除发送者的阻塞 6 MD5摘要示例 现在来看看更真实的管道应用。 MD5 是一种消息摘要算法，可用作文件校验和。 命令行实用程序 md5sum 打印文件列表的摘要值。 % md5sum *.go d47c2bbc28298ca9befdfbc5d3aa4e65 bounded.go ee869afd31f83cbb2d10ee81b2b831dc parallel.go b88175e65fdcbc01ac08aaf1fd9b5e96 serial.go 示例程序像 md5sum ，但是以单个目录作为参数，并打印该目录下每个常规文件的摘要值，并按路径名排序。 % go run serial.go . d47c2bbc28298ca9befdfbc5d3aa4e65 bounded.go ee869afd31f83cbb2d10ee81b2b831dc parallel.go b88175e65fdcbc01ac08aaf1fd9b5e96 serial.go 示例程序的 main 函数 调用一个辅助函数 MD5All ，它返回一个从路径名到摘要值的 map ，然后排序并打印结果： func main() { // Calculate the MD5 sum of all files under the specified directory, // then print the results sorted by path name. m, err := MD5All(os.Args[1]) if err != nil { fmt.Println(err) return } var paths []string for path := range m { paths = append(paths, path) } sort.Strings(paths) for _, path := range paths { fmt.Printf("%x %s\n", m[path], path) }} 6.1 串行版 MD5All 函数是讨论的焦点。 在 serial.go 中的实现不使用并发性，只是在遍历文件树时读取和计算校验和。 // MD5All reads all the files in the file tree rooted at root and returns a map// from file path to the MD5 sum of the file's contents. If the directory walk// fails or any read operation fails, MD5All returns an error.func MD5All(root string) (map[string][md5.Size]byte, error) { m := make(map[string][md5.Size]byte) err := filepath.Walk(root, func(path string, info os.FileInfo, err error) error { if err != nil { return err } if !info.Mode().IsRegular() { return nil } data, err := ioutil.ReadFile(path) if err != nil { return err } m[path] = md5.Sum(data) return nil }) if err != nil { return nil, err } return m, nil} 6.2 并行版 在 parallel.go ，将 MD5All 函数分为两级管道。 第一级， sumFiles ，遍历树， 为每个文件做校验和创建 goroutine , 并将结果发送到 result 类型的 channel 上： type result struct { path string sum [md5.Size]byte err error} sumFiles 返回两个 channel ：一个用于传递结果，另一个用于返回 filepath.Walk 返回的错误。 walk 函数启动一个新的 goroutine 来处理每个常规文件，然后检查 done 。 如果完成关闭， walk 将立即停止： func sumFiles(done &amp;lt;-chan struct{}, root string) (&amp;lt;-chan result, &amp;lt;-chan error) { // For each regular file, start a goroutine that sums the file and sends // the result on c. Send the result of the walk on errc. c := make(chan result) errc := make(chan error, 1) go func() { var wg sync.WaitGroup err := filepath.Walk(root, func(path string, info os.FileInfo, err error) error { if err != nil { return err } if !info.Mode().IsRegular() { return nil } wg.Add(1) go func() { data, err := ioutil.ReadFile(path) select { case c &amp;lt;- result{path, md5.Sum(data), err}: case &amp;lt;-done: } wg.Done() }() // Abort the walk if done is closed. select { case &amp;lt;-done: return errors.New("walk canceled") default: return nil } }) // Walk has returned, so all calls to wg.Add are done. Start a // goroutine to close c once all the sends are done. go func() { wg.Wait() close(c) }() // No select needed here, since errc is buffered. errc &amp;lt;- err }() return c, errc} MD5All 从 channel 中接受摘要值，返回最早出现的错误，并通过 defer 来关闭 done ： func MD5All(root string) (map[string][md5.Size]byte, error) { // MD5All closes the done channel when it returns; it may do so before // receiving all the values from c and errc. done := make(chan struct{}) defer close(done) c, errc := sumFiles(done, root) m := make(map[string][md5.Size]byte) for r := range c { if r.err != nil { return nil, r.err } m[r.path] = r.sum } if err := &amp;lt;-errc; err != nil { return nil, err } return m, nil} 6.3 受限的并行 在 parallel.go 的 MD5All 实现中为每个文件创建一个 goroutine 。 试想一下，若是一个目录中有许多大文件，上面的实现，很可能导致资源枯竭。 可以通过限制同时打开的问题个数来解决资源占用的问题。在 bounded.go 中， 创建固定数量的用于读取文件的 goroutine 。 重新设计流程，包含三个片段： 遍历目录树， 读取文件生成摘要，收集摘要。 第一个片段 walkFiles , 过滤出常规文件路径，同时往下游发送： func walkFiles(done &amp;lt;-chan struct{}, root string) (&amp;lt;-chan string, &amp;lt;-chan error) { paths := make(chan string) errc := make(chan error, 1) go func() { // Close the paths channel after Walk returns. defer close(paths) // No select needed for this send, since errc is buffered. errc &amp;lt;- filepath.Walk(root, func(path string, info os.FileInfo, err error) error { if err != nil { return err } if !info.Mode().IsRegular() { return nil } select { case paths &amp;lt;- path: case &amp;lt;-done: return errors.New("walk canceled") } return nil }) }() return paths, errc} 中间片段启动固定数量的 digester goroutine 从 paths channel 中接受文件名， 通过 c channel 来回写摘要值： func digester(done &amp;lt;-chan struct{}, paths &amp;lt;-chan string, c chan&amp;lt;- result) { for path := range paths { data, err := ioutil.ReadFile(path) select { case c &amp;lt;- result{path, md5.Sum(data), err}: case &amp;lt;-done: return } }} 与以前的示例不同，/digester/ 不会关闭其输出 channel ，因为多个 goroutine 正在共享 channel 上发送。 相反，当所有的 digester 完成时，MD5All中的代码会关闭 channel ： // MD5All reads all the files in the file tree rooted at root and returns a map// from file path to the MD5 sum of the file's contents. If the directory walk// fails or any read operation fails, MD5All returns an error. In that case,// MD5All does not wait for inflight read operations to complete.func MD5All(root string) (map[string][md5.Size]byte, error) { // MD5All closes the done channel when it returns; it may do so before // receiving all the values from c and errc. done := make(chan struct{}) defer close(done) paths, errc := walkFiles(done, root) // Start a fixed number of goroutines to read and digest files. c := make(chan result) // HLc var wg sync.WaitGroup const numDigesters = 20 wg.Add(numDigesters) for i := 0; i &amp;lt; numDigesters; i++ { go func() { digester(done, paths, c) // HLc wg.Done() }() } go func() { wg.Wait() close(c) // HLc }() // End of pipeline. OMIT m := make(map[string][md5.Size]byte) for r := range c { if r.err != nil { return nil, r.err } m[r.path] = r.sum } // Check whether the Walk failed. if err := &amp;lt;-errc; err != nil { // HLerrc return nil, err } return m, nil} 可以让每个 digester 创建并返回自己的输出 channel ，但是后面需要额外的 goroutine 来扇入结果。 最后片段接收 c 的所有结果，然后从 errc 检查错误。 此检查不能早于从 c 中接受数据，因为在此之前， walkFiles 可能会被下游阻塞。 7 总结 本文介绍了Go中构建管道流的技术。 处理这种管道中的故障是很棘手的，因为管道中的任一片段都可能被尝试发送下游值而阻塞，并且下游片段可能也不再关心或者需要输入数据。 本文展示了如何关闭 channel 方式来向管道启动的所有 goroutines 广播“完成”信号，并且正确地定义了管道构建的准则。 Last Updated 2017-05-23 Tue 13:28.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Gopher面试中的Coding]]></title>
      <url>%2F2017%2F05%2F14%2Finterview-code%2F</url>
      <content type="text"><![CDATA[从四月份下半月开始，陆陆续续面试了几家公司，都是golang的岗位。每一次面试，侧重点都会有不同，有的会直接给过来一道试题， 然后边解题，边讲述自己的思路，然后面试官根据你的思路和你交流沟通；有的呢，让讲述自己最近做过的项目，遇到的难点， 自己怎么解决的问题思路，而无独有偶的呢，这样的面试中，都要需要展示编码能力。这篇文章就把自己最近面试中遇到的每一个编程问题， 分三步阐述出来：问题描述，解题思路，实际编程。 1 交替打印数字和字母 1.1 问题描述 使用两个 goroutine 交替打印序列，一个 goroutinue 打印数字， 另外一个goroutine打印字母， 最终效果如下 12AB34CD56EF78GH910IJ 。 1.2 解题思路 问题很简单，使用 channel 来控制打印的进度。使用两个 channel ，来分别控制数字和字母的打印序列， 数字打印完成后通过 channel 通知字母打印, 字母打印完成后通知数字打印，然后周而复始的工作。 1.3 实际编码 runtime.GOMAXPROCS(runtime.NumCPU())chan_n := make(chan bool)chan_c := make(chan bool, 1)done := make(chan struct{})go func() { for i := 1; i &amp;lt; 11; i += 2 { &amp;lt;-chan_c fmt.Print(i) fmt.Print(i + 1) chan_n &amp;lt;- true }}()go func() { char_seq := []string{"A","B","C","D","E","F","G","H","I","J","K"} for i := 0; i &amp;lt; 10; i += 2 { &amp;lt;-chan_n fmt.Print(char_seq[i]) fmt.Print(char_seq[i+1]) chan_c &amp;lt;- true } done &amp;lt;- struct{}{}}()chan_c &amp;lt;- true&amp;lt;-done 代码执行结果: 12AB34CD56EF78GH910IJ 看完上面的代码，是不是会有些疑惑，为什么 chan_c 需要缓存，而 chan_n 不需要呢? 当两个打印 goroutine 无限交替运行时，没有缓存是OK的， 但很明显上面的示例不是，打印数字的 goroutine 先退出，也就失去了 goroutine 来读取 chan_c 中的内容了， 而打印字母的goroutine就会阻塞在 chan_c &lt;- true 这里，这样就导致了死锁。 当然无缓存版也是可以，代码如下： runtime.GOMAXPROCS(runtime.NumCPU())chan_n := make(chan bool)chan_c := make(chan bool)done := make(chan struct{})go func() { for i := 1; i &amp;lt; 11; i += 2 { fmt.Print(i) fmt.Print(i + 1) chan_n &amp;lt;- true &amp;lt;-chan_c } done &amp;lt;- struct{}{}}()go func() { char_seq := []string{"A","B","C","D","E","F","G","H","I","J","K"} for i := 0; i &amp;lt; 10; i += 2 { &amp;lt;-chan_n fmt.Print(char_seq[i]) fmt.Print(char_seq[i+1]) chan_c &amp;lt;- true } done &amp;lt;- struct{}{}}()&amp;lt;-done&amp;lt;-done 2 随机抽奖 2.1 问题描述 用户随机抽奖，数据结构如下所示： // map&amp;#20013;&amp;#65292;key&amp;#20195;&amp;#34920;&amp;#21517;&amp;#31216;&amp;#65292;value&amp;#20195;&amp;#34920;&amp;#25104;&amp;#20132;&amp;#21333;&amp;#25968;var users map[string]int64 = map[string]int64{ "a": 10, "b": 6, "c": 3, "d": 12, "f": 1,} 2.2 解决思路 从map中选取随机用户，拿到这个编码问题，有点懵逼,但仔细一想，只需把关注用户的区间，转变一下数据结构即解题。 把map转成array，思考起来就简单多了，原有问题变成了从0至n-1中选取一个数字，数字对应的用户即中奖用户。 2.3 实际编码 package mainimport ( "fmt" "math/rand" "time")func GetAwardUserName(users map[string]int64) (name string) { sizeOfUsers := len(users) award_index := rand.Intn(sizeOfUsers) var index int for u_name, _ := range users { if index == award_index { name = u_name return } index += 1 } return}func main() { var users map[string]int64 = map[string]int64{ "a": 10, "b": 6, "c": 3, "d": 12, "e": 20, "f": 1, } rand.Seed(time.Now().Unix()) award_stat := make(map[string]int64) for i := 0; i &amp;lt; 1000; i += 1 { name := GetAwardUserName(users) if count, ok := award_stat[name]; ok { award_stat[name] = count + 1 } else { award_stat[name] = 1 } } for name, count := range award_stat { fmt.Printf("user: %s, award count: %d\n", name, count) } return} 代码执行结果： user: f, award count: 178 user: d, award count: 152 user: b, award count: 159 user: e, award count: 182 user: c, award count: 170 user: a, award count: 159 3 权重抽奖 3.1 问题描述 数据结构和上面一致，只是问题发生变化，需要更加用户的成单数来抽奖，用户成单越多，中奖概率越高，结构如下所示： // map&amp;#20013;&amp;#65292;key&amp;#20195;&amp;#34920;&amp;#21517;&amp;#31216;&amp;#65292;value&amp;#20195;&amp;#34920;&amp;#25104;&amp;#20132;&amp;#21333;&amp;#25968;var users map[string]int64 = map[string]int64{ "a": 10, "b": 6, "c": 3, "d": 12, "f": 1,} 3.2 解决思路 这一题是上一题的延伸，加了订单数进去，做为权重来为用户抽奖。此题和上面的问题如此的相似，可把上面的问题， 理解成所有的用户权重都相同的抽奖，而此题是权重不同的抽奖。解决此问题，依旧是把map转为数组来思考， 把各用户的权重，从前到后依次拼接到数轴上，数轴的起点到终点即时中奖区间，而随机数落到的那个用户的区间，那个用户即为中奖用户。 3.3 实际编码 package mainimport ( "fmt" "math/rand" "time")func GetAwardUserName(users map[string]int64) (name string) { type A_user struct { Name string Offset int64 Num int64 } a_user_arr := make([]*A_user, 0) var sum_num int64 for name, num := range users { a_user := &amp;amp;A_user{ Name: name, Offset: sum_num, Num: num, } a_user_arr = append(a_user_arr, a_user) sum_num += num } award_num := rand.Int63n(sum_num) for index, _ := range a_user_arr { a_user := a_user_arr[index] if a_user.Offset+a_user.Num &amp;gt; award_num { name = a_user.Name return } } return}func main() { var users map[string]int64 = map[string]int64{ "a": 10, "b": 5, "c": 15, "d": 20, "e": 10, "f": 30, } rand.Seed(time.Now().Unix()) award_stat := make(map[string]int64) for i := 0; i &amp;lt; 10000; i += 1 { name := GetAwardUserName(users) if count, ok := award_stat[name]; ok { award_stat[name] = count + 1 } else { award_stat[name] = 1 } } for name, count := range award_stat { fmt.Printf("user: %s, award count: %d\n", name, count) } return} 代码执行结果： user: c, award count: 1667 user: f, award count: 3310 user: e, award count: 1099 user: d, award count: 2276 user: b, award count: 549 user: a, award count: 1099 感谢各位的评论，让我受益匪浅，上面代码确实有太多的槽点，感谢吐槽，代码更正如下： func GetAwardUserName(users map[string]int64) (name string) { var sum_num int64 for _, num := range users { sum_num += num } award_num := rand.Int63n(sum_num) var offset_num int64 for _name, num := range a_user_arr { offset_num += num if award_num &amp;lt; offset_num { name = _name return } } return} 由于一直以为Golang的map for range 是可重入的，但现实是前后两轮遍历到的 key 的顺序居然是被随机化的， 代码示例如下： n_map := make(map[int]bool)for i := 1; i &amp;lt;= 10; i++ { n_map[i] = true}for num, _ := range n_map { fmt.Print(num)}fmt.Print("\n")for num, _ := range n_map { fmt.Print(num)} 91257103468 46810325791 由于map的不可重入性， 以及 liguoqinjim 给出的 示例代码 和 运行结果 证明了map的 for range 的伪随机性， 代码修改如下(在Playground 中可查看完整代码): func GetAwardUserName(users map[string]int64) (name string) { var sum_num int64 name_arr := make([]string, len(users)) for u_name, num := range users { sum_num += num name_arr = append(name_arr, u_name) } award_num := rand.Int63n(sum_num) var offset_num int64 for _, u_name := range name_arr { offset_num += users[u_name] if award_num &amp;lt; offset_num { name = u_name return } } return} 上面代码，对于多次调用会有性能问题，每次都要重新计算 sum_num 和创建 name_arr, 使用闭包优化实现， 代码如下(在Playground 中可查看完整代码): func GetAwardGenerator(users map[string]int64) (generator func() string) { var sum_num int64 name_arr := make([]string, len(users)) for u_name, num := range users { sum_num += num name_arr = append(name_arr, u_name) } generator = func() string { award_num := rand.Int63n(sum_num) var offset_num int64 for _, u_name := range name_arr { offset_num += users[u_name] if award_num &amp;lt; offset_num { return u_name } } // &amp;#32570;&amp;#30465;&amp;#36820;&amp;#22238;&amp;#65292;&amp;#27491;&amp;#24120;&amp;#24773;&amp;#20917;&amp;#19979;&amp;#65292;&amp;#19981;&amp;#20250;&amp;#36816;&amp;#34892;&amp;#21040;&amp;#27492;&amp;#22788; return name_arr[0] } return} 上面代码使用了闭包避免了多次抽奖时频繁的初始化， 但每次抽奖的复杂度O(n)，很明显依旧有可优化的空间，可使用二分搜索来使复杂度降到 O(log n), 代码如下： func GetAwardGenerator(users map[string]int64) (generator func() string) { var sum_num int64 name_arr := make([]string, len(users)) offset_arr := make([]int64, len(users)) var index int for u_name, num := range users { name_arr[index] = u_name offset_arr[index] = sum_num sum_num += num index += 1 } generator = func() string { award_num := rand.Int63n(sum_num) return name_arr[binary_search(offset_arr, award_num)] } return}func binary_search(nums []int64, target int64) int { start, end := 0, len(nums)-1 for start &amp;lt;= end { mid := start + (end-start)/2 if nums[mid] &amp;gt; target { end = mid - 1 } else if nums[mid] &amp;lt; target { if mid+1 == len(nums) { // &amp;#26368;&amp;#21518;&amp;#19968;&amp;#21517;&amp;#20013;&amp;#22870; return mid } if nums[mid+1] &amp;gt; target { return mid } start = mid + 1 } else { return mid } } return -1} 在已知长度的情况下，应使用 array[index]=num 而避免使用 array=append(array, num), 代码和测试如下： package mainimport ( "fmt" "time")func main() { test_len := 10000000 start := time.Now() s := make([]int, test_len, test_len) for i := 0; i &amp;lt; test_len; i++ { s = append(s, i) } fmt.Println(time.Now().Sub(start).String()) start = time.Now() s1 := make([]int, test_len) for i := 0; i &amp;lt; test_len; i++ { s1[i] = i } fmt.Println(time.Now().Sub(start).String())} 132.123121ms 27.453897ms 4 总结 问题一来自一家公司 , 侧重于语言特性；问题二三来自另外一家公司 ，侧重于解决问题的思路；本人更喜欢第二种，很有启发性。 我之后会把其他自己认为比较有趣的编程任务，整理到此篇文章中，敬请期待。 Last Updated 2017-10-18 Wed 14:50.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.1.2)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[一周回顾--2017-05-12]]></title>
      <url>%2F2017%2F05%2F14%2Fweekly-review-ending-2017-05-12%2F</url>
      <content type="text"><![CDATA[参加了 Gopher China 2017 后，感触很多，想了很多，看了很多。 毕业后的第一个五年，很快就要过去了，回首来时路，发现自己要做的还很多。 没有完备的知识体系，没有拿得出作品，除了工作中的成果外，没有任何产出。 想到这些后背一凉，是时候该梳理一下，找寻一下，拼搏一下了。 说完了，题外话，就来点真是的了，第一篇每周回顾，回顾一周自己读的文章和书籍，写的blog，在专业上的长进，对于一些东西的认识。 1 微服务 在Gopher China 2017的活动中，听到的最多就是微服务这个概念，对我来说这个概念是如此之新，又如此的激发我的好奇心。 回来之后，找各种文章来了解微服务具体是怎么样的东东的，优点是什么，有那些缺点，以及怎样实践。 把研习的文章列于此，作为技术积累，以馈日后。 实施微服务，我们需要哪些基础框架？从全局介绍了微服务，并给出了业界最近实践&#x2013; Netflix的开源框架组件, 入门扫盲的一篇不二的佳文。 Introduction to Microservices 讨论了使用微服务的好处和缺点，尽管微服务的有相当大的复杂性，但通常它都是复杂应用的理想选择 Building Microservices: Using an API Gateway应用程序的客户端如何通过 Api Gateway 与微服务进行通信 Building Microservices: Inter-Process Communication in a Microservices Architecture微服务架构中服务之间的IPC机制 Service Discovery in a Microservices Architecture微服务架构中的服务发现和服务注册 Event‑Driven Data Management for Microservices微服务架构中的事件驱动数据管理机制 Choosing a Microservices Deployment Strategy微服务的发布策略 Refactoring a Monolith into Microservices单体程序迁移到微服务的策略 微服务那么热，创业公司怎么选用实践？映兔科技在微服务中的实践 今日头条Go建千亿级微服务的实践今日头条在微服务的实践，较为全面，涵盖了方方面面 饿了么的架构设计及演进之路饿了么在架构方面的实践 企业的应用架构到底该怎么演变才能合了CEO的愿？推演一个企业级应用架构的演变之路，由小及大，由浅入深，很有深意 2 Golang 用了两年golang了，却依旧觉得没有掌握正确的姿势，所以最近也是一通研习。 理解Go Context机制由于我的目标是搭一套微服务出来，初步选定服务间的通信机制选用grpc，而grpc生成的代码中， 第一个参数都是 ctx context.Context ，所以务必要搞清楚 context 背后的原理。 grpc服务发现&amp;负载均衡grpc的服务发现和负载均衡的实现 Load Balancing in grpcgrpc中的负载平衡&#x2013;实现自己的服务发现，需要阅读此文档 grpc Health Checking Protocolgrpc的健康监测机制 3 无关技术 3.1 如何提升你的能力？给年轻程序员的几条建议 无关技术，却给出技术人该有的修为，以及怎样更好的成长，准备随后写篇读后感，写写自己接下来要怎么做。 3.2 不要自称是程序员，我十多年的 IT 职场总结 别人雇用你的目的，是让你创造价值，而不是让你编程 一位老司机的肺腑之言，值得每个初入职场的IT从业人员深思， 你对于企业的价值是什么,无非就是创造价值与节约成本，编程只是实现的一种途径，放大你的劳动成果，为公司创造更好的利润，节约了公司的成本支出，你才是有价值的。 对于此文，我也准备写篇读后感。 4 认知 无意之间翻到了 傅盛的认知三部曲 ，和我一直以来的想法不谋而合，我觉得人和人之间的差别，就是看待这个世界的角度或者视角不同，或者说对于这个世界的认知层次不同。 我一直以来最想要的一种能力就是有明锐的洞察力，能看到技术发展趋势，能看到下一个风口，但是我不能，至少目前的我不能，因为我没有那么高层次的认知。大学时期， 反复看过一个有关乔布斯采访的报道，当时乔布斯离开苹果，自己创立公司。采访中，有一个关于未来的技术发展趋势的问题，乔布斯指出自己看好 互联网 和 Web 。 这个采访发生在1995年， 当时中国互联网可能都还没，即便是大洋彼岸的美国互联网也还处于萌芽阶段，但是老乔却已精准的认知到了未来的机遇与趋势。 4.1 傅盛认知三部曲之一：所谓成长就是认知升级 人有四种认知状态: 不知道自己不知道——以为自己什么都知道，自以为是的认知状态 知道自己不知道——有敬畏之心，开始空杯心态，准备丰富自己的认知。 知道自己知道——抓住了事情的规律，提升了自己的认知。 不知道自己知道——永远保持空杯心态，认知的最高境界。 95%的人都处在第一个状态，甚至更多。这也就是为什么碌碌无为的人是大多数。 视而不见，只会失去升级的可能性。只有自我否定，保持空杯心态，一个人才有可能真正成长，实现跨越。 真正的认知需要通过行动展现，行动一旦缺失，认知容易陷入误区。 博盛总结了两个可能的误区: 以为自己知道，远远不如以为自己不知道 自以为是，是自我认知升级的死敌。 自我否定，假设自己无知，是自我认知升级的唯一路径。 以为自己认为重要和真的认为重要，往往不是一回事 有一个词叫自我迷惑。自认为觉得很重要，但根本没把它转化成真正的行动。 不行动的认知，就是伪认知。炫耀自己知道，有什么用？一个浪潮打过来，认知就没了，如同没有。真正的认知，必须知行结合。 人和人最大的差别是认知 , 但认知可以升级，你可以去拟合差别， 认知升级的三剂良药： 坚信大趋势 对外求教，不做井底之蛙 活在当下，面向未来 如果一个人，不断想学习，想了解，去反思；空杯心态，放下恐惧，不拒绝改变。认知升级，其实也就是捅破那层窗户纸。成长如是。 4.2 傅盛认知三部曲之二：管理本质就是认知管理 这个时代，管理不是执行管理，不是组织结构管理，而是你比别人更理解一件事情。管理的本质就是一种认知管理。 领导力的核心不是所谓的高情商，而是在大格局下构建对整个行业的认知体系，用大趋势做出正确的判断和聪明的决策。 在这个大的认知体系下，管理又可被细化为“信息、时间、人”三个维度：怎样利用“信息”做出正确的决定，怎样通过抓关键让“时间”更高效，怎样运用简化管理“人”。 博盛总结了“一体两翼”和“三个管理维度”，来回答以上的几个怎样的问题。 一体：构建领导者的认知体系 一个优秀的领导，必须在核心点上拥有覆盖队伍的认知体系。 本质上，就是这个人，在这个点上的认知体系，超越了一个庞大的队伍。 所谓认知体系，是在脑海里有完整的认知框架，才能做出正确的判断。 怎么建立这种认知架构？ 首先，对市场和产品的深入了解是认知体系的基础。 其次，真的要去和市场上吃过猪肉的人多聊天。 其三，切忌以听报告的方式建立认知。 两翼：认知管理的两剂良药 大的认知体系构建之后，具体问题是否有具体方法论作支撑——比如，事情太多管不过来怎么办？做了那么多总被老板批怎么办？做得辛苦不出绩效怎么办？ 对此，博盛开了两剂良药： 解药一：学会逆向思考，如果花的时间少一半，事情能否做得更好 怎么让管理变得更有效率? 本质是减少真正所谓管理的量，增加判断的量。 核心是转换思维，培养做判断的能力。而不是勤勉工作的能力。勤勉工作只是基础。 假设一下，如果只花一半时间，事情能不能做得更好？顺着这个方向想，很多事情就会不断要求去划分优先级。 解药二：战略的略是忽略，不敢忽略，本质是分不清优先级 不敢忽略，本质就是分不清优先级。怎么去建立优先级？分清优先级的前提是认知清晰。 人和人最大的区别就在于思维格局。什么是中层？什么是创始人？ 两者区别就在于：一个是迷恋具体情况，我在努力工作；一个是高低结合，我既能努力工作，又能不断花时间去反思，去判断，去拿到认知。 而且清楚知道，低的目的是高。即我的每一个执行，本质上又在建立我的认知。 三个管理维度：信息、时间、人 宏观层面，领导者要构建对行业的认知体系；那么微观层面，执行操作时，怎样才能做到更聪明的工作？怎样找到那件最重要的事？ 博盛从信息、时间、人三个维度剖析管理方法。 先说信息维度。人的本质就是一个CPU。有足够大的信息输入，足够高的反思频度，你才会有足够的信息输出，也才会产生格局，做出正确判断。 信息怎么输入？第一，深入分析对手。 第二，定期遍访行业。第三，不断招聘行业里的人。 再来说时间维度，管理上最重要的资源就是领导人时间。时间的分配，表明了一个领导者对实际情况的优先级判断。 讲完信息和时间，回到人的维度。一句话：学会通过管一个人达到管一片人的目的。 管理一个人，解决一大片。要简化对人的管理，找到关键人。其次就是简化目标。团队目标越简单，越明确，越容易达成一致。 4.3 傅盛认知三部曲之三：战略就是格局+破局 经过二十年的发展，今天，互联网已经是一个传统行业。风停了，放眼望去，到处是血海竞争，乌压压一片创业大军。勤奋依然很重要，但聪明的勤奋才是关键。这个时候，就要求我们想清楚，行业里的大风在哪里，并做出预测。 因此，你的脑海里必须有一个对于这个行业越来越清晰的认知格局脑图。哪里已经是过度竞争，哪里刚兴起却没人察觉，三四线城市网民的不同在哪，互联网与哪个行业、以哪种形式的结合会有机会等等。 我们需要在这样的大格局下，在过去积累的认知红利之上，重新构建新的认知体系，制定战略的新打法，去更大的空间，寻找新的破局点和机会。 现象即规律&#x2013;没有偶然，只有必然，所有单点都是大趋势下的必然。 美国人强调“think different”很有情怀，后来才发现，本质不是情怀，而是为了减少竞争成本。 因为美国创业者们比我们更早进入血海竞争阶段，“勤奋+努力+不要命”已经很难产生质的差别了，才逼迫他们用“更勤奋的思考”来避免高成本的竞争，从而降低失败概率。 创业必须讲究方法论，必须讲究不同情形下的不同方法。今天互联网的竞争格局，远远不是十年前的样子。我们必须think different，而think different的前提，就是要有行业格局认知，看清大趋势，在大趋势下做判断。 所谓战略，就是在这样的格局认知下，找到破局点，制定路线图，投入资源。如果不去建立这样的认知，公司很容易陷入一些误区。 战略认知的两个误区 第一个误区是：见招拆招，啥热做啥，啥熟悉做啥。 这是懒惰思考，不愿意认知升级的表现。结果就是越做越多，越做越累，越做越委屈。 如果每个单点，不是在一个大格局下的累加，以致每个单点都会遇到对手强大的竞争，很难长大。 第二个误区是：做产品的方法论依然停留在5年前，认为抓一个简单功能热点就颠覆格局。 只把一个单点做到极致就能创造奇迹的时代，真的过去了。你必须结合趋势，结合整个战略思考，把所有东西累加进去。 在看上去繁杂纷扰的信息中，不断深度思考，加大自己的认知优势，然后在熙熙攘攘的人流中找到不为人知的机会，趁着大家还不够懂，突然发起战役，全力以赴。 怎样做战略? 首先，脑海要有大格局。大格局就是对这个行业深入的、清晰的认知。我们需要花足够的时间去了解行业，去思考对手，去观察现象。在获取大量信息后，不断在脑海里做思维推演，去判断。 其次，养成格局和破局结合的思维习惯。 互联网竞争已经白热化的形势下，做战略的关键点，就在于不断加深自己的认知，找到已经存在但不为人知的那个秘密。 而且，这个秘密所能孕育的机会，要足够大；离现有领先者的区域，要足够远。核心是你能否具备超出对手的、对行业的、与众不同的认知。基于这个格局认知，为自己撕开一道突破口。 简单一句话概括——经过充分思考和认真研究后，制定清晰目标以及持续推进的路线图，这应该就是战略的全貌。 战略是在这个路线图下的势能的累加，不能累加势能的，再有效果的执行，本质都是增加成本。 回到战略，它的本质是什么？我认为，战略就是一个杠杆。它让你做的每一件事，都放大几倍，几十倍。一旦远离这个杠杆，就变成小公司创业模式。关键是，这种创业模式，又比不过真正的创业公司。 4.4 傅盛认知三部曲后记：到底什么是认知？ 一幅图来描述认知产生的过程。 认知三要素： 认知第一要素：信息输入与挖掘 认知第二要素：思维模式训练 认知第三要素：自我博弈与输出判断 Last Updated 2017-05-23 Tue 13:28.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[consul的docker环境配置]]></title>
      <url>%2F2017%2F05%2F13%2Fconsul-and-docker%2F</url>
      <content type="text"><![CDATA[构造consul的docker集群 sudo docker run -d --name=node0 consul agent -server -client=0.0.0.0 -node=node0 -bootstrap-expect=1 -bind=172.17.0.2 -data-dir=/tmp/consul -ui-dir /ui&#10;sudo docker run -d --name=node1 consul agent -node-id=$(uuidgen | awk &#39;{print tolower($0)}&#39;) -server -client=0.0.0.0 -node=node1 -bind=172.17.0.3 -join=172.17.0.2&#10;sudo docker run -d --name=node2 consul agent -node-id=$(uuidgen | awk &#39;{print tolower($0)}&#39;) -server -client=0.0.0.0 -node=node2 -bind=172.17.0.4 -join=172.17.0.2&#10;sudo docker run -d --name=node3 consul agent -node-id=$(uuidgen | awk &#39;{print tolower($0)}&#39;) -client=0.0.0.0 -node=node3 -bind=172.17.0.5 -join=172.17.0.2 参看集群状态 sudo docker exec -t node0 consul info Network Coordinates in consul curl http://172.17.0.2:8500/v1/coordinate/datacenters curl http://172.17.0.2:8500/v1/coordinate/nodes 健康检查 curl http://172.17.0.3:8500/v1/health/service/consul Last Updated 2017-06-01 Thu 13:40.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Org-mode的列视图简明教程]]></title>
      <url>%2F2017%2F04%2F14%2Forg-column-view-tutorial%2F</url>
      <content type="text"><![CDATA[原文Emacs Org's Column View, 由 Bastien Guerry 编辑，维护。本文只做学习之用。 简介：默认列视图 首先按 C-c C-x C-c 打开默认列视图, 将每个 outline item 转换成一个显示其某些属性的表格行。 只可以在列视图起作用的条目上，按 q 关闭列视图,返回到普通视图, 但可以从缓冲区中的任何位置打开列视图。 第一个标题现在是一列显示属性的可浏览列。 缓冲区的第一个突出显示的行简要地告诉你在每个列中显示什么属性。 在这个截图中，它显示： ITEM for the headline title T for the TODO keyword P for the priority cookie T for the tags 默认列仅显示 当前条目的内容（标题内容） ，/TODO/ 状态， 当前条目的优先级及其标签，稍后将看到如何添加自己的其他属性。 此默认设置由变量 org-columns-default-format 所定义的，该全局值为： #+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS Element Description %25ITEM display the item in a 25-characters-width field %TODO display the TODO state of the item %3PRIORITY display the priority in a 3-chars-width field %TAGS display the tags of the entry 自定义默认列视图 好的，现在让我们来自定义列视图。 例如，我们要更改 PRIORITY 字段和 TAGS 字段的宽度： #+COLUMNS: %25ITEM %5TODO %1PRIORITY %10TAGS TODO字段（％5TODO）现在为5个字符，而优先级和标签字段为1和10。 现在我们要更改列的标题。 例如 - 由于我们是这样的勤奋工作 - 每个项目其实就是一个 /Task/： #+COLUMNS: %25ITEM(Task) %5TODO(To-do) %1PRIORITY %10TAGS 以上还添加了一个 To-do 的别名，用于显示此条目的TODO状态。 列视图中添加其他属性 要怎么在列视图中添加其他属性呢？ 例如，我们想要添加 SCHEDULED 属性。 那么只需要重新定义全局 ＃+COLUMNS 选项，如下所示： #+COLUMNS: %30ITEM %10SCHEDULED %TODO %3PRIORITY %TAGS 刷新 Org 缓冲区来使配置生效，然后再次输入 C-c C-x C-c 。 现在列视图中显示SCHEDULED属性。 ** Exemple of outline item with a SCHEDULED property SCHEDULED: &lt;2007-10-14 dim&gt; 可用在列视图中可用属性如下所示： ITEM The content of the headline. TODO The TODO keyword of the entry. TAGS The tags defined directly in the headline. ALLTAGS All tags, including inherited ones. PRIORITY The priority of the entry, a string with a single letter. DEADLINE The deadline time string, without the angular brackets. SCHEDULED The scheduling time stamp, without the angular brackets. 以上属性都是特殊属性，但是可以定义自己的属性。 在自定义属性进行复杂的操作之前，让我们来学习如何为不同的子树使用不同的列视图。 定义子树的列视图 要定义特定条目的列视图，只需添加特殊属性 :COLUMNS: 即可： ** Top node for columns view :PROPERTIES: :COLUMNS: %25ITEM %TAGS %PRIORITY %TODO :END: 此视图将用于条目及其整个子树 - 除非其子节点有其自己的列视图。 看下面的示例: ** Top node for columns view :PROPERTIES: :COLUMNS: %25ITEM %TAGS %PRIORITY %TODO :END: *** TODO Example 1 *** TODO Example 2 *** DONE Example 3 但是，如果你突然喜欢 ％TAGS 在 ％TODO 的右边呢？ 将光标放在 ％TAGS 字段中，然后按 M-right ，它会将该字段向右移动。 如果你想让一个区域变得更宽？ 没问题。 只要去那个字段，然后按`&gt;'来扩大字段（或'&lt;'缩小它）。 如果要交互定义属性的列元素，请转到其字段并按's'。 已知道如何自定义每个条目的列视图，接下来就到自定义属性了。 为某些属性添加 summary-types 来定义一个包含自己的列视图和一些属性的新条目： ** My project :PROPERTIES: :COLUMNS: %20ITEM %9Approved(Approved?){X} %Owner %11Status %10Time_Spent{:} :END: 有点复杂，这里解说一下。 一个 :COLUMNS: 属性，定义了列视图,具体每个元素具体含义如下： Element Description %20ITEM display the item (20 characters for this field) %9Approved(Approved?){X} display the "Approved" property %Owner display the "Owner" property %11Status display the "Status" property %10TimeSpent{:} display the "Timespent" property {X} 和 {:} 具体代表了什么，有什么含义呢? 它们定了 summary-types. {X} 表示：如果所有条目的 Approved 属性都具有 [X] 值，才最终显示 [X] （否则显示 [-] 或 [ ] ）。 {:} 表示：通过把 Timespent 属性中找到的所有时间值求和，来显示总的时间支出。 一旦有了 :COLUMN: 属性定义，可以通过 C-c C-x p 交互地添加任何属性。 它将提示输入属性的名称，并根据属性（如果有）的 _ALL 关联属性或缓冲区中找到的值提供默认的可能值。 定义属性的所有可能值 定义 summary-types 类型意味着需要为某些属性设置一组有限的可能值。 例如，上面讨论的 Approved 应该只有两个可能的值： [ ] 和 [X] 。 Status 属性也是同样的：你可能只想定义一些状态， 如 "In progress" "Not started yet" "Finished"。 可以使用 _ALL 后缀来限制任何属性的允许值，如下所示： ** My project :PROPERTIES: :COLUMNS: %20ITEM %9Approved(Approved?){X} %Owner %11Status %10Time_Spent{:} :Owner_ALL: Tammy Mark Karl Lisa Don :Status_ALL: "In progress" "Not started yet" "Finished" "" :Approved_ALL: "[ ]" "[X]" :END: | Owner_ALL | only accept Tammy Mark Karl Lisa Don | | Status_ALL | only accept "In progress" "Not started yet" "Finished" | | Approved_ALL | only accept "[ ]" "[X]" | 注意：* _ALL属性是元属性，定义了如何使用属性本身的规则。 当位于列的字段中时，可以通过按 a 来定义关联属性的所有可能值： 它将提示当前的一组允许的值，你可以编辑它。 在子树中有三个条目的完整的例子 下面是一个关于列视图如何影响条目及其子树的显示的示例。 好好观察并测试它。 ** My project :PROPERTIES: :COLUMNS: %20ITEM %9Approved(Approved?){X} %Owner %11Status %10Time_Spent{:} :Owner_ALL: Tammy Mark Karl Lisa Don :Status_ALL: "In progress" "Not started yet" "Finished" "" :Approved_ALL: "[ ]" "[X]" :END: *** Item 1 :PROPERTIES: :Owner: Tammy :Time_spent: 1:45 :Status: Finished :END: *** Item 2 :PROPERTIES: :Owner: Tammy :Status: In progress :Time_spent: 0:15 :END: *** Item 3 :PROPERTIES: :Owner: Lisa :Status: Not started yet :Approved: [X] :END: 从列视图编辑属性 到现在为止还挺好。 但是，列视图的一个好处是它可以让您快速访问和编辑任何属性。 使用 v 在minibuffer中显示字段值。 使用 e 来交互地选择/编辑值。 使用 S-left/right 循环遍历字段中的允许值。 使用 a 编辑此属性的允许值。 结论： 能做的还有更多更多 好的，以上就是今天的全部了。 但是让我告诉你最后两个提示，让你进一步探索的列视图： 您可以使用列视图并循环浏览可见性。 列视图也适用于议程缓冲区。 http://orgmode.org/ http://orgmode.org/org.html#Column-view Last Updated 2017-05-23 Tue 13:28.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Org-mode表查找功能的简明教程]]></title>
      <url>%2F2017%2F04%2F09%2Forg-lookups%2F</url>
      <content type="text"><![CDATA[原文Org tutorial on table lookup functions, 由 Jarmo Hurri 编辑，维护。本文只做学习之用。 序言 Org 提供三个不同的函数，用于在表中执行搜索和数据依赖的计算。 这些函数可以用于实现数组关联，统计匹配单元格，结果排名或分组数据。 以下示例将有助于开始使用这些功能。 具有唯一键的关联数组 查找最直接的用法是将 Org 表的一部分视为关联数组：一个键可用于查找相应的值。 假设你去斯堪的纳维亚，并且想跟踪你花了多少钱在旅途中。 你决定将所有金额转换为欧元。 在行程之前，你请记下大致汇率,如下表所示: #+TBLNAME: rates | currency | abbreviation | euros | |-----------------+--------------+-------| | euro | eur | 1 | | Norwegian krone | nok | 0.14 | | Swedish krona | sek | 0.12 | | US dollar | usd | 0.77 | 接下来将使用函数 org-lookup-first 和前面的汇率表格来自动将不同货币的金额转换成欧元。 函数 org-lookup-first 的签名如下: (org-lookup-first VAL S-LIST R-LIST &amp;amp;optional PREDICATE) 假定 PREDICATE 为 nil ，在这种情况下使用默认谓词(predicate) equal ， 则该函数将在 S-LIST 中搜索 VAL 的第一个实例，并从 R-LIST 中的相应位置返回一个值。 在下表中，每笔金额分配了货币缩写; 对于相应的缩写，在汇率表格的第二列中进行查找，然后从第三列返回相应的汇率。 对于每一行只需要填充前四列; 第5列和第6列自动计算产生。 请注意，如果找不到键值，则会出现错误：在最后一行中，空键将被搜索。 | date | expense | sum | currency | rate | euros | |-------+------------------+------+----------+--------+--------| | 1.3. | flights | 324 | eur | 1 | 324 | | 4.6. | books and maps | 243 | usd | 0.77 | 187.11 | | 30.7. | rental car | 8300 | sek | 0.12 | 996. | | 2.7. | hotel | 1150 | sek | 0.12 | 138. | | 2.7. | lunch | 190 | sek | 0.12 | 22.8 | | 3.7. | fishing licenses | 1400 | nok | 0.14 | 196. | | 3.7. | gasoline | 340 | | #ERROR | #ERROR | #+TBLFM: $5='(org-lookup-first $4 '(remote(rates,@2$2..@&gt;$2)) '(remote(rates,@2$3..@&gt;$3)))::$6=$5*$3 多个匹配优先排序 教师的常见任务是从总分中分配考试成绩。 这种分级的起点是具有等级边界的表。 以下是一个这样的表，其中行按照特定等级所需的下限的递增排序。 #+TBLNAME: grade-boundaries | lower bound | grade | |-------------+-------| | 0 | F | | 10 | D | | 20 | C | | 30 | B | | 40 | A | 使用函数 org-lookup-last 和根据前面的 等级边界 表来为学生分配成绩。 函数 org-lookup-last 的签名与 org-lookup-first 的完全相同: (org-lookup-last VAL S-LIST R-LIST &#38;amp;optional PREDICATE) 函数 org-lookup-last 会搜索 S-LIST 中的最后一个匹配项，并从 R-LIST 中的相应位置返回一个值。 用于分配等级的查找思想如下:假定学生的考试成绩是33分。我们寻找学生的 marks 大于或等于下限的表中的最后一行; 在这种情况下，它是下边界的行30。学生的成绩是第二列的相应元素，在这种情况下是B. 因此，给定学生的标记数VAL，找到下限S满足 (&gt;= VAL S) 的表等级边界的第一列的最后一行。 因此，我们将使用 &gt;= 作为 PREDICATE 来执行匹配。 注意， VAL 和 S 按照它们在 org-lookup-last 的签名中的顺序被分配给谓词，其中 VAL 在 S-LIST 之前。 下表列出了从总 marks 到最终成绩的转换。 注: 文字插值 L 表示表值的字面值插入到Elisp公式中，这是必须的，因为一些值是数字，一些是符号。 | student | marks | grade | |---------+-------+-------| | X | 30 | B | | Y | 29 | C | | Z | 5 | F | | W | 55 | A | #+TBLFM: $3='(org-lookup-last $2 '(remote(grade-boundaries,@2$1..@&gt;$1)) '(remote(grade-boundaries,@2$2..@&gt;$2)) '&gt;=);L 统计匹配单元格 函数 org-lookup-all 不能在表等式中使用自己，因为它返回值列表。 但是，通过将函数与其他 elisp 函数相结合，可执行强大的查找任务。 作为一个简单的例子，计算表中缺少值的数量。 函数 org-lookup-all 的签名与其他两个查找函数的签名完全相同： (org-lookup-all VAL S-LIST R-LIST &#38;amp;optional PREDICATE) 数搜索 S-LIST 中的所有匹配项，并从 R-LIST 中的相应位置返回所有相应的值。 与org-lookup-first和org-lookup-last的情况一样，如果 R-LIST 为nil，则直接返回 S-LIST 相应匹配值。 注意使用 E 标志来保留范围内的空字段。 还要注意，在这种情况下，以真正的二维范围来进行查找，这也是可能的 | group | round 1 | round 2 | |-------+---------+---------| | A | | 2.4 | | B | 4.7 | 11 | | C | | | | D | 5 | | | E | | 7.2 | | F | 3.2 | 4.3 | | G | | 4.4 | | H | | 8 | |-------+---------+---------| | total | missing | 7 | #+TBLFM: @&gt;$3='(length(org-lookup-all "" '(@2$2..@-1$3) nil));E 排序结果 org-lookup-all 的另一个示例应用是结果的自动排序。 在下表中，总数越大越好。 请注意，Elisp表达式还自动处理关联关系。 | group | marks | rank | |-------+-------+------| | A | 22 | 2 | | B | 22 | 2 | | C | 14 | 4 | | D | 28 | 1 | | E | 9 | 5 | #+TBLFM: $3='(+ 1 (length (org-lookup-all $2 '(@2$2..@&gt;$2) nil '&lt;)));N 统计原始数据的频率 数据分析中的常见情况是对可视化的原始数据值进行分类（分组）。 通常是通过统计在特定范围内的出现频率来完成的。 可使用函数 org-lookup-all ，结合其他 elisp 函数来执行此任务。 此示例还显示了如何使用表中的多个值构建更复杂的查找规则。 考虑下表，不同组A-I的不同结果。 #+TBLNAME: raw-data | group | result | |-------+--------| | A | 2.3 | | B | 4.2 | | C | 1.1 | | D | 3.6 | | E | 4.5 | | F | 2.4 | | G | 1.0 | | H | 2.3 | | I | 2.8 | 将结果分为不同的，并且相斥的类。 例如，属于第一类的值在区间 [1，1.9] （包括端点）中。 为了执行这样的分类，我们定义了以下两参数谓词函数 in-interval 。 请注意，此函数的第一个参数是一对，其第一个元素是下限，第二个成员是该间隔的上限。 #+BEGIN_SRC emacs-lisp (defun in-interval (bounds el) (and (&gt;= el (car bounds)) (&lt;= el (cadr bounds)))) #+END_SRC #+RESULTS: : in-interval 使用这个谓词函数，我们可以构造一个具有分类边界和相应频率的表。 请注意，函数 org-lookup-all 的第一个参数是作为第一个参数传递给谓词 in-interval 中的第一个参数，是一对边界。 | lower bound | upper bound | frequency | |-------------+-------------+-----------| | 1 | 1.9 | 2 | | 2 | 2.9 | 4 | | 3 | 3.9 | 1 | | 4 | 4.9 | 2 | #+TBLFM: $3='(length (org-lookup-all '($1 $2) '(remote(raw-data,@2$2..@&gt;$2)) nil 'in-interval));N 结论 Org 的 lookup 函数可用于大量不同的数据相关计算。 例如，libreoffice或Excel用户熟悉的以下电子表格操作都可以使用它们来实现： HLOOKUP ， VLOOKUP ， COUNTIF ， SUMIF 和 FREQUENCY 。 Last Updated 2017-05-23 Tue 13:28.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[在Org-mode的电子表格中使用elisp公式]]></title>
      <url>%2F2017%2F04%2F08%2Forg-spreadsheet-lisp-formulas%2F</url>
      <content type="text"><![CDATA[原文Org as a spreadsheet system: using Emacs lisp as formulas, 由 Bastien 编辑，维护。本文只做学习之用。 序言 本教程介绍如何在Org表中使用Emacs Lisp作为公式。 如果想要了解如何使用Org作为电子表格系统的一般教程，请阅读这个教程。 还可以查看有关此主题的完整Org文档1。 示例 1: 操纵单元格 下面是一个简单的表格: First name Last Name Email John Doe john.doe@emacs.edu Jennie Duh jennie.duh@emacs.edu 你会很容易就注意到第三列模式： [firstname].[lastname]@emacs.edu 。 给出 First name 和 Last name ，很容易计算 Email 列的结果。 首先将光标放在第三列中: 现在键入 C-c } 显示表的坐标(引用)。 对于每一行，需要将第一列（使用 $1 访问）的内容连接到点（"."），然后连接到第二列（使用 $2 访问）的单元格, 最后连接到字符串 "@emacs.edu"。 使用 Emacs Lisp 编写的公式如下所示: '(concat (downcase $1) "." (downcase $2) "@emacs.edu") 现在复制这个公式，在右下角的字段中键入 C-c = 来插入列公式2，然后粘贴公式。 点击 RET 将立即将结果插入此单元格（ jack.goody@emacs.edu ），并在表格的底部添加 ＃+TBLFM 行。 警告：请注意初始引用 ( initial quote ) ：公式是表达式本身 (expression itself) ，而不是其值。 当 $1 和 $2 引用将被正确的字符串替换时，该表达式将只有一个含义，然后通过在 ＃+TBLFM 上键入 C-c C-c 来应用该表达式。 经过公式计算表格如下: 在执行公式时， $1 和 $2 将被解释并由这些单元格的值替换为字符串：不需要用 " 括起 $1 。 如果需要强制 $1 和 $2 被解释为数字，请在 Emacs lisp 表达式的末尾添加标志 ;N 。 参见下面表格: First name Last Name Maths French Mean John Doe 12 16 14 Jennie Duh 15 9 12 使用如下公式计算第五列: #+TBLFM: $5=&#39;(/ (+ $3 $4) 2);N 作为一个练习，尝试写出下面表第五列的Emacs lisp公式: First name Last Name Maths French Mean John Doe 12 16 John: 14 Jennie Duh 15 9 Jennie: 12 前四列的值是目前已知的，在此基础上构造出第五列。 （提示：参阅 Emacs lisp 函数 string-to-number 和 number-to-string 。） 解决方案 ：不能使用 ;N 标志，因为它会强制将单元格解释为数字，如果这样做，将无法访问第一行单元格的值。 所以一个方案就是使用 string-to-number 和 number-to-string, 如下所示： #+TBLFM: $5=&#39;(concat $1 &#34;: &#34; (number-to-string (/ (+ (string-to-number $3) (string-to-number $4)) 2))) 另一个解决方案是使用 ;L 标志：单元格内容不是被直接解释成字符串或数字，而是直接插入到 Emacs lisp 表达式中。 所以上面的公式可以安全地被下面这个更精简的代替： #+TBLFM: $5=&#39;(concat &#34;$1&#34; &#34;: &#34; (number-to-string (/ (+ $3 $4) 2)));L 注意 "$1" 的双引号：因为在字面上插入 First name 将意味着 "it is an Emacs lisp symbol" 。 所以，当使用 ;L 标志时，添加双引号确保引用被解释为一个字符串。 示例 2: 操纵行列区间 假设有以下表格 Col1 Col2 Col3 Col4 Col5 ? ? in Col1 and Col2 (no duplicates) only in Col1 only in Col2 ? ? &#x2026; &#x2026; &#x2026; ? ? &#x2026; &#x2026; &#x2026; Col1 和 Col2 包含字符串。 第三列的第一个单元格包含一个字符串，这个字符串由 Col1 和 Col2 中的所有字符串去重后组成。 Col4 包含仅在 Col1 （不在 Col2 ）中的字符串，而 Col5 包含仅在 Col2 （不在 Col1 ）中的字符串。 如何使用Emacs lisp公式来自动计算出结果？ 首先弄清楚想要的结果: Col1 Col2 Col3 Col4 Col5 a a a b c d c d a b &#xa0; &#xa0; &#xa0; b a &#xa0; &#xa0; &#xa0; c d &#xa0; &#xa0; &#xa0; 现在从第二行开始获取第一列的值。 可通过引用 @2$1 访问左上角单元格中的“a”。 可通过引用 @5$1 访问左下方单元格上的“c”。 然后可使用 @2$1..@5$1 访问单元格区间内值。 将上面获取的区间添加到 Col3 的第一个单元格中: Col1 Col2 Col3 Col4 Col5 a a a a b c c d a b &#xa0; &#xa0; &#xa0; b a &#xa0; &#xa0; &#xa0; c d &#xa0; &#xa0; &#xa0; 公式如下: #+TBLFM: @2$3=&#39;(mapconcat &#39;identity (list @2$1..@5$1) &#34; &#34;) 公式要怎么解读呢? 解释时，区间 @2$1..@5$1 由单元格的值替换，并用空格分隔。 所以 (list @2$1..@5$1) 变成 (list "a" "a" "b" "c") ，整个公式变成 '(mapconcat 'identity (list "a" "a" "b" "c") " ") 上面的公式大体意味着的连接 ("a" "a" "b" "c") 中元素，并在每个元素之间添加一个空格。 把问题更一般话，我很可能不知道表包含多少行。 区间 @2$1..@5$1 变成 @2$1..@&gt;$1 其中 @&gt; 表示“最后一行”， @&gt;$1 表示“第一列的最后一行”。 记住：我们希望第三列包含一个字符串，这个字符串由 Col1 和 Col2 中的所有字符串去重后组成。 首先从 Col1 和 Col2 列出所有值 (list =@2$1..@&gt;$1 @2$2..@&gt;$2) ， 然后删除重复项 (delete-dups (list @2$1..@&gt;$1 @2$2..@&gt;$2)), 最后把这个表达式放在上面已有的表达式中。 #+TBLFM: @2$3=&#39;(mapconcat &#39;identity (delete-dups (list @2$1..@&#38;gt;$1 @2$2..@&#38;gt;$2)) &#34; &#34;) Col1 Col2 Col3 Col4 Col5 a a a b c d c d a b &#xa0; &#xa0; &#xa0; b a &#xa0; &#xa0; &#xa0; c d &#xa0; &#xa0; &#xa0; 好的。 现在你已经知道如何操纵区间，你可以用正确的公式替换 "?"了&#x2026; 记住： Col4 包含仅在 Col1 中而不在 Col2 中的字符串，而 Col5 包含仅在 Col2 中而不在 Col1 中的字符串。 (注：可以编写自己的函数并在 Emacs lisp 公式中使用它们) Col4 和 Col5 的公式如下： #+TBLFM: @2$4=&#39;(apply &#39;concat (delete-if (lambda(e) (member e (list @2$2..@&#38;gt;$2))) (list @2$1..@&#38;gt;$1)))&#10;#+TBLFM: @2$5=&#39;(apply &#39;concat (delete-if (lambda(e) (member e (list @2$1..@&#38;gt;$1))) (list @2$2..@&#38;gt;$2))) 不要忘记，可以通过在表上的任何位置点击 C-c ' 来编辑表的公式： 它将打开公式编辑器，并突出显示光标所在的引用（在公式编辑器和表中）。 当需要检查引用是否正确时，公式编辑器非常方便。 此外，在该编辑器中的公式上点击 TAB 将格式化公式，这样更有助于公式编辑！ 结论 请浏览Org手册（精简但准确和最新）使用Lisp作为公式的信息：请参阅在线手册 和 相关信息页。 Footnotes: 1 如果在Emacs中阅读本教程，请浏览手册的电子表格部分，点击链接：电子表格。 2 列公式适用于整个列，而单元格公式仅适用于当前单元格。 可以通过在字段中按 C-u C-c = 来插入单元格公式。 Last Updated 2017-05-23 Tue 13:28.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Org-mode的电子表格的简明教程]]></title>
      <url>%2F2017%2F04%2F06%2Forg-spreadsheet-intro%2F</url>
      <content type="text"><![CDATA[原文Org as a spreadsheet system: a short introduction, 由 Bastien 编辑，维护。本文只做学习之用。 序言 这篇简短的教程将介绍使用 Org 作为电子表格系统需要的基础知识。 从一个非常简单的表开始: student maths physics bertrand 13 09 henri 15 14 arnold 17 13 上面的表格在 Org 文件中的样式: | student | maths | physics | |----------+-------+---------| | bertrand | 13 | 09 | | henri | 15 | 14 | | arnold | 17 | 13 | 本教程的目的是阐述如何从上面简单的表生成出如下所示的包含平均每个学生和每个学科的平均分的表： student maths physics mean bertrand 13 09 11 henri 15 14 14.5 arnold 17 13 15 means 15 12 13.5 熟悉引用 先从每个学生的平均值开始。 | student | maths | physics | mean | |----------+-------+---------+-----------| | bertrand | 13 | 09 | [formula] | | henri | 15 | 14 | | | arnold | 17 | 13 | | 在往 [formula] 中插入公式之前，需要知道如何引用 ( refer )一行，一列或一个单元格。 了解引用的最简单的方法是当你在一个单元格时，键入 C-c ? 。 例如，如果在 [formula] 单元格中， C-c ? 展示给你的信息是： line @2, col $4, ref @2$4 or D2 ， 这表示在第四列的第二行上，而这个字段的引用是 @2$4 或 D2 。 在任何时刻，如果不清楚行和列，可以随时使用 C-c } 打开引用的可视化网格： 第一个公式 将光标放在（空） [formula] 单元格中, 然后在此字段中输入 :=vmean（$2..$3） 。 该公式意味着：计算此行中第二（ $2 ）到 第三（ $3 ）单元格的字段平均值。 如果喜欢其他符号，请输入 :=vmean(B&amp;..C&amp;) &#x2013; 其中 &amp; 字符代表在这一行。 在上面键入公式的行中，键入 C-c C-c , 你将观察到两点变化： 1） :=vmean（$2..$3） 已被计算结果代替，2）以 ＃+TBLFM 开头的新行已被插入到表的底部。 ＃+TBLFM 行包含表的所有公式，在手动编辑时应小心。 列公式和单元格公式 经过上面的操作，表格变成了: | student | maths | physics | mean | |----------+-------+---------+------| | bertrand | 13 | 09 | 11 | | henri | 15 | 14 | | | arnold | 17 | 13 | | #+tblfm: @2$4=vmean($2..$3) 但是我们真正想要的是计算“Mean”列中所有单元格的公式。 换句话说，我们真的想要一个列公式，而不是单元格公式。 要使用列公式替换当前公式，请返回到已定义的单元格，然后键入 =vmean($2..$3) 。 请注意，与之前插入的唯一区别在于公式以 = 替代前缀 := 。 完成后，在单元格中执行 C-c C-c ：列公式替换先前公式，这正是我们想要的。 一旦执行了上面步骤，该单元格中的值应该与以前相同（即11），现在可以通过键入 C-u C-c * (或者在 #+TBLFM 行键入 C-c C-c ) 重新应用公式来更新此列中的所有单元格。 经过上面的步骤，表格如下所示: | student | maths | physics | mean | |----------+-------+---------+------| | bertrand | 13 | 09 | 11 | | henri | 15 | 14 | 14.5 | | arnold | 17 | 13 | 15 | #+tblfm: $4=vmean($2..$3) 由于在 ＃+TBLFM 中的单个公式现在适用于整个列，所以它不包含任何对行的引用。 公式以前被应用于 @2$4 单元格，现在它被应用于 $4 列。 最后，为每个学科平均值添加一行。 此行包含两个字段公式，每个公式计算同一列中上面单元格的平均值: | student | maths | physics | mean | |----------+-------+---------+------| | bertrand | 13 | 09 | 11 | | henri | 15 | 14 | 14.5 | | arnold | 17 | 13 | 15 | |----------+-------+---------+------| | means | 15 | 12 | | #+tblfm: $4=vmean($2..$3)::@5$2=vmean(@2$2..@4$2)::@5$3=vmean(@2$3..@4$3) 表格如下所示: student maths physics mean bertrand 13 09 11 henri 15 14 14.5 arnold 17 13 15 means 15 12 &#xa0; 交互的编辑公式 我们可通过将公式直接插入到表格单元格的方式来定义它们：在一个字段中键入 = 开始列公式的定义，和键入 := 开始一个单元格公式的定义。 如果你喜欢，可以在 minibuffer 中编辑公式：使用 C-c = 编辑列公式或 C-u C-c = 用于字段公式。 但是也可以通过键入 C-c ' 在专用缓冲区中交互式地编辑公式。 此新缓冲区列出了表的所有公式，并提供编辑引用的功能。 当光标在引用上方时，表中的相应字段将突出显示。 很好！ 但可以做的更多：可以使用 S-&lt;left/right/up/down&gt; 键实际选择引用。 注：不用担心使用 M-&lt;left/right&gt; 左右移动列或 M-&lt;up/down&gt; 上下移动行会混淆 ＃+TBLFM 行中的引用，因为每次移动都会自动更新引用。 Calc和Elisp公式 公式的默认语法是 Calc ，用于进行计算的 GNU Emacs 包。 以下是Calc手册 中关于代数式公式的摘录: Algebraic formulas use the operators `+', `-', `*', `/', and `^'. You can use parentheses to make the order of evaluation clear. In the absence of parentheses, `^' is evaluated first, then `*', then `/', then finally `+' and `-'. For example, the expression 2 + 3*4*5 / 6*7^8 - 9 is equivalent to 2 + ((3*4*5) / (6*(7^8)) - 9 在 Org 表中，可使用引用而不是值来执行计算。 但是，如果需要使用 Emacs lisp 代码而不是 Calc ？ 例如，将每个学生与Pi数字的十进制相关联，具体取决于他们在数学和物理学上的平均数。 为此，需要告诉 Org Pi数值的值。 可以通过添加以下行来实现： #+CONSTANTS: pi=3.14159265358979323846 (不要忘了在 #+CONSTANTS 行上 键入 C-c C-c 以刷新 Local 设置) 你定义的 Emacs lisp 公式可能如下所示: $5='(substring (number-to-string $pi) (round $4) (1+ (round $4)));N Ahem. Let's parse this: (substring S A B): 获取 S 字符串 A 和 B 之间的子串 (number-to-string $pi): 把常量"Pi"转换成字符串 (round $4): 获取 $4 四舍五入后整数值 ;N: 把当前单元格的值当成整数，而不是字符串 如果学生的平均数是10，该公式返回的Pi中第十位数字。 调试公式 现在表格如下所示: Student Maths Physics Mean Pi number Bertrand 13 09 11 5 Henri 15 14 14.5 7 Arnold 17 13 15 9 如果你回顾这个表，并试图了解 Emacs Lisp 函数具体完成了那些计算; 这个时候，你会产生疑惑，你可能会想要调试公式，并按步骤一步一步进行计算。 在表格的任意地方键入 C-c { 或 在一个单元格中键入 C-c C-c （或 C-u C-c * 在这个表的任何地方）都会打开表格公式调试器。 然后将一个一个地执行公式的计算，并在一个单独的缓冲区显示关于每个公式的计算步骤的细节。 Substitution history of formula Orig: '(substring (number-to-string $pi) (round $4) (1+ (round $4)));N $xyz-&gt; '(substring (number-to-string 3.14159265358979323846) (round $4) (1+ (round $4))) @r$c-&gt; '(substring (number-to-string 3.14159265358979323846) (round $4) (1+ (round $4))) $1-&gt; '(substring (number-to-string 3.14159265358979323846) (round 11) (1+ (round 11))) Result: 5 Format: NONE Final: 5 一旦调试完成，再次键入 C-c { 关闭调试器。 很多, 还有更多 使用 Org 作为电子表格系统非常容易上手。 本教程只是冰山一叫，你可以做的远不止于此！ 可以使用相对引用，为公式的列和参数定义名称，定义自动重新计算的单元格等。还可以在公式中使用 Emacs lisp （请阅读本教程）。 浏览下 Org-mode手册 中的高级功能，它会给你一个更广阔的视角&#x2026; Last Updated 2017-05-23 Tue 13:28.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Babel: org-mode的元编程]]></title>
      <url>%2F2017%2F04%2F01%2Fbabel-intro%2F</url>
      <content type="text"><![CDATA[原文Babel: Introduction, 由 Eric Schulte , Dan Davison, Tom Dye 编辑，维护。本文只做学习之用。 1 序言 Bable 可让许多不同的语言工作一起。 编程语言生活在自然语言的 Org-mode 文档的代码块之中。 一个数据片段可从一个表格传递给一个 Pythoh 代码块，然后可能再转移到一个 R 代码块， 最终以数据块被嵌入段落的中间而终结，或者通过 gnuplot 代码块生成图片嵌入在文档中。 通过扩展 Org-mode, 使其具有编辑,导出和执行源代码的功能, Babel 将 Org-mode 变成了文学编程和可重复性研究的工具。 Babel 通过提供以下特性来增强 Org-mode对代码代码块的支持: Babel augments Org-mode support for code blocks by providing: 代码块的交互和执行结果导出 代码块可像函数一样可参数化，引用其他代码块，可被远程调用 拼接，导出源代码到文件支持文学编程。 2 概述 Babel 在几个不同的方面提供了新的功能，不同的人可能想在不同的地方开始。 在 Org-mode 中使用代码块如果目前你还不知道怎么在 Org-mode 中创建代码块， 或者不清楚怎样在 Org-mode 的缓冲区和语言主模式编辑缓冲区(the language major-mode edit buffer)之间切换， 那么你需要应该看看Org 手册中的相关部分 和 下面的代码块章节, 尝试下，然后赶紧回来。 执行代码Babel 的核心是能够在 Org-mode 代码块中执行代码， 从其他块和表格获取输入，并输出到更多的块和表。 从源代码执行开始描述。 Literate Programming程序员编写的代码，通常以其他方式执行（例如从命令行或将其引入到交互式会话中）， 那么对 Babel 的简单介绍就是将代码放在 Org-mode 文件的代码块中， 然后使用 Babel 的 Literate Programming 支持从 Org-mode 文件中扩展提取源代码。 所有这些用例以及 Babel 功能的详尽文档都被涵盖在 Org 手册的 使用源代码中。 3 初始配置 If you have a working Emacs installation, then getting started with Babel is a simple process. If you are running Emacs24 a current version of Org-mode with Babel is already available by default. Otherwise, it is strongly recommended that you update to the latest version of Org-mode by keeping current with Org-mode development. As of Org-mode 7.0, Babel is included as part of Org-mode. Optionally activate the subset of languages that you will want to execute with Babel. See Configure active languages instructions. Emacs Lisp is activated by default so this step can be skipped for now and all emacs-lisp examples will still work as expected. If you have made any changes don&rsquo;t forget to evaluate your modified .emacs. 4 代码块 4.1 代码块在 Org-mode 中 Babel 是关于 Org-mode 中代码块的。 如果还不熟悉 Org-mode 中的代码块的概念，请在继续之前查看 Org-mode手册的相关章节。 受到支持语言的代码块可以出现在 Org-mode 文件的任意位置。 代码块可以直接在 Org-mode 文件中编辑，但通过 C-c ' 调用的函数 org-edit-src-code 编辑代码往往更容易。 将代码块放全新的缓冲区中，同时激活相应语言的模式,语言的编辑特性你全都可用，真是爽。 #+begin_src language org-switches&#10;,body&#10;#+end_src ruby 代码的代码块如下所示: #+begin_src ruby&#10;,require 'date'&#10;,&#34;This file was last evaluated on #{Date.today}&#34;&#10;#+end_src 4.2 代码块在 Babel 中 Babel 向代码块添加了一些新的元素。 基本结构变成了: #+begin_src language org-switches header-arguments&#10;,body&#10;#+end_src language代码块中代码的语言标示。 有效值必须是 org-babel-interpreters 的成员。 header-argumentsheader-arguments 控制源代码块的执行和输出的许多方面。 请参阅Header Arguments部分，以查看可用的 header-arguments= 。 body等待被执行的源代码。 一个重要的键绑定 C-c ' , 调用 org-edit-src-code ，打开一个包含适合于该语言 major mode 的编辑缓冲区。 然后你就可以像往常在emacs编辑代码那样来编辑你的代码块。 5 源代码执行 Babel 通过将代码传递给解释器来执行解释语言（如shell，python，R等）的代码块。 在执行结果上可以做进一步的操作，如果你想的话。 5.1 示例 以下是三种不同语言的代码块，其后是其输出。 如果正在Emacs中查看本文档的 Org-mode 版本，则把光标放置在块的任何位置，然后按 C-c C-c 执行代码1（并随意更改它）。 5.1.1 Ruby 在 Org-mode 的文件中: #+begin_src ruby require 'date' "This file was last evaluated on #{Date.today}" #+end_src HTML 导出的代码: require 'date'"This file was last evaluated on #{Date.today}" HTML 导出的执行结果: This file was last evaluated on 2017-04-05 5.1.2 Shell 在 Org-mode 的文件中: #+begin_src sh echo "This file takes up `du -h babel-intro.org |sed 's/\([0-9k]*\)[ ]*babel-intro.org/\1/'`" #+end_src HTML 导出的代码: echo "This file takes up `du -h babel-intro.org |sed 's/\([0-9k]*\)[ ]*babel-intro.org/\1/'`" HTML 导出的执行结构: This file takes up 36K 5.1.3 R 当前这个文件中最常用的词是？ 在 Org-mode 文件中: #+begin_src R :colnames yes words 3]), decreasing=TRUE)[1:10]) #+end_src HTML 导出的代码: words &lt;- tolower(scan("babel-intro.org", what="", na.strings=c("|",":")))t(sort(table(words[nchar(words) &gt; 3]), decreasing=TRUE)[1:10]) 5.1.4 ditaa 在 Org-mode 文件中: #+begin_src ditaa :file blue.png :cmdline -r +---------+ | cBLU | | | | +----+ | |cPNK| | | | +----+----+ #+end_src HTML导出的代码: +---------+&#10;| cBLU |&#10;| |&#10;| +----+&#10;| |cPNK|&#10;| | |&#10;+----+----+ HTML导出的结果图: 5.1.5 js console.log('Hello, world'); 5.2 捕获代码执行结果 Babel 提供了两种根本不同的模式来捕获代码执行的结果： functional mode 和 scripting mode 。 模式的选择可以通过配置 :results 头参数来指定。 5.2.1 :results value (functional mode) 代码执行的结果是代码块中最后一个语句的值。 在 functional mode 下，代码块是具有返回值的函数。 一个代码块的返回值可以用作另一代码块的输入，即使是不同语言的输入。 这样的话，Babel成为一种元编程语言。 如果块返回表格数据（某种类型的向量，数组或表），那么将可以作为 Org-mode 的表格保存在缓冲区中。 functional mode 是默认设置。 作为示例，观察以下python代码块及其输出。 import timeprint("Hello, today's date is %s" % time.ctime())print("Two plus two is")return 2 + 2 请注意，在 functional mode 下，输出只由最后一个语句返回，没有其他情况。 5.2.2 :results output (scripting mode) 在 scripting mode 中，Babel捕获代码块的文本输出并将其放置在 Org-mode 的缓冲区中。 它被称为 scripting mode ，因为代码块包含一系列命令，并返回每个命令的输出。 与功能模式不同，代码块本身除了其包含的命令的输出之外没有返回值。2 观察以下使用 scripting mode 执行代码块的结果。 import timeprint("Hello, today's date is %s" % time.ctime())print('Two plus two is')2 + 2 在这里， scripting mode 返回了python写到 stdout 的文本。 因为代码块不包含最后一个语句 (2 + 2) 的 print() 语句，所以结果中不会出现4。 5.3 基于会话的代码块 对于某些语言，例如Python，R，ruby和shell，可以在Emacs中运行一个不完备的交互式会话进程。 这意味着创建了一个不同源代码块之间共享数据对象的持久化环境。 Babel 支持使用 :session 头参数来 指定代码块运行于特定会话中。 如果头参数被赋予一个值，那么该参数将被用作会话的名称。 因此，可以并发的在不同的会话中运行同一语言的不同代码块。 基于特定会话的代码块对于原型设计和调试特别有用。 函数 org-babel-pop-to-session 可用于切换会话缓冲区。 一旦代码块编辑完成，通常最好在会话之外执行它，因为这样它执行的环境将是确定的。 With R, the session will be under the control of Emacs Speaks Statistics as usual, and the full power of ESS is thus still available, both in the R session, and when switching to the R code edit buffer with ​C-c '​. 5.4 代码块的入参 Babel 支持代码块的参数化，即可以将参数传递给代码块，从而使它们函数化。 functional mode 和 scripting mode 都支持入参。 5.4.1 代码块作为函数的简单示例 首先我们来看一个非常简单的例子。 以下源代码块使用Python定义了一个函数，求入参的平方。 return x*x 在 Org-mode 文件中, 函数定义如下: #+name: square #+header: :var x=0 #+begin_src python return x*x #+end_src 调用函数如下: #+call: square(x=6,y=8) (对于 call 语法细节请参阅 Library of Babel) 36 5.4.2 Org-mode 表格作为入参的更复杂的示例 在本例中，使用Emacs Lisp定义的一个名为 fibonacci-seq 的函数。 函数 fibonacci-seq 计算斐波纳契序列。 该函数只需要一个参数，在当前情况下参数即为 Org-mode 表格的引用。 下面即为传递给 fibonacci-seq 的 Org-mode 表格: 1 2 3 4 5 6 7 8 9 10 2 4 6 8 10 12 14 16 18 20 表格在 Org-mode 的缓冲区中如下所示： #+tblname: fibonacci-inputs | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | | 2 | 4 | 6 | 8 | 10 | 12 | 14 | 16 | 18 | 20 | Emacs Lisp的源代码: (defun fibonacci (n)(if (or (= n 0) (= n 1)) n (+ (fibonacci (- n 1)) (fibonacci (- n 2))))) (mapcar (lambda (row) (mapcar #'fibonacci row)) fib-inputs) 在 Org-mode 中函数如下所示: #+name: fibonacci-seq #+begin_src emacs-lisp :var fib-inputs=fibonacci-inputs (defun fibonacci (n) (if (or (= n 0) (= n 1)) n (+ (fibonacci (- n 1)) (fibonacci (- n 2))))) (mapcar (lambda (row) (mapcar #'fibonacci row)) fib-inputs) #+end_src fibonacci-seq 的返回值，也是一个表格: 5.5 内联(In-line)的代码块 可使用以下语法内联(In-line)的执行代码： Without header args: src_lang{code} or with header args: src_lang[args]{code}, for example src_python[:session]{10*x}, where x is a variable existing in the python session. 代码如下: src_python{return "Hello World!"} 执行结果： Hello World! 5.6 代码块扩展 Babel 在执行之前“扩展”代码块，即，执行代码包括把引用的数据(或代码)填充到代码块内容里。 可以预览展开的内容，还可以在 tangling 期间展开代码。 扩展时，头参数和变量需要一并考虑进去。 previewC-c M-b p (C-c C-v v) 关联到 org-babel-expand-src-block 函数。它可用于在代码块中预览扩展的内容, 对调试很有用。 tangling扩展的的代码块可以被 tangled 。 tangling 可能包括的变量值 其他代码的执行结果， 存储在标题属性中变量，或者 表格。 tangling 扩展代码块的一个可能用途是用于emacs初始化。 用户名和密码等值可以存储在标题属性或表格中。 可以使用 :no-expand 头参数来阻止 tangling 期间代码块的扩展。 下面是代码块及其生成的扩展的示例。 数据被存储在表格中: username john-doe password abc123 引用数据表格的代码块: (setq my-special-username (first (first data)))(setq my-special-password (first (second data))) 在代码块内部， C-c M-b p (C-c C-v v)扩展内容如下： (let ((data (quote (("john-doe") ("abc123")))))(setq my-special-username (first (first data)))(setq my-special-password (first (second data)))) 5.7 Org-mode 的元编程语言 因为用一种语言编写的函数的返回值可以被传递给另一种语言编写的函数， 或者传递到本身就可程序化的 Org-mode 的表格中， 所以可将 Babel 用作元功能编程语言。 Bable 可使许多语言一起工作, 混合使用各语言，每种语言可用于最合适的任务。 例如，在shell中进行一些系统诊断，并用R图形化诊断结果. 使用shell代码创建一个代码块，列出program目录中的目录以及它们的大小。Babel自动将输出转换为 Org-mode 表格。 #+name: directories #+begin_src sh :results replace cd ~/program/ && du -sc * | grep -v total #+end_src 代码如下： cd ~/program/ &amp;&amp; du -sc * | grep -v total 结果如下： #+RESULTS: directories | 2392 | github | | 90728 | org | | 15820 | program | | 190488 | program.tgz | 一行R语言编写的函数将 Org-mode 表中的数据绘制为饼形图。 请注意，当前代码块如何使用前一代码块的 srcname 来获取的数据 。 在 Org-mode 文件中: #+name: directory-pie-chart(dirs = directories) #+begin_src R :session R-pie-example :file ../images/babel/dirs.png :var dirs=directories() :results graphics pie(dirs[,1], labels = dirs[,2]) #+end_src 注： :results graphics 请参阅 Org Mode Features for R Source Code Blocks HTML 导出的代码: pie(dirs[,1],labels=dirs[,2]) 6 在Org表格中使用代码块 除了可将表格中的数据作为参数传递给代码块和结果存储为表格外， Babel 还有第三种方式使用 Org-mode 表格。 Org-mode 现有电子表格 功能允许使用 ＃+TBLFM 从指定单元格值自动计算出其他单元格值。 通过以上方式，表可使用calc 和 emacs lisp来执行计算任务。 Babel 有效扩展了 ＃+TBLFM 行使用代码块（以任何语言）进行必要计算的能力。 6.1 示例 6.1.1 示例 1: 使用R生成数据概要 将使用几个数字的平均值来填充 Org-mode 表中的一个单元格，来做简单示例。 首先，要生成数据, 以下代码块生成0和1之间的五个随机数来填充了 Org-mode 表。 在 Org-mode 文件中,如下所示: #+name: tbl-example-data #+begin_src R runif(n=5, min=0, max=1) #+end_src HTML 导出的代码如下: runif(n=5, min=0, max=1) 紧接着定义一个代码块计算来表列的平均值。 在 Org-mode 文件中,如下所示: #+name: R-mean #+begin_src R :var x="" colMeans(x) #+end_src HTML 导出的代码如下: colMeans(x) 最后，创建使用R代码的表。 通过使用 org-sbe （&rsquo;source block evaluate&rsquo;）宏来完成的代码块的调用。 在 Org-mode 文件中，表格调用代码块如下所示: #+tblname: summaries | mean | |-------------------| | 0.779619386699051 | #+TBLFM: @2$1='(org-sbe "R-mean" (x "tbl-example-data()")) HTML export of code: mean 0.58 重新计算表格公式，请在表格中使用 C-u C-c C-c 。 每次重新计算表格公式时，代码块都会再次计算，因此计算的平均值会发生变化。 6.1.2 示例 2: Babel 的测试套件 While developing Babel, we used a suite of tests implemented as a large Org-mode table. 在开发 Babel 时，开发者曾使用了一个居大的 Org-mode 表作为测试套件。 要运行测试套件，我们只需使用 C-u C-c C-c 对表进行计算：运行所有测试，将结果与期望进行比较，并使用结果和通过/失败的状态信息来更新表。 测试套件的简单版本如下. 在 Org-mode 文件中，如下所示: #+TBLNAME: org-babel-tests | functionality | block | arg | expected | results | pass | |------------------+--------------+-----+-------------+-------------+------| | basic evaluation | | | | | pass | |------------------+--------------+-----+-------------+-------------+------| | emacs lisp | basic-elisp | 2 | 4 | 4 | pass | | shell | basic-shell | | 6 | 6 | pass | | ruby | basic-ruby | | org-babel | org-babel | pass | | python | basic-python | | hello world | hello world | pass | | R | basic-R | | 13 | 13 | pass | #+TBLFM: $5='(if (= (length $3) 1) (org-sbe $2 (n $3)) (org-sbe $2)) :: $6='(if (string= $4 $5) "pass" (format "expected %S but was %S" $4 $5)) HTML 导出的代码: functionality block arg expected results pass basic evaluation &#xa0; &#xa0; &#xa0; &#xa0; pass emacs lisp basic-elisp 2 4 4 pass shell basic-shell &#xa0; 6 6 pass ruby basic-ruby &#xa0; org-babel org-babel pass python basic-python &#xa0; hello world hello world pass R basic-R &#xa0; 13 13 pass 用于测试的代码块 Org-mode 文件中，如下所示：: #+name: basic-elisp #+begin_src emacs-lisp :var n=0 (* 2 n) #+end_src HTML 导出代码，如下所示：: (* 2 n) Org-mode 文件中，如下所示：: #+name: basic-shell #+begin_src sh :results silent expr 1 + 5 #+end_src HTML 导出代码，如下所示：: expr 1 + 5 Org-mode 文件中，如下所示：: #+name: date-simple #+begin_src sh :results silent date #+end_src HTML 导出代码，如下所示：: date Org-mode 文件中，如下所示：: #+name: basic-ruby #+begin_src ruby :results silent "org-babel" #+end_src HTML 导出代码，如下所示：: "org-babel" Org-mode 文件中，如下所示： #+name: basic-python #+begin_src python :results silent "hello world" #+end_src HTML 导出代码，如下所示：: return "hello world" Org-mode 文件中，如下所示：: #+name: basic-R #+begin_src R :results silent b 任何可选参数都可以传递给 example-block() ，方法是将参数放入括号内，并遵循调用代码块函数定义的约定（参见 babel库）。 如下: #> 参数 “a” 的值设置为等于 “9”。 请注意，这些参数不在当前源代码块中执行，而是按字面顺序传递给 example-block() 。 8.1.2 用Bable初始化Emacs Babel 对于将Emacs初始化信息嵌入 Org-mode 文件中有特别的支持。 org-babel-load-file 函数可用于加载嵌入在 Org-mode 文件中的Emacs Lisp代码块，方法与加载常规Emacs Lisp文件（如.emacs）相同。 这就允许利用Org-mode的功能特性，例如折叠，标签，笔记，HTML导出等，来组织和维护Emacs初始化配置。 要想了解这一点，可以参考简单的优雅的Emacs初始化示例，或者查看 Org-babel-emacs-starter-kit 中提供的 Phil Hagelberg 的优秀 emacs-starter-kit 的 Babel Literate Programming 版本。 To try this out, either see the simple Literate Emacs Initialization example, or check out the Babel Literate Programming version of Phil Hagelberg&rsquo;s excellent emacs-starter-kit available at Org-babel-emacs-starter-kit. 优雅的Emacs初始化 请按照以下5个步骤进行操作： 在主目录的内创建一个名为 .emacs.d 的目录; mkdir ~/.emacs.d checkout 最新版本的 Org-mode 到这个新目录的src子目录中; of this new directory; cd ~/.emacs.dmkdir srccd srcgit clone git://orgmode.org/org-mode.git 将以下代码块放入Emacs初始化目录（ ~/.emacs.d ）下名为 init.el 的文件中。 ;;; init.el --- Where all the magic begins;;;; This file loads Org-mode and then loads the rest of our Emacs initialization from Emacs lisp;; embedded in literate Org-mode files.;; Load up Org Mode and (now included) Org Babel for elisp embedded in Org Mode files(setq dotfiles-dir (file-name-directory (or (buffer-file-name) load-file-name)))(let* ((org-dir (expand-file-name "lisp" (expand-file-name "org" (expand-file-name "src" dotfiles-dir)))) (org-contrib-dir (expand-file-name "lisp" (expand-file-name "contrib" (expand-file-name ".." org-dir)))) (load-path (append (list org-dir org-contrib-dir) (or load-path nil)))) ;; load up Org-mode and Org-babel (require 'org-install) (require 'ob-tangle));; load up all literate org-mode files in this directory(mapc #'org-babel-load-file (directory-files dotfiles-dir t "\\.org$"));;; init.el ends here 在Emacs Lisp代码块中实现所有Emacs定制，嵌入在该目录中的 Org-mode 文件中; 和 重启Emacs读取自定义配置。 9 可重复性研究 An article about computational science in a scientific publication is not the scholarship itself, it is merely advertising of the scholarship. The actual scholarship is the complete software development environment and the complete set of instructions which generated the figures. &#x2013; D. Donoho 可重复性研究 （RR）是与科研出版物一起分发的所有数据，软件源代码和重现出版物中讨论的结果所需的工具的方法。 因此，RR包不仅描述了研究及其结果，而且成为可以复制和扩展研究的完整实验室。 Org-mode 已经很好的支持导出到HTML和LaTeX。 Babel 通过激活嵌入在 Org-mode 文档中的数据和代码块，使组织模式成为RR的工具; 整个文档变得可执行。 这使得鼓励读者重新创建结果并实验自己的思路来分发科研成果成为可能。 Sweave 是目前比较知名的RR工具，它提供了将R代码嵌入到LaTeX文档中的机制。 Sweave是一个成熟而且非常有用的工具，但我们认为 Babel 有几个优点: 支持多种语言 导出过程灵活强大，除了LaTeX之外，还包括HTML作为目标格式; 和 文档可利用 Org-mode 强大的功能特性，支持项目规划和任务管理等。 Footnotes: 1 Calling C-c C-o on a code block will open the block&rsquo;s results in a separate buffer. 2 This mode will be familiar to Sweave users. 3 摘自文艺编程 Literate Programming （原文中英文对照）, 个人更喜欢文学编程。 literate-devOps Last Updated 2017-10-31 Tue 21:54.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.1.2)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Go的日志库logrus试用]]></title>
      <url>%2F2017%2F03%2F21%2Fgo-logrus%2F</url>
      <content type="text"><![CDATA[1 示例 package mainimport ( "os" log "github.com/sirupsen/logrus")func init() { // Log as JSON instead of the default ASCII formatter. log.SetFormatter(&amp;amp;log.JSONFormatter{}) // Output to stdout instead of the default stderr // Can be any io.Writer, see below for File example log.SetOutput(os.Stdout) // Only log the warning severity or above. log.SetLevel(log.WarnLevel)}func main() { log.WithFields(log.Fields{ "animal": "walrus", "size": 10, }).Info("A group of walrus emerges from the ocean") log.WithFields(log.Fields{ "omg": true, "number": 122, }).Warn("The group's number increased tremendously!") log.WithFields(log.Fields{ "omg": true, "number": 100, }).Fatal("The ice breaks!") // A common pattern is to re-use fields between logging statements by re-using // the logrus.Entry returned from WithFields() contextLogger := log.WithFields(log.Fields{ "common": "this is a common field", "other": "I also should be logged always", }) contextLogger.Info("I'll be logged with common and other field") contextLogger.Info("Me too")} Last Updated 2017-06-19 Mon 23:25.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Org-mode手册]]></title>
      <url>%2F2017%2F03%2F21%2Fjust-try%2F</url>
      <content type="text"><![CDATA[org-mode我用了两年，却未曾深入。 最近两周静下心来，仔仔细细的钻研了一番，深深被这厮震撼到了，作为文档编辑工作，在我的认知范围里，无出其右。 归纳整理于此，以作留存，馈与日后。 1 文档结构 1.1 标题 Org 是在大纲模式之上实现的。 大纲模式可以让我们用层次结构来组织文档，这（至少对我来说）是笔记和想法的最好实现方式。 这种结构可以折叠（隐藏）文档的一部分而只显示文档的大概结构或者只显示我们正在处理的部分。 Org 大大简化了大纲模式的使用，它把大纲模式的整个显示/隐藏功能整合到了一个命令中：org-cycle，这个命令绑定到了TAB键上。 标题定义了大纲树的结构,以处于一行左边缘的一个或多个星号开头,如下: * Top level headline ** Second level *** 3rd level some text ** 3rd level more text , Another top level headline 1.1.1 视图命令 Table 1: 视图命令 Key Desc Command TAB 子树循环,在下列状态之间转换当前子树: ,-&gt;folded-&gt;children-&gt;subtree&#x2013;. org-cycle S-TAB 全局循环, 在下列状态之间转换当前的整个buffer： ,-&gt;overview-&gt;contents-&gt;show all&#x2013;. org-global-cycle C-c C-r 显示当前位置的上下文，展示当前条目，紧跟的标题和标题的层次结构。 适用于通过稀疏树命令或议程命令展露出来的位置附近工作。 org-reveal C-c C-k 展开子树的所有标题，CONTENT视图只有一个子树。 outline-show-branches C-c TAB 展开子树的所有直接子节点。 outline-show-children C-c C-x b 在间接缓冲区中显示当前子树 org-tree-to-indirect-buffer C-c C-x v 将区域中的可见文字复制到 kill ring. org-copy-visible org-mode默认的视图模式是'OVERVIEW',即概览模式，只有顶层的标题可见。 你可以通过配置变量 org-startup-folded 来改变视图模式，如下: (setq org-startup-folded 'content)(setq org-catch-invisible-edits nil) ;; prevent editing an invisible part of the bu&amp;#8629;er 当然你也可以为每个文件指定视图模式，只要在文件buffer中任意位置包含以下语句（推荐配置在文件头）： #+STARTUP: overview #+STARTUP: content #+STARTUP: showall #+STARTUP: showeverything 更进一步,任何条目都包含 VISIBILITY 属性，此属性定义了条目的视图模式，覆盖一般性设置。可接受的值为： folded children content all, 示例如下 #+STARTUP: overview * A :PROPERTIES: :VISIBILITY: all :END: 1.1.2 跳转命令 Table 2: 标题跳转命令 Key Desc Command C-c C-n 跳转到下一个标题 org-next-visible-heading C-c C-p 跳转到上一个标题 org-previous-visible-heading C-c C-f 跳转到下一个同级标题 org-forward-same-level C-c C-b 跳转到上一个同级标题 org-backward-same-level C-c C-u 跳回更高一级的标题 outline-up-heading C-c C-j 跳转到别处，不改变当前的视图模式，创建一个临时buffer来展示当前文档 org-goto 在 C-c C-j 触发的临时buffer中，可用的命令如下： TAB Cycle visibility. down/up Next/previous visible headline. RET Select this location. / Do a Sparse-tree search 若是关闭了 org-goto-auto-isearch ，以下命令可用： n/p Next/previous visible headline. f/b Next/previous headline same level. u One level up. 0-9 数字参数 q 退出 1.1.3 编辑命令 Table 3: 编辑命令 Key Desc Command M-RET 插入一个同级标题在当前位置(行首，把当前行转成标题；行中，截断余下文本，在下一行生成标题) org-insert-heading M-S-RET 在M-RET的基础上，添加了 TODO 标示 org-insert-todo-heading C-RET 在当前子树的结束位置插入同级标题 org-insert-heading-respect-content C-S-RET 在CRET的基础上，添加了 TODO 标示 org-insert-todo-heading-respect-content TAB 用于还未输入文本信息的标题，第一个TAB变为之前标题的子标题，第二个TAB变为父标题,第三个TAB恢复原有等级 (,-&gt;children-&gt;parent-&gt;initial)) org-cycle M-left 当前标题提升一个等级 org-do-promote M-right 当前标题降低一个等级 org-do-demote M-S-left 当前整个子树提升一个等级 org-promote-subtree M-S-right 当前整个子树降低一个等级 org-demote-subtree M-up 当前整个子树和前面同级子树交换位置 org-move-subtree-up M-down 当前整个子树和后面同级子树交换位置 org-move-subtree-down M-h Mark the element at point. org-mark-element C-c @ Mark the subtree at point. 目前看起来是可视化选中当前子树 org-mark-subtree C-c C-x C-w 剪切子树到 kill ring org-cut-subtree C-c C-x M-w 拷贝子树到 kill ring org-copy-subtree C-c C-x C-y 从 kill ring 中粘贴子树 org-paste-subtree C-y Depending on the options org-yank-adjusted-subtrees and org-yank- folded-subtrees, Org’s internal yank command will paste subtrees folded and in a clever way, using the same command as C-c C-x C-y. org-yank C-c C-x c Clone a subtree by making a number of sibling copies of it. You will be prompted for the number of copies to make, and you can also specify if any timestamps in the entry should be shifted. org-clone-subtree-with-time-shift C-c C-w 将条目或区域 refile 到不同的位置。 org-refile C-c ^ 排序相同级别的条目。 org-sort C-x n s 将缓冲区缩小到当前子树。 org-narrow-to-subtree C-x n b 将缓冲区缩小到当前 block 。 org-narrow-to-block C-x n w 加宽缓冲区以消除变窄。 widen C-c * 使正常的文本行变为标题,重复操作可恢复成原样 org-toggle-heading 1.1.4 稀疏树 一个很重要的特性就是org有能力为被选中的信息构造出稀疏树，使得被选中信息突出显示，无关信息折叠显示。实践才是检测真理的唯一标准，试一试就知道具体是怎样优化你的工作了。 Table 4: 稀疏树 Key Desc Command C-c / 本命令会触发sparse-tress命令界面，提示输入字符，来选择创建稀疏树的命令 org-sparse-tree C-c / r 创建出和正则表达式匹配的稀疏树;标题匹配，标题可见; body匹配, 标题和body都可见；所以匹配高亮，当当前buffer通过编辑命令发送改变时，高亮消失，当然你可以通过 C-c C-c 主动取消高亮。 org-occur M-g n 跳转到下一个匹配 next-error M-g p 跳转到上一个匹配 previous-error 很有可能需要频繁创建特定搜索条件的稀疏树，可通过 org-agenda-custom-commands 来定义快速访问的快捷键（这个命令可用在agenda dispatcher中）。 如下： ;; the key C-c a f as a shortcut for creating a sparse tree matching the string &amp;#8216;FIXME&amp;#8217;.(setq org-agenda-custom-commands '(("f" occur-tree "FIXME"))) The other sparse tree commands select headings based on TODO keywords, tags, or properties and will be discussed later in this manual. To print a sparse tree, you can use the Emacs command ps-print-buffer-with-faces which does not print invisible parts of the document. Or you can use C-c C-e C-v to export only the visible part of the document and print the resulting file. 1.2 列表 Within an entry of the outline tree, hand-formatted lists can provide additional structure. They also provide a way to create lists of checkboxes. Org supports editing such lists, and every exporter can parse and format them. 在大纲树的组织结构中，自定义格式的列表可以提供更多的组织结构。使我们得到一个复先框列表。 Org 可以处理这种列表，同时各个 exporter 可以解析和格式化。 Org 可识别 ordered 列表, unordered 列表, 和 description 列表。 Unordered 的列表项以 ‘-’, ‘+’ 或 ‘*’ 开始。 Ordered 的列表项以数字加在 ‘.’ 或 ‘)’ 开始。格式如下：‘1.’ 或 ‘1)’。 可自定义起始值，在文本开始出插入[@20]，代表以20开始。 Description 列表项其实就是 unordered 列表项, 只在文本中间插入了分隔符 ‘::’ 。 同一个列表中项首行必须缩进一致。特别是 ordered 列表到了 ‘10.’ ，两位数字必须和其他数字左对齐。 若是下一行的缩进小于等于当前列表的缩进，则当前项终结。当所有项都终结，或者后面隔了两个空行时，列表终结。示例如下： ** Lord of the Rings My favorite scenes are (in this order) 1. The attack of the Rohirrim 2. Eowyn's fight with the witch king + this was already my favorite scene in the book + I really like Miranda Otto. Important actors in this film are: - Elijah Wood :: He plays Frodo - Sean Austin :: He plays Sam, Frodo's friend. Org supports these lists by tuning filling and wrapping commands to deal with them correctly, and by exporting them properly. Since indentation is what governs the structure of these lists, many structural constructs like #+BEGIN_... blocks can be indented to signal that they belong to a particular item. If you find that using a different bullet for a sub-list (than that used for the current list-level) improves readability, customize the variable org-list-demote-modify-bullet. To get a greater difference of indentation between items and their sub-items, customize org-list-indent-offset. The following commands act on items when the cursor is in the first line of an item (the line with the bullet or number). Some of them imply the application of automatic rules to keep list structure intact. If some of these actions get in your way, configure org-list-automatic-rules to disable them individually. 当光标位于一项的首行时（带有项标志符的行），下面命令将作用于该项： Table 5: 稀疏树 Key Desc Command TAB 列表项像标题一样的被折叠，展开 org-cycle TAB 用于还未输入文本信息的子项，第一个TAB变为子项，第二个TAB变为父项,第三个TAB恢复原有等级 (,-&gt;children-&gt;parent-&gt;initial)) org-cycle M-RET 插入一个同级项(行首，把当前行转成列表项；行中，截断余下文本，在下一行生成列表项) org-insert-heading M-S-RET 插入一个带 checkbox 的同级项(行为类似于M-RET) &#xa0; S-up/S-down 跳转到当前列表的上一项或者下一项 &#xa0; M-up/M-down 和上一项或者下一项交换位置（同级之间) &#xa0; M-left/M-right 提升或者降低一项的等级,子项不变 &#xa0; M-S-left/M-S-right 提升或者降低一项的等级,子项同等变化 &#xa0; C-c C-c 当前项有 checkbox , 触发状态转换 &#xa0; C-c - 循环改变将当前列表的项标志符 &#xa0; C-c * 使列表项变为标题 (在当前位置生成子标题). org-toggle-heading C-c C-* 使整个列表变成当前标题的子树 checkboxes 将变为 TODO 当未 unchecked 时 &#xa0; S-left/right 循环改变将当前列表的项标志符 &#xa0; C-c ^ Sort the plain list org-sort 1.3 Drawers Sometimes you want to keep information associated with an entry, but you normally don’t want to see it. For this, Org mode has drawers. They can contain anything but a headline and another drawer. You can interactively insert drawers at point by calling org-insert-drawer, which is bound to C-c C-x d. With an active region, this command will put the region inside the drawer. With a prefix argument, this command calls org-insert-property-drawer and add a property drawer right below the current headline. Completion over drawer keywords is also possible using M-TAB. Visibility cycling on the headline will hide and show the entry, but keep the drawer collapsed to a single line. In order to look inside the drawer, you need to move the cursor to the drawer line and press TAB there. Org mode uses the PROPERTIES drawer for storing properties , and you can also arrange for state change notes and clock times to be stored in a drawer LOGBOOK. If you want to store a quick note in the LOGBOOK drawer, in a similar way to state changes, use C-c C-z Add a time-stamped note to the LOGBOOK drawer. You can select the name of the drawers which should be exported with org-export-with-drawers. In that case, drawer contents will appear in export output. Property drawers are not affected by this variable: configure org-export-with-properties instead. Drawers 如下所示： ** This is a headline Still outside the drawer :DRAWERNAME: This is inside the drawer. :END: After the drawer. 1.4 块 Org mode uses begin&#x2026;end blocks for various purposes from including source code examples to capturing time logging information. These blocks can be folded and unfolded by pressing TAB in the begin line. You can also get all blocks folded at startup by configuring the option org-hide-block-startup or on a per-file basis by using #+STARTUP: hideblocks #+STARTUP: nohideblocks 1.5 脚注 A footnote is started by a footnote marker in square brackets in column 0, no indentation allowed. It ends at the next footnote definition, headline, or after two consecutive empty lines. The footnote reference is simply the marker in square brackets, inside text. Markers always start with fn:. For example: The Org homepage[fn:1] now looks a lot better than it used to. ... [fn:1] The link is: http://orgmode.org Org mode extends the number-based syntax to named footnotes and optional inline definition. Here are the valid references: [fn:name]A named footnote reference, where name is a unique label word, or, for simplicity of automatic creation, a number. [fn::This is the inline definition of this footnote]A LATEX-like anonymous footnote where the definition is given directly at the reference point. [fn:name:a definition]An inline definition of a footnote, which also specifies a name for the note. Since Org allows multiple references to the same note, you can then use \[fn:name\] to create additional references. Footnote labels can be created automatically, or you can create names yourself. This is handled by the variable org-footnote-auto-label and its corresponding #+STARTUP keywords. See the docstring of that variable for details. 示例如下： The Org homepage1 now looks a lot better than it used to. Table 6: 脚注命令列表 Key Desc Command C-c C-x f 当光标处于引用处时，跳转到它的定义；当光标处理定义处时，跳转到第一个引用处。其他情况下，新建一个脚注。当有前缀参数时，会提供一个菜单供选择操作，其中包括重新给脚注编号。 org-footnote-action C-c C-c 当光标处于引用处时，跳转到它的定义；当光标处理定义处时，跳转到第一个引用处。当有前缀参数时，行为和 C-c C-x f 一样,提供同样操作菜单。 &#xa0; C-c C-o 脚注标签也是指向相应定义/引用的链接，您可以使用常用(链接)命令来跟踪这些链接。 org-open-at-point C-c ' 在独立的窗口中，编辑引用关联的脚注定义。窗口可通过 C-c ' 关闭 org-edit-special 当 C-c C-x f 命令加上附加前缀参数时(C-u C-c C-x f) ,一个操作菜单被提供： s Sort the footnote definitions by reference sequence. During editing, Org makes no effort to sort footnote definitions into a particular sequence. If you want them sorted, use this command, which will also move entries according to org-footnote-section. Automatic sorting after each insertion/deletion can be configured using the option org-footnote-auto-adjust. r Renumber the simple fn:N footnotes. Automatic renumbering after each insertion/deletion can be configured using the option org-footnote-auto-adjust. S Short for first r, then s action. n Normalize the footnotes by collecting all definitions (including inline definitions) into a special section, and then numbering them in sequence. The references will then also be numbers. d Delete the footnote at point, and all definitions of and references to it. 1.6 The Orgstruct minor mode If you like the intuitive way the Org mode structure editing and list formatting works, you might want to use these commands in other modes like Text mode or Mail mode as well. The minor mode orgstruct-mode makes this possible. Toggle the mode with M-x orgstruct-mode RET, or turn it on by default, for example in Message mode, with one of: (add-hook 'message-mode-hook 'turn-on-orgstruct)(add-hook 'message-mode-hook 'turn-on-orgstruct++) 1.7 Org 的语法 A reference document providing a formal description of Org’s syntax is available as a draft on Worg, written and maintained by Nicolas Goaziou. It defines Org’s core internal concepts such as headlines, sections, affiliated keywords, (greater) elements and objects. Each part of an Org file falls into one of the categories above. To explore the abstract structure of an Org buffer, run this in a buffer: M-: (org-element-parse-buffer) RET It will output a list containing the bu↵er’s content represented as an abstract structure. The export engine relies on the information stored in this list. Most interactive commands (e.g., for structure editing) also rely on the syntactic meaning of the surrounding context. You can check syntax in your documents using org-lint command. 2 表格 Org 提供了一个快速直观的表编辑器。 使用 Emacs 内嵌的 calc 的包可支持类似于制表软件的操作。 2.1 内置表编辑器 Org 能够很容易地格式化 ASCII 文本表格。 任何把'|'作为首个非空白字符的行都被视为表的一部分。 '|'也是列分隔符。 表如下所示： 名字 手机号 年龄 brantou 170xxxxxxxx 18 在表格内键入 TAB , RET 或 C-c C-c 时，表格都会自动重新对齐。 TAB 也可以移动到下一个表格区域（ RET 进入下一行），并在表的末尾或水平线之前创建新的表行。 表的缩进由第一行设置。 以"|-"开头的任何行都被视为水平分隔符行，并在下一个重新对齐时展开。所以，要创建上面的表，你只需要键入 | 名字 | 手机号 | 年龄 | |- 然后按 TAB 扩展表格。 更快的是键入 |名称|手机号|年龄 后, 再键入 C-c RET 。 在表格区域中输入文本时，Org以特殊方式处理DEL，Backspace和所有字符键，以便插入和删除避免移动其他字段。 此外，当使用TAB，S-TAB或RET将光标移动到新的表格区域后会自动填充空格。 如果这种行为对您太不可预测，请配置选项 org-enable-table-editor 和 org-table-auto-blank-field 。 2.1.1 创建和转换 =C-c= =|= ~org-table-create-or-convert-from-region~ 将活动区域转换为表。 如果每行包含至少一个TAB字符，则认为 TAB 是分隔符。 如果每一行都包含逗号，则逗号作为分隔（CSV）。 如果不是，则将行以空格为分隔符。 您可以使用前缀参数强制指定分隔符： C-u 强制CSV， C-u C-u 强制TAB， C-u C-u C=u 将提示正则表达式匹配分隔符，数值参数N表示至少N个连续空格，或者 一个TAB将是分隔符。 如果没有活动区域，此命令将创建一个空的组织表。 2.1.2 调整和区域移动 Key Description Command C-c C-c 重新对齐表格，不移动到其他字段。 org-table-align C-c SPC 使用空格填充当前区域 org-table-blank-field &lt;TAB&gt; 重新对齐表格，移动到下一区域。 如有必要，创建一个新行。 org-table-next-field S-TAB 重新对齐，移动到上一区域。 org-table-previous-field RET 重新对齐表格并向下移动到下一行。 如有必要，创建一个新行。 org-table-next-row M-a 移动到当前表区域的开头，或移动到上一个区域。 org-table-beginning-of-field M-e 移动到当前表区域的结尾，或移动到上一个区域。 org-table-end-of-field 2.1.3 列和行编辑 Key Description Command M-left \ M-right 向左/向右移动当前列 org-table-move-column-left\right M-S-left 删除当前列 org-table-delete-column M-S-right 在光标位置的左侧插入一个新列 org-table-insert-column M-up \ M-down 向上/向下移动当前行 org-table-move-row-up\down M-S-up 删除当前行或水平分隔线 org-table-kill-row M-S-down 在当前行上方插入新行。 使用前缀参数，该行在当前行下创建 org-table-insert-row C-c - 在当前行下插入水平线。 使用前缀参数，在当前行之上创建 org-table-insert-hline C-c RET 在当前行下插入水平线，将光标移动到该线下面的行 org-table-hline-and-move C-c ^ 对区域中的表行进行排序 org-table-sort-lines 2.1.4 区域 Key Description Command C-c C-x M-w 将矩形区域从表复制到特殊剪贴板。 点和标记确定矩形的边缘字段。 如果没有活动区域，只复制当前字段。 该过程忽略水平分隔线。 org-table-copy-region C-c C-x C-w 将矩形区域从表格复制到特殊剪贴板，并将矩形中的所有字段都留空。 所以这是“剪切”操作。 org-table-cut-region C-c C-x C-y 将矩形区域粘贴到表中。 左上角在当前字段中结束。 所有涉及的字段将被覆盖。 如果矩形不适合当前表格，则根据需要放大表格。 该过程忽略水平分隔线。 org-table-paste-rectangle M-RET 在光标位置分割当前字段，并将其余部分移动到下面的行。 如果存在活动区域，并且点和标记都在同一列中，则列中的文本将包装为给定行数的最小宽度。 数字前缀参数可用于更改所需行的数量。 如果没有区域，但您指定了前缀参数，则将当前字段设置为空，并将内容追加到上面的字段。 org-table-wrap-region 2.1.5 计算 Key Description Command C-c + 将当前列中的数字或由活动区域定义的矩形中的数字相加。 结果显示在echo区域中，可以用C-y插入。 org-table-sum S-RET 当前字段为空时，从上面的第一个非空区域复制。 当不为空时，将当前区域复制到下一行，并将光标与其一起移动。 org-table-copy-down 2.1.6 杂项 Key Description Command C-c ` 在单独的窗口中编辑当前区域。 这对于不完全可见的区域很有用。当使用C-u前缀调用时，仅仅使整个字段可见，以便可以在当前位置编辑 。 当使用两个C-u前缀调用时，使编辑器窗口跟随光标在表移动，并始终显示光标所在区域。 当光标离开表时，或者当您用C-u C-u C-c`重复此命令时，跟随模式将自动退出。 org-table-edit-field M-x org-table-import RET 将文件作为表导入。 表格应该是TAB或空格分隔。 org-table-import C-c \vert 也可以通过将表格文本粘贴到 Org buffer，使用 C-x C-x 选择粘贴的文本，然后使用C-c &vert; 命令（请参阅上面的创建和转换）。 org-table-create-or-convert-from-region M-x org-table-export RET 导出表，默认情况下作为 TAB 分隔的文件。 用于与例如电子表格或数据库程序进行数据交换。 用于导出文件的格式可以在选项 org-table-export-default-format 中配置。 您还可以使用属性 TABLEEXPORTFILE 和 TABLEEXPORT_ FORMAT 来指定子树中的表导出的文件名和格式。 Org支持导出表格的相当一般格式。 org-table-export 你可能因为‘|’开始的行，妨碍到你，而不喜欢自动表编辑器，你可以用下面的语句来关闭 (setq org-enable-table-editor nil) 然后唯一的表命令 C-c C-c 仍然工作, 做一个手动重新对齐。 2.2 列宽和对齐 列的宽度由表编辑器自动确定。 并且还可以从列中包含的数据类型（数字或者非数字）自动确定列的对齐方式。 有时一个区域或几个区域需要包含很多文本信息，会导致信息展示和编辑的诸多不便。 或者你想设定固定宽度的几列，而不管内容如何。 要设置列的宽度，列中任何位置的一个字段可能只包含字符串“N”，其中“N”是指定列的宽度（以字符为单位）的整数。 接下来重新对齐，然后将此列的宽度设置为此值。 设定固定宽度后，长文本将会裁剪展示，多余部分用字符串 =&gt; 来替代展示。 要查看全文，请将鼠标悬停在该字段上&#x2014;工具提示窗口(tool-tip window)将显示完整的内容。 要编辑这样一个区域，可使用 C-c ` 。 这将打开一个的新窗口。 编辑后用 C-c C-c 来提交编辑内容，并关闭窗口。 当浏览包含有固定宽度表的文件时，必需的隐藏内容尚未发生，需要对齐表来隐藏内容，来变美观。 可设置 org-startup-align-all-tables 是浏览时对文件中的所有表进行重新调整，但这样会减慢文件打开的速度。 也可以在每个文件中设置此选项: #+STARTUP: noalign #+STARTUP: align 如果不喜欢默认自动对齐的方式，您可以使用 &lt;r&gt; ，*&lt;c&gt;* 或者 &lt;l&gt; 来自定义对齐方式。 还可以将对齐和固定宽度组合使用，如下所示： &lt;r10&gt; 。 在导出文档时，将自动删除仅包含这些格式化信息的行。 2.3 列组 当Org导出表时，默认情况下不会有垂直线，因为在视觉上一般来说更令人满意。 然而，偶尔，垂直线对于将表结构化成一组列可能是有用的，就像水平线可以对于一组行所做的那样。 为了指定列组，您可以使用第一个字段仅包含"/"的特殊行。 其他字段可以包含'&lt;'表示此列应该启动一个组，'&gt;'表示组的结束，或'&lt;&gt;'（'&lt;'和'&gt;'之间没有空格） 当前列自己一组。 导出后，列组之间的边界将用垂直线标记。 示例如下： 效果如下（好像没有效果）： N N2 N3 N4 sqrt(n) sqrt[4](N) 2 4 8 16 1.4142136 1.1892071 3 9 27 81 1.7320508 1.3160740 只插入列组启动器也是足够的： N N2 N3 N4 sqrt(n) sqrt[4](N) 2 4 8 16 1.4142136 1.1892071 3 9 27 81 1.7320508 1.3160740 2.4 The Orgtbl minor mode If you like the intuitive way the Org table editor works, you might also want to use it in other modes like Text mode or Mail mode. The minor mode Orgtbl mode makes this possible. You can always toggle the mode with M-x orgtbl-mode RET. To turn it on by default, for example in Message mode, use (add-hook 'message-mode-hook 'turn-on-orgtbl) Furthermore, with some special setup, it is possible to maintain tables in arbitrary syntax with Orgtbl mode. For example, it is possible to construct LATEX tables with the underlying ease and power of Orgtbl mode, including spreadsheet capabilities. 2.5 电子表格 请参阅如下内容： Org as a spreadsheet system: a short introduction Org as a spreadsheet system: using Emacs lisp as formulas 2.6 Org-Plot 请参阅如下内容： Plotting tables in Org-Mode using org-plot http://www.gnuplot.info/ 3 超链接 就如 HTML 一样， Org 提供文件内部链接，到其他文件，Usenet文章，电子邮件等外部链接。 3.1 链接格式 Org 能够识别类似URL链接的文本，并处理成可点击的链接。 通用链接格式如下所示： [[link][description]] 或者 [[link]] 一旦链接完成，链接样式将发生变化，显示 description 而不是 [[link] [description]] 或 link 而不是 [ [link]]] 。 可以直接编辑链接的可见部分。 请注意，这可以是 link 部分（如果没有 description ）或 description 部分。 要编辑不可见的“链接”部分，只需在链接上键入 C-c C-l 。 在链接的头和尾可删除链接不可见的边际括号，使得链接不完整，内部再次显示为纯文本。 插入缺失的括号将再次隐藏链接内部。 要显示所有链接的内部结构，可用菜单条目 Org-&gt;Hyperlinks-&gt;Literal links 。 3.2 内部链接 如果一个链接不是URL形式的，它被当做当前文件中的内部链接。 最重要的情况是像 [ [＃my-custom-id]] 这样的链接，它将链接到 CUSTOMID 属性是 my-custom-id 的条目。 自己要负责确保这些自定义ID在文件中是唯一的。 诸如 [ [MyTarget]] 或 [[MyTarget] [Findmytarget]] 的链接会在当前文件的文本中搜索。 在链接上输入 C-c C-o 或 鼠标点击时，会跳转到链接匹配处。 自定义ID的链接将指向相应的标题。 文本链接的首选匹配是 dedicated target ：双角括号中的相同字符串，如 &larr;&larr; My Target&rarr;&rarr; 。 如果没有 dedicated target ，链接将尝试匹配缓冲区内元素的精确名称。 使用 ＃+NAME 关键字进行命名，必须将其放在引用的元素之前的行中，如以下示例所示: #+NAME: My Target | a | table | |----+------------| | of | four cells | 如果以上都没有成功，Org将搜索与链接文本完全相同的标题(也会搜索 TODO 关键字和标签)。 在导出过程中，内部链接被用于标记对象(并分配一个数字)。 标记的对象将被指向它们的链接引用。 特别地，没有 description 的链接将显示为分配给标记对象的编号。 以下摘录自 Org 缓冲区 - one item - &lt;&lt;target&gt;&gt; another item Here we refer to item [[target]]. 导出时，最后一句将显示为 Here we refer to item 2 。 在非 Org 文件中，搜索将查找链接文本中的单词。 在上面的例子中搜索将是 my Target 。 链接后，将 mark 推到 Org 自己的 mark ring 上。 可使用 C-c ＆ 返回到前一个位置。 直接连续使用这个命令多次可以回到前面记录的位置。 3.2.1 Radio targets Org 可自动将正常文本中某些目标名称的任何出现转换为链接。 所以没有明确创建一个链接，文本就连接到 Radio targents 的位置。 Radio targets 由三角形括号括起来, 如 &larr;&larr;&larr; My Target&rarr;&rarr;&rarr; 导致正常文本中的每个出现的 my target 被激活为链接。 仅当文件首次加载到Emacs中时，才会自动扫描 Radio targets 。 要在编辑过程中更新 Radio targets 列表，请在光标处于 Radio targets 位置时按 C-c C-c 。 3.3 外部链接 Org 支持链接到文件，网站，Usenet和电子邮件，BBDB数据库条目和链接到IRC对话及其日志。 外部链接是类似URL的 locators 。 它们以一个简短的识别字符串后面跟一个冒号开始。 冒号后没有空格。 下面列表显示每个链接类型的示例。 http://www.astro.uva.nl/~dominik on the web doi:10.1000/182 DOI for an electronic resource file:/home/dominik/images/jupiter.jpg file, absolute path /home/dominik/images/jupiter.jpg same as above file:papers/last.pdf file, relative path ./papers/last.pdf same as above file:/myself@some.where:papers/last.pdf file, path on remote machine /myself@some.where:papers/last.pdf same as above file:sometextfile::NNN file, jump to line number file:projects.org another Org file file:projects.org::some words text search in Org file file:projects.org::*task heading search in Org file docview:papers/last.pdf::NNN open in doc-view mode at page id:B7423F4D-2E8A-471B-8810-C40F074717E9 Link to heading by ID news:comp.emacs Usenet link mailto:adent@galaxy.net Mail link mhe:folder MH-E folder link mhe:folder#id MH-E message link rmail:folder RMAIL folder link rmail:folder#id RMAIL message link gnus:group Gnus group link gnus:group#id Gnus article link bbdb:R.*Stallman BBDB link (with regexp) irc:/irc.com/#emacs/bob IRC link info:org#External links Info node or index link shell:ls *.org A shell command elisp:org-agenda Interactive Elisp command elisp:(find-file-other-frame "Elisp.org") Elisp form to evaluate 链接应包含在双括号中，当然可能想要显示的描述性文本而不是URL（参见链接格式），例如： [[http://www.gnu.org/software/emacs/][GNU Emacs]] 如果描述是文件名或指向图像的URL，则HTML导出将内嵌图像作为可点击按钮。 如果没有任何描述和链接指向图像，该图像将被内联到导出的HTML文件中。 Org 能识别出正常文本中的外部链接，并将其作为链接激活。 如果空格必须是链接的一部分（例如在 bbdb:[Richard Stallman] 中）， 或者如果需要消除关于链接结尾的歧义，请将其括在方括号中。 3.4 处理链接 Org 为了正确的创建链接，插入链接和跟随链接，提供了很多快捷键。 Key Description Command C-c l 存储当前位置的链接。 这是一个全局命令，可以在任何缓冲区中使用它来创建链接。 链接将被存储以备将来插入 Org 的缓冲区。 创建什么样的链接取决于当前的缓冲区。 org-store-link C-c C-l 插入链接。 将提示将链接插入缓冲区。 可以键入链接，使用内部链接的文本或上述示例中提到的链接类型前缀之一。 该链接将被插入到缓冲区，以及一个描述性的文本。 如果在调用此命令时选择了某些文本，则所选文本将成为默认描述。 org-insert-link C-u C-c C-l 当使用 C-u 前缀参数调用 C-c C-l 时，将插入文件链接，可以使用文件名来完成文件选择。当前用到是相对路径，若是想要绝对路径可用两个 C-u 前缀。 &#xa0; C-c C-l 当光标在已有链接上时， C-c C-l 允许编辑链接的链接和描述部分。 &#xa0; C-c C-o 打开当前位置的链接。如果要覆盖默认应用程序并使用Emacs访问文件，请使用 C-u 前缀。 如果要避免在Emacs中打开，请使用 C-u C-u 前缀。如果光标位于标题上，但不在链接上，则打开标题中所有链接。 org-open-at-point RET 当 org-return-follow-link 设置时，RET也将跟随当前位置的链接。 &#xa0; C-c C-x C-v 触发图片链接内联显示。当用前缀参数调用时，还会显示具有描述信息的图片链接。 可以通过配置变量 org-startup-with-inline-images 使内联图片在启动时显示。 org-toggle-inline-images C-c % Push the current position onto the mark ring, to be able to return easily. Commands following an internal link do this automatically. org-mark-ring-push C-c &amp; 跳回到记录位置。 A position is recorded by the commands following internal links, and by C-c %. Using this command several times in direct succession moves through a ring of previously recorded positions. org-mark-ring-goto C-c C-x C-n/p 向前/向后移动到缓冲区中的下一个链接。 org-next/previous-link 3.5 在Org之外使用链接 可以插入和跟踪具有Org语法的链接，不仅在组织中，而且可以在任何Emacs缓冲区中。 为此，应该创建两个全局命令，如下： (global-set-key "\C-c L" 'org-insert-link-global)(global-set-key "\C-c o" 'org-open-at-point-global) 3.6 链接缩写 长的URL输入起来会很麻烦，同时在文档中类似的链接可能会很频繁的出现。 为此，你可能需要使用链接缩写。 链接缩写看起来如下所示: [[linkword:tag][description]] tag 是可选的， linkword 必须是一个单词，以字母开头，后跟字母，数字，' - '和'_'。 根据将链接缩写词与替换文本相关联的变量 org-link-abbrev-alist 中的信息来解析缩写。 定义如下所示： (setq org-link-abbrev-alist '(("bugzilla" . "http://10.1.2.9/bugzilla/show_bug.cgi?id=") ("url-to-ja" . "http://translate.google.fr/translate?sl=en&amp;amp;tl=ja&amp;amp;u=%h") ("google" . "http://www.google.com/search?q=") ("gmap" . "http://maps.google.com/maps?q=%s") ("omap" . "http://nominatim.openstreetmap.org/search?q=%s&amp;amp;polygon=1") ("ads" . "http://adsabs.harvard.edu/cgi-bin/nph-abs_connect?author=%s&amp;amp;db_key=AST"))) 如果替换文本包含字符串 ％s ，它将被标签所替换。 使用 ％h 而不是 ％s ,是因为需要对标签进行url编码（参见上面示例，需要对URL参数进行编码）。 使用 ％(my-function) 将标签传递给自定义函数 ，并将其替换为生成的字符串。 如果替换文本不包含任何说明符，则只需把标签添加到替换文本后即可创建链接。 如果只需要单个Org缓冲区的特殊缩写，可以在文件中定义它们 #+LINK: bugzilla http://10.1.2.9/bugzilla/show_bug.cgi?id=&#10;#+LINK: google http://www.google.com/search?q=%s 3.7 文件链接的搜索选项 参见Org-mode手册中相关章节 3.8 自定义搜索 参见Org-mode手册中相关章节 4 待办事项 Org-mode 不把 TODO 列表作为单独的文档来维护。 相反， TODO 列表是笔记的组成部分，因为它通常产生于记录笔记时！ 使用 Org-mode ，只需将树中的任何条目标记为 TODO 就可构造出 TODO 列表。 这种方式，信息不会冗余重复，并且始终显示 TODO 项出现的整个上下文。 当然，这种用于管理 TODO 项的方式会将它们分散在各个笔记文件中。 Org-mode 通过提供一些方法使我们可以把它们看作一个整体来处理。 4.1 基础的待办事项功能 以 TODO 关键字开始的任意标题都会变为代办事项，例如： *** TODO Write letter to Sam Fortune Key Desc Command C-c C-t 转换当前项的TODO状态 ,-&gt; (unmarked) -&gt; TODO -&gt; DONE &#x2013;. org-todo C-u C-c C-t 当TODO关键字没有选择时，使用补全选择特定的关键字; 否则强制循环遍历TODO状态，没有提示。 &#xa0; S-left/right 选择之后/之前的TODO状态，像是循环。 &#xa0; C-c / t 构造出TODO列的稀疏树;折叠整个缓冲区，但显示所有TODO项（ not-DONE 状态）和其上的标题层次结构。 使用前缀参数（或使用 C-c / T ），搜索特定的TODO。 系统提示输入关键字，还可以输入KWD1 &vert; KWD2 &vert; &#x2026;等关键字，列出与这些关键字中的任何一个匹配的项。 使用数字前缀参数N，在选项 org-todo-keywords 中显示第N个关键字的树。 使用两个前缀参数，找到所有TODO状态，无论是完成还是未完成。 org-show-todo-tree C-c a t 展示全局 TODO 列表;将所有agenda文件中的TODO项（ not-DONE 状态）收集到一个缓冲区中。 新的缓冲区将处于 agenda-mode ，它提供了从新的缓冲区检查和操作TODO项的命令。 org-todo-list S-M-RET 在当前项之后插入新的 TODO 项 org-insert-todo-heading 注： 改变 TODO 状态也可触发标签发生变更。 请参阅 org-todo-state-tags-triggers 文档以了解详细信息, 也可可查看How to automatically trigger a change in TODO state in Emacs org-mode。 4.2 待办事项扩展 默认情况下， 待办事项只能为以下两种状态之一： TODO 和 DONE 。 Org-mode 允许使用 TODO 关键字（存储在 org-todo-keywords ）以更复杂的方式对 TODO 项目进行分类管理。 通过特殊设置， TODO 关键字系统可在不同的文件对不同的工作流程进行定制。 4.2.1 工作流状态应用 可以使用 TODO 关键字来表示项目进行过程中工作流状态，例如： (setq org-todo-keywords&#10; &#39;((sequence &#34;TODO&#34; &#34;FEEDBACK&#34; &#34;VERIFY&#34; &#34;|&#34; &#34;DONE&#34; &#34;DELEGATED&#34;))) 垂直条将 TODO 关键字（需要处理的状态）从DONE状态分离（无需进一步操作）。 如果不提供垂直条，则最后一个状态用作 DONE 状态。 使用以上设置，命令 C-c C-t 将待办事项从 TODO 循环到 FEEDBACK ，然后到 VERIFY ，最后到 DONE 和 DELEGATED 。 也可以使用数字前缀参数快速选择特定状态。 例如， C-3 C-c C-t 将立即将状态更改为VERIFY。 或者可以使用 S-left/right 向后/向前遍历序列。 4.2.2 类型标示应用 第二种可能性是使用TODO关键字来指示待办事项的隶属于不同类型。 例如，可能希望指出项目是 work 或 home 。 或者，当在一个项目中与多个人合作时，可能需要通过使用他们的名字作为 TODO 关键字来将项目任务直接分配给个人。 如下配置： (setq org-todo-keywords &#39;((type &#34;Fred&#34; &#34;Sara&#34; &#34;Lucy&#34; &#34;|&#34; &#34;DONE&#34;))) 在这种情况下，不同的关键字不表示序列，而是不同的类型。 所以正常的工作流程是将任务分配给一个人，然后将其标记为DONE。 Org-mode 通过调整命令 C-c C-t 的工作机制来支持这种风格。 当连续使用多次时，它仍将循环遍历所有名称，以便首先为任务选择正确的类型。 但是，当经过一段时间后返回该项目并再次执行 C-c C-t ，它将从任何名称直接切换到 DONE 。 使用前缀参数或完成快速选择一个特定的名称。 还可以使用 C-c / t 的数字前缀来查看稀疏树中特定 TODO 类型的项目。 例如，要查看Lucy所做的一切事情，使用 C-3 C-c / t 。 要将Lucy的所有项目从所有议程文件收集到一个单独的库中，还可以在创建全局TODO列表时使用数字前缀参数： C-3 C-c a t 。 4.2.3 单个文件中多个关键字集合 有时可能需要并行使用不同的TODO关键字集。 例如，可能需要具有基本的 TODO / DONE ，还有一个修复错误的工作流程，以及指示某个项目已被取消的单独状态（因此它不是 DONE ，也不需要执行操作）。 设置如下所示： (setq org-todo-keywords&#10; &#39;((sequence &#34;TODO&#34; &#34;|&#34; &#34;DONE&#34;)&#10; (sequence &#34;REPORT&#34; &#34;BUG&#34; &#34;KNOWNCAUSE&#34; &#34;|&#34; &#34;FIXED&#34;)&#10; (sequence &#34;|&#34; &#34;CANCELED&#34;))) 这些关键字应该是不同的，这有助于 Org-mode 跟踪给定条目应该使用哪个子序列。 在这个设置中， C-c C-t 只能在一个子序列中运行， 所以它从 DONE 切换到（无）到 TODO ， 从 FIXED 切换到（无）到 REPORT 。 因此，需要一种机制来正确初始选择序列。 除了显式的键入关键字或使用补全外，还可应用以下命令： C-u C-u C-c C-t C-S-right/left 这些键从一个 TODO 子集跳到下一个。 在上面的例子中， C-u C-u C-c C-t 或 C-S-right 将从 TODO 或 DONE 跳到 REPORT ， 而第二行中的任何一个字都可跳转到 CANCELED 。 S-right/left S-right/left 并从所有集合中遍历所有关键字，例如在上面的例子中，S-right将从DONE切换到REPORT。 4.2.4 快速访问代办状态 如果要快速将条目更改为任意TODO状态，而不是循环遍历状态，则可以设置单个字符来快速访问状态的键。 这是通过在每个关键字后面的括号中添加选择字符来完成的。 (setq org-todo-keywords&#10; &#39;((sequence &#34;TODO(t)&#34; &#34;|&#34; &#34;DONE(d)&#34;)&#10; (sequence &#34;REPORT(r)&#34; &#34;BUG(b)&#34; &#34;KNOWNCAUSE(k)&#34; &#34;|&#34; &#34;FIXED(f)&#34;)&#10; (sequence &#34;|&#34; &#34;CANCELED(c)&#34;))) 如果按C-c C-t，后按选择键，则条目将切换到此状态。 SPC可用于从条目中删除任何TODO关键字。 4.2.5 为文件设置独立的关键字集合 在不同文件中使用 TODO 机制的不同方面是非常有用的。 对于文件本地设置，需要在文件中添加专用行，仅为该文件设置关键字和仅对当前文件起效。 例如，要设置上述两个示例之一，需要在文件中包含以下任何一行： #+TODO: TODO FEEDBACK VERIFY | DONE CANCELED 或者 #+TYP_TODO: Fred Sara Lucy Mike | DONE 并行使用几组的设置如下： #+TODO: TODO | DONE&#10;#+TODO: REPORT BUG KNOWNCAUSE | FIXED&#10;#+TODO: | CANCELED 在更改其中一行后，在行中使用 C-c C-c ，以使变更生效。 4.2.6 代办事项关键字的样式 Org-mode 突出显示具有特殊样式的TODO关键字：关键字的 org-todo 表示某个项目仍然需要执行，对于表示项目完成的关键字 org-done 。 如果使用两种以上的不同状态，可能需要为其中某些状态使用特殊样式。 可使用选项 org-todo-keyword-faces 来完成。 例如： (setq org-todo-keyword-faces&#10; &#39;((&#34;TODO&#34; . org-warning) (&#34;STARTED&#34; . &#34;yellow&#34;)&#10; (&#34;CANCELED&#34; . (:foreground &#34;blue&#34; :weight bold)))) 4.2.7 待办事项的依赖关系 Org 结构（层次结构和列表）可以轻松定义TODO依赖关系。 通常，在将所有子任务标记为 DONE 之前，不应将父 TODO 任务标记为 DONE 。 有时，对于一些（子）任务有一个逻辑顺序，所以在完成上面的所有兄弟任务之前，一个任务不能被执行。 如果设置自定义选项 org-enforce-todo-dependencies ，Org将会阻塞任务从 TODO 更改为 DONE ，而它的子项不是DONE。 此外，如果条目具有 ORDERED 属性，则每个子项将被阻塞，直到所有较早的兄弟节点被标记为 DONE 。 设置 org-enforce-todo-dependencies,如下所示： (setq org-enforce-todo-dependencies t) 依赖关系示例如下： * TODO Blocked until (two) is done&#10;** DONE one&#10;** TODO two&#10;&#10;* Parent&#10; :PROPERTIES:&#10; :ORDERED: t&#10; :END:&#10;** TODO a&#10;** TODO b, needs to wait for (a)&#10;** TODO c, needs to wait for (a) and (b) 可以使用 NOBLOCKING 属性确保从不阻塞输入： * This entry is never blocked&#10; :PROPERTIES:&#10; :NOBLOCKING: t&#10; :END: C-c C-x o 切换当前条目的 ORDERED 属性。 ORDERED 属性只适用于当前项，而不是像标签一样可继承。 但是，如果要使用标签跟踪该属性的值，以便更好地查看，请自定义选项 org-track-ordered-property-with-tag 。 C-u C-u C-u C-c C-t改变 TODO 状态，规避任何状态阻塞。 如果设置选项 org-agenda-dim-blocked-tasks ，则由于这些依赖关系而无法关闭的TODO条目将以渐变字体显示，甚至在议程视图中不可见。 还可以通过查看复选框来阻止 TODO 状态的更改。 如果设置了选项 org-enforce-todo-checkbox-dependencies ，则将禁止具有未选中复选框的条目切换到 DONE 。 如果需要更复杂的依赖关系结构，例如不同树或文件中的条目之间的依赖关系，请查看模块 org-depend.el 。 4.3 进度记录 4.3.1 关闭项目 4.3.2 追踪TODO状态变化 4.3.3 追踪你的习惯 4.4 优先级 4.5 任务分解 4.6 复选框 5 标签 6 属性 7 日期和时间 8 捕获——转发——存档 9 议程视图 Footnotes: 1 org-mode 官方链接地址: http://orgmode.org/ Last Updated 2017-10-13 Fri 17:33.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.1.2)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Leetcode编程练习]]></title>
      <url>%2F2017%2F03%2F21%2Fleetcode%2F</url>
      <content type="text"><![CDATA[LeetCode 编程训练的积累，目前在努力做题中，日后整理！ 1 maxCount func maxCount(m int, n int, ops [][]int) int { M := make([]([]int), 0,m) for i := 0; i &amp;lt; m; i+=1 { r := make([]int,n) M = append(M, r) } var max int var max_count int for index, _ := range ops { a, b := ops[index][0],ops[index][1] fmt.Println(a,b) rs := M[0:a] for index, _ := range rs { ris := rs[index] for index, _ := range ris { ri := ris[index] if index == b { break } ri +=1 ris[index]=ri if ri &amp;gt; max { max = ri max_count = 0 } if ri == max { max_count +=1 } } rs[index] = ris } } return max_count} func maxCount(m int, n int, ops [][]int) int { m_r, m_c := m, n for _, op := range ops { op_r := op[0] op_c := op[1] if op_r &amp;lt; m_r { m_r = op_r } if op_c &amp;lt; m_c { m_c = op_c } } return m_r * m_c} func main() { fmt.Println(maxCount(3,3, [][]int{[]int{2,2},[]int{3,3}}))} 2 lengthOfLongestSubstring func lengthOfLongestSubstring(s string) int { byte_arr := []byte(s) max_sub_arr := make([]byte, 0) byte_sub_arr := make([]byte, 0) byte_m := make(map[byte]int) var start_index int for index, byte_i := range byte_arr { if ori_index, ok := byte_m[byte_i]; !ok { byte_m[byte_i] = index byte_sub_arr = append(byte_sub_arr, byte_i) } else { if len(max_sub_arr) &amp;lt; len(byte_sub_arr) { max_sub_arr = byte_sub_arr } byte_sub_arr = byte_arr[ori_index+1 : index+1] for ; start_index &amp;lt;= ori_index; start_index += 1 { delete(byte_m, byte_arr[start_index]) } byte_m[byte_i] = index } } if len(max_sub_arr) &amp;lt; len(byte_sub_arr) { max_sub_arr = byte_sub_arr } return len(max_sub_arr)} func main() { fmt.Println(lengthOfLongestSubstring("abcabcbb"))} 3 findMedianSortedArrays func findMedianSortedArrays(nums1 []int, nums2 []int) float64 { total := len(nums1) + len(nums2) if total%2 &amp;gt; 0 { return findKth(nums1, nums2, total/2+1) } else { return (findKth(nums1, nums2, total/2) + findKth(nums1, nums2, total/2+1)) / float64(2) }}func min(a, b int) int { if a &amp;gt; b { return b } else { return a }}func findKth(a []int, b []int, k int ) float64 { m, n := len(a), len(b) //always assume that m is equal or smaller than n if m &amp;gt; n { return findKth(b, a, k) } if m == 0 { return float64(b[k-1]) } if k == 1 { return float64(min(a[0], b[0])) } //divide k into two parts pa := min(k/2, m) pb := k - pa if a[pa-1] &amp;lt; b[pb-1] { return findKth(a[pa:], b, k-pa) } else if a[pa-1] &amp;gt; b[pb-1] { return findKth(a, b[pb:], k-pb) } else { return float64(a[pa-1]) }} func main() { fmt.Println(findMedianSortedArrays([]int{1,3}, []int{2})) fmt.Println(findMedianSortedArrays([]int{1,2}, []int{3, 4})) fmt.Println(findMedianSortedArrays([]int{2,4,8}, []int{3,6,9})) fmt.Println(findMedianSortedArrays([]int{2,4,7,8}, []int{3,5,6,9}))} 4 findMin func findMin(nums []int) int { if len(nums) &amp;lt; 1 { return 0 } if len(nums) == 1 { return nums[0] } if len(nums) == 2 { return min(nums[0], nums[1]) } size := len(nums) max_min_num := nums[0] mid_num := nums[size/2] if mid_num &amp;gt; max_min_num { return findMin(nums[size/2+1:]) } else { if nums[size/2-1] &amp;gt; nums[size/2] { return nums[size/2] } else { return findMin(nums[:size/2]) } }}func min(a, b int) int{ if a &amp;gt; b{ return b } else { return a }} 5 findDiagonalOrder func findDiagonalOrder(matrix [][]int) []int { rst_arr := make([]int, 0) if len(martix) &amp;lt; 1 || len(matrix[0]) &amp;lt; 1 { return rst_arr } r_n := len(matrix) c_n := len(matrix[0]) max_n := max(r_n, c_n) order := "asc" // desc var r_index, c_index int for { if r_index == r_n-1 &amp;amp;&amp;amp; c_index == c_n-1 { rst_arr = append(rst_arr, matrix[r_index][c_index]) break } switch order { case "asc": order = "desc" for { rst_arr = append(rst_arr, matrix[r_index][c_index]) if c_index == c_n-1 || r_index == 0 { break } c_index += 1 r_index -= 1 } if r_index == 0 { if c_index == c_n-1 { r_index += 1 } else { c_index += 1 } } else if c_index == c_n-1 { r_index += 1 } case "desc": order = "asc" for { rst_arr = append(rst_arr, matrix[r_index][c_index]) if c_index == 0 || r_index == r_n-1 { break } c_index -= 1 r_index += 1 } if c_index == 0 { if r_index == r_n-1 { c_index += 1 } else { r_index += 1 } } else if r_index == r_n-1 { c_index += 1 } } } return rst_arr} 6 thirdMax func parent(i int) int { return i / 2}func left(i int) int { return 2*i + 1}func right(i int) int { return 2 * (i + 1)}func min_heapify(A []int, i int) { l := left(i) r := right(i) var least int if l &amp;lt; len(A) &amp;amp;&amp;amp; A[l] &amp;lt; A[i] { least = l } else { least = i } if r &amp;lt; len(A) &amp;amp;&amp;amp; A[r] &amp;lt; A[least] { least = r } if least != i { A[i], A[least] = A[least], A[i] min_heapify(A, least) }}func thirdMax(nums []int) int { var size int = 3 min_heap := make([]int, 0) heap_M := make(map[int]bool) var index int for { if !heap_M[nums[index]] { heap_M[nums[index]] = true min_heap = append(min_heap, nums[index]) } index += 1 if len(min_heap) == size { break } if index == len(nums) { break } } for i := len(min_heap) / 2; i &amp;gt;= 0; i -= 1 { min_heapify(min_heap, i) } if index == len(nums) { if len(min_heap) == size { return min_heap[0] } else { var max int for _, num := range min_heap { if num &amp;gt; max { max = num } } return max } } for i := index; i &amp;lt; len(nums); i += 1 { num := nums[i] if num &amp;gt; min_heap[0] &amp;amp;&amp;amp; !heap_M[num] { delete(heap_M, min_heap[0]) heap_M[num] = true min_heap[0] = num min_heapify(min_heap, 0) } } return min_heap[0]} func main() { fmt.Println(thirdMax([]int{3, 2, 1})) fmt.Println(thirdMax([]int{1, 2})) fmt.Println(thirdMax([]int{2, 2, 3, 1})) fmt.Println(thirdMax([]int{5,2,4,1,3,6,0}))} 7 combinationSum 7.1 combinationSum type PreCombin struct { Sum int Arr []int}func IsEqualCombin(lc, rc *PreCombin) bool { if lc.Sum != rc.Sum { return false } if len(lc.Arr) != len(rc.Arr) { return false } for i := 0; i &amp;lt; len(lc.Arr); i += 1 { l_num := lc.Arr[i] r_num := rc.Arr[i] if l_num != r_num { return false } } return true}func sortInsert(nums []int, num int) []int { if len(nums) &amp;lt; 1 { return []int{num} } new_nums := make([]int, len(nums)+1) copy(new_nums, nums) new_nums[len(nums)] = num num_index := len(new_nums) - 1 for i := len(new_nums) - 2; i &amp;gt;= 0; i -= 1 { if new_nums[i] &amp;lt;= new_nums[num_index] { break } new_nums[i], new_nums[num_index] = new_nums[num_index], new_nums[i] num_index = i } return new_nums}func combinationSum(candidates []int, target int) [][]int { combin_arr := make([]([]int), 0) pre_combin_arr := make([]*PreCombin, 0) for index, _ := range candidates { num := candidates[index] if num &amp;gt; target { continue } sub_pre_combin_arr := make([]*PreCombin, 0) for index, _ := range pre_combin_arr { pre_combin := pre_combin_arr[index] if pre_combin.Sum == target { continue } for { if pre_combin.Sum+num &amp;lt;= target { _pre_combin := &amp;amp;PreCombin{ Sum: pre_combin.Sum + num, Arr: sortInsert(pre_combin.Arr, num), } sub_pre_combin_arr = append(sub_pre_combin_arr, _pre_combin) pre_combin = _pre_combin } else { break } } } pre_combin := &amp;amp;PreCombin{ Sum: num, Arr: []int{num}, } sub_pre_combin_arr = append(sub_pre_combin_arr, pre_combin) for { if pre_combin.Sum+num &amp;lt;= target { _pre_combin := &amp;amp;PreCombin{ Sum: pre_combin.Sum + num, Arr: sortInsert(pre_combin.Arr, num), } sub_pre_combin_arr = append(sub_pre_combin_arr, _pre_combin) pre_combin = _pre_combin } else { break } } for index, _ := range sub_pre_combin_arr { sub_pre_combin := sub_pre_combin_arr[index] var hasEqual bool for index, _ := range pre_combin_arr { pre_combin := pre_combin_arr[index] if IsEqualCombin(sub_pre_combin, pre_combin) { hasEqual = true break } } if !hasEqual { pre_combin_arr = append(pre_combin_arr, sub_pre_combin) } } } for index, _ := range pre_combin_arr { pre_combin := pre_combin_arr[index] if pre_combin.Sum == target { combin_arr = append(combin_arr, pre_combin.Arr) } } return combin_arr} func main() { fmt.Println(combinationSum([]int{2, 3, 6, 7}, 7))} 7.2 combinationSum2 type PreCombin struct { Sum int Arr []int}func IsEqualCombin(lc, rc *PreCombin) bool { if lc.Sum != rc.Sum { return false } if len(lc.Arr) != len(rc.Arr) { return false } for i := 0; i &amp;lt; len(lc.Arr); i += 1 { l_num := lc.Arr[i] r_num := rc.Arr[i] if l_num != r_num { return false } } return true}func sortInsert(nums []int, num int) []int { if len(nums) &amp;lt; 1 { return []int{num} } new_nums := make([]int, len(nums)+1) copy(new_nums, nums) new_nums[len(nums)] = num num_index := len(new_nums) - 1 for i := len(new_nums) - 2; i &amp;gt;= 0; i -= 1 { if new_nums[i] &amp;lt;= new_nums[num_index] { break } new_nums[i], new_nums[num_index] = new_nums[num_index], new_nums[i] num_index = i } return new_nums}func combinationSum2(candidates []int, target int) [][]int { combin_arr := make([]([]int), 0) pre_combin_arr := make([]*PreCombin, 0) for index, _ := range candidates { num := candidates[index] if num &amp;gt; target { continue } sub_pre_combin_arr := make([]*PreCombin, 0) for index, _ := range pre_combin_arr { pre_combin := pre_combin_arr[index] if pre_combin.Sum == target { continue } if pre_combin.Sum+num &amp;lt;= target { _pre_combin := &amp;amp;PreCombin{ Sum: pre_combin.Sum + num, Arr: sortInsert(pre_combin.Arr, num), } sub_pre_combin_arr = append(sub_pre_combin_arr, _pre_combin) } } pre_combin := &amp;amp;PreCombin{ Sum: num, Arr: []int{num}, } sub_pre_combin_arr = append(sub_pre_combin_arr, pre_combin) for index, _ := range sub_pre_combin_arr { sub_pre_combin := sub_pre_combin_arr[index] var hasEqual bool for index, _ := range pre_combin_arr { pre_combin := pre_combin_arr[index] if IsEqualCombin(sub_pre_combin, pre_combin) { hasEqual = true break } } if !hasEqual { pre_combin_arr = append(pre_combin_arr, sub_pre_combin) } } } for index, _ := range pre_combin_arr { pre_combin := pre_combin_arr[index] if pre_combin.Sum == target { combin_arr = append(combin_arr, pre_combin.Arr) } } return combin_arr} func main() { fmt.Println(combinationSum2([]int{10, 1, 2, 7, 6, 1, 5}, 8)) fmt.Println(combinationSum2([]int{4,4,2,1,4,2,2,1,3}, 6)) fmt.Println(combinationSum2([]int{3,1,3,5,1,1}, 8))} 7.3 combinationSum3 type PreCombin struct { Sum int Arr []int}func IsEqualCombin(lc, rc *PreCombin) bool { if lc.Sum != rc.Sum { return false } if len(lc.Arr) != len(rc.Arr) { return false } for i := 0; i &amp;lt; len(lc.Arr); i += 1 { l_num := lc.Arr[i] r_num := rc.Arr[i] if l_num != r_num { return false } } return true}func sortInsert(nums []int, num int) []int { if len(nums) &amp;lt; 1 { return []int{num} } new_nums := make([]int, len(nums)+1) copy(new_nums, nums) new_nums[len(nums)] = num num_index := len(new_nums) - 1 for i := len(new_nums) - 2; i &amp;gt;= 0; i -= 1 { if new_nums[i] &amp;lt;= new_nums[num_index] { break } new_nums[i], new_nums[num_index] = new_nums[num_index], new_nums[i] num_index = i } return new_nums}func combinationSum3(k int, n int) [][]int { candidates := make([]int, 9) for index, _ := range candidates { candidates[index] = index + 1 } target := n combin_arr := make([]([]int), 0) pre_combin_arr := make([]*PreCombin, 0) for index, _ := range candidates { num := candidates[index] if num &amp;gt; target { continue } sub_pre_combin_arr := make([]*PreCombin, 0) for index, _ := range pre_combin_arr { pre_combin := pre_combin_arr[index] if pre_combin.Sum == target { continue } if pre_combin.Sum+num &amp;lt;= target { _pre_combin := &amp;amp;PreCombin{ Sum: pre_combin.Sum + num, Arr: sortInsert(pre_combin.Arr, num), } sub_pre_combin_arr = append(sub_pre_combin_arr, _pre_combin) } } pre_combin := &amp;amp;PreCombin{ Sum: num, Arr: []int{num}, } sub_pre_combin_arr = append(sub_pre_combin_arr, pre_combin) for index, _ := range sub_pre_combin_arr { sub_pre_combin := sub_pre_combin_arr[index] var hasEqual bool for index, _ := range pre_combin_arr { pre_combin := pre_combin_arr[index] if IsEqualCombin(sub_pre_combin, pre_combin) { hasEqual = true break } } if !hasEqual { pre_combin_arr = append(pre_combin_arr, sub_pre_combin) } } } for index, _ := range pre_combin_arr { pre_combin := pre_combin_arr[index] if pre_combin.Sum == target &amp;amp;&amp;amp; len(pre_combin.Arr) == k { combin_arr = append(combin_arr, pre_combin.Arr) } } return combin_arr} func main() { fmt.Println(combinationSum3(3, 7)) fmt.Println(combinationSum3(3, 9))} 7.4 combinationSum4 7.4.1 V1 type PreCombin struct { Sum int Arr []int}func IsEqualCombin(lc, rc *PreCombin) bool { if lc.Sum != rc.Sum { return false } if len(lc.Arr) != len(rc.Arr) { return false } for i := 0; i &amp;lt; len(lc.Arr); i += 1 { l_num := lc.Arr[i] r_num := rc.Arr[i] if l_num != r_num { return false } } return true}func sortInsert(nums []int, num int) []int { if len(nums) &amp;lt; 1 { return []int{num} } new_nums := make([]int, len(nums)+1) copy(new_nums, nums) new_nums[len(nums)] = num num_index := len(new_nums) - 1 for i := len(new_nums) - 2; i &amp;gt;= 0; i -= 1 { if new_nums[i] &amp;lt;= new_nums[num_index] { break } new_nums[i], new_nums[num_index] = new_nums[num_index], new_nums[i] num_index = i } return new_nums}func permut_num(nums []int) int { size := len(nums) num_M := make(map[int]int) for _, num := range nums { num_M[num] += 1 } if len(num_M) == 1 { return 1 } var max_count int var max_count_num int for num, count := range num_M { if count &amp;gt; max_count { max_count = count max_count_num = num } } delete(num_M, max_count_num) var factor int = 1 for i := size; i &amp;gt; max_count; i -= 1 { factor *= i } var un_factor int = 1 for _, count := range num_M { for i := count; i &amp;gt; 0; i -= 1 { un_factor *= i } } return factor / un_factor}func combinationSum4(nums []int, target int) int { pre_combin_arr := make([]*PreCombin, 0) for index, _ := range nums { num := nums[index] if num &amp;gt; target { continue } sub_pre_combin_arr := make([]*PreCombin, 0) for index, _ := range pre_combin_arr { pre_combin := pre_combin_arr[index] if pre_combin.Sum == target { continue } for { if pre_combin.Sum+num &amp;lt;= target { _pre_combin := &amp;amp;PreCombin{ Sum: pre_combin.Sum + num, Arr: sortInsert(pre_combin.Arr, num), } sub_pre_combin_arr = append(sub_pre_combin_arr, _pre_combin) pre_combin = _pre_combin } else { break } } } pre_combin := &amp;amp;PreCombin{ Sum: num, Arr: []int{num}, } sub_pre_combin_arr = append(sub_pre_combin_arr, pre_combin) for { if pre_combin.Sum+num &amp;lt;= target { _pre_combin := &amp;amp;PreCombin{ Sum: pre_combin.Sum + num, Arr: sortInsert(pre_combin.Arr, num), } sub_pre_combin_arr = append(sub_pre_combin_arr, _pre_combin) pre_combin = _pre_combin } else { break } } for index, _ := range sub_pre_combin_arr { sub_pre_combin := sub_pre_combin_arr[index] var hasEqual bool for index, _ := range pre_combin_arr { pre_combin := pre_combin_arr[index] if IsEqualCombin(sub_pre_combin, pre_combin) { hasEqual = true break } } if !hasEqual { pre_combin_arr = append(pre_combin_arr, sub_pre_combin) } } } var permuts int for index, _ := range pre_combin_arr { pre_combin := pre_combin_arr[index] if pre_combin.Sum == target { permuts += permut_num(pre_combin.Arr) } } return permuts} 7.4.2 V2 func permut_num(num_M map[int]int) int { if len(num_M) == 1 { return 1 } var sum_count int var max_count int var max_count_num int for num, count := range num_M { sum_count += count if count &amp;gt; max_count { max_count = count max_count_num = num } } delete(num_M, max_count_num) var factor int = 1 for i := sum_count; i &amp;gt; max_count; i -= 1 { factor *= i } var un_factor int = 1 for _, count := range num_M { for i := count; i &amp;gt; 0; i -= 1 { un_factor *= i } } return factor / un_factor}func combinationSum4(nums []int, target int) int { var result_num int if len(nums) == 0 { return 0 } if len(nums) == 1 { if target%nums[0] == 0 { return 1 } else { return 0 } } fir_num := nums[0] var factor int = 0 for sub_sum := 0; sub_sum &amp;lt;= target; sub_sum += fir_num { combin_M_arr := sub_combin(nums[1:], target-fir_num*factor) if len(combin_M_arr) &amp;gt; 0 { for index, _ := range combin_M_arr { combin_M := combin_M_arr[index] combin_M[fir_num] = factor result_num += permut_num(combin_M) } } if fir_num*factor == target { result_num += 1 } factor += 1 } return result_num}func sub_combin(nums []int, target int) [](map[int]int) { if target &amp;lt; 1 { return []map[int]int{} } if len(nums) == 1 { if target%nums[0] == 0 { return []map[int]int{ map[int]int{ nums[0]: target / nums[0], }, } } else { return []map[int]int{} } } fir_num := nums[0] var factor int = 0 combin_M_arr := make([]map[int]int, 0) for sub_sum := 0; sub_sum &amp;lt;= target; sub_sum += fir_num { sub_combin_M_arr := sub_combin(nums[1:], target-fir_num*factor) if len(sub_combin_M_arr) &amp;gt; 0 { for index, _ := range sub_combin_M_arr { combin_M := sub_combin_M_arr[index] combin_M[fir_num] = factor combin_M_arr = append(combin_M_arr, combin_M) } } if fir_num*factor == target { combin_M := map[int]int{ fir_num: factor, } combin_M_arr = append(combin_M_arr, combin_M) } factor += 1 } return combin_M_arr} func main() { fmt.Println(combinationSum4([]int{1,2,3}, 4)) fmt.Println(combinationSum4([]int{1,50}, 200)) fmt.Println(combinationSum4([]int{3,33,333}, 10000))} 7.4.3 V3 动态规划解法 dp[i] += dp[i-num] dp[i+num] += dp[i] func combinationSum4(nums []int, target int) int { dp := make([]int, target+1) dp[0] = 1 for i := 1; i &amp;lt;= target; i += 1 { for _, num := range nums { if i &amp;gt;= num { dp[i] += dp[i-num] } } } return dp[target]} func main() { fmt.Println(combinationSum4([]int{1,2,3}, 4)) fmt.Println(combinationSum4([]int{1,50}, 200)) fmt.Println(combinationSum4([]int{3,33,333}, 10000))} 8 combine func combine(n int, k int) [][]int { return subCombine(1, n, k)}func subCombine(start, end, k int) [][]int { if k &amp;lt; 1 || end-start+1 &amp;lt; k { return [][]int{} } combine_arr := make([][]int, 0) if k == 1 { for i := start; i &amp;lt;= end; i += 1 { combine_arr = append(combine_arr, []int{i}) } } for i := start; i &amp;lt;= end-(k-1); i += 1 { sub_combine_arr := subCombine(i+1, end, k-1) if len(sub_combine_arr) &amp;gt; 0 { for index, _ := range sub_combine_arr { combines := append([]int{i}, sub_combine_arr[index]...) combine_arr = append(combine_arr, combines) } } } return combine_arr} func main() { fmt.Println(combine(4,2))} 9 pathSum 9.1 hasPathSum type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func hasPathSum(root *TreeNode, sum int) bool { if root == nil { return false } if root.Left == nil &amp;amp;&amp;amp; root.Right == nil { if root.Val == sum { return true } else { return false } } return hasPathSum(root.Left, sum-root.Val) || hasPathSum(root.Right, sum-root.Val)} func main() { lc := &amp;amp;TreeNode{ Val: 4, Left: &amp;amp;TreeNode{ Val: 11, Left: &amp;amp;TreeNode{ Val: 7, }, Right: &amp;amp;TreeNode{ Val: 2, }, }, } rc := &amp;amp;TreeNode{ Val: 8, Left: &amp;amp;TreeNode{ Val: 13, }, Right: &amp;amp;TreeNode{ Val: 4, Left: &amp;amp;TreeNode{ Val: 5, }, Right: &amp;amp;TreeNode{ Val: 1, }, }, } root := &amp;amp;TreeNode{ Val: 5, Left: lc, Right: rc, } fmt.Println(hasPathSum(root, 22))} 9.2 pathSum type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func pathSum(root *TreeNode, sum int) [][]int { if root == nil { return [][]int{} } if root.Left == nil &amp;amp;&amp;amp; root.Right == nil { if root.Val == sum { return [][]int{[]int{root.Val}} } else { return [][]int{} } } var lc_path_arr, rc_path_arr [][]int if root.Left != nil { lc_path_arr = pathSum(root.Left, sum-root.Val) } if root.Right != nil { rc_path_arr = pathSum(root.Right, sum-root.Val) } path_arr := make([][]int, 0) if len(lc_path_arr) &amp;gt; 0 { for index, _ := range lc_path_arr { path := lc_path_arr[index] path = append([]int{root.Val}, path...) path_arr = append(path_arr, path) } } if len(rc_path_arr) &amp;gt; 0 { for index, _ := range rc_path_arr { path := rc_path_arr[index] path = append([]int{root.Val}, path...) path_arr = append(path_arr, path) } } return path_arr} func main() { lc := &amp;amp;TreeNode{ Val: 4, Left: &amp;amp;TreeNode{ Val: 11, Left: &amp;amp;TreeNode{ Val: 7, }, Right: &amp;amp;TreeNode{ Val: 2, }, }, } rc := &amp;amp;TreeNode{ Val: 8, Left: &amp;amp;TreeNode{ Val: 13, }, Right: &amp;amp;TreeNode{ Val: 4, Left: &amp;amp;TreeNode{ Val: 5, }, Right: &amp;amp;TreeNode{ Val: 1, }, }, } root := &amp;amp;TreeNode{ Val: 5, Left: lc, Right: rc, } fmt.Println(pathSum(root, 22))} 9.3 number of path type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func pathSum(root *TreeNode, sum int) int { if root == nil { return 0 } return sumUp(root, 0, sum) + pathSum(root.Left, sum) + pathSum(root.Right, sum)}func sumUp(node *TreeNode, pre, sum int) int { if node == nil { return 0 } var cur int = pre + node.Val var res_num int if cur == sum { res_num += 1 } return res_num + sumUp(node.Left, cur, sum) + sumUp(node.Right, cur, sum)} func main() { lc := &amp;amp;TreeNode{ Val: 5, Left: &amp;amp;TreeNode{ Val: 3, Left: &amp;amp;TreeNode{ Val: 3, }, Right: &amp;amp;TreeNode{ Val: -2, }, }, Right: &amp;amp;TreeNode{ Val: 2, Right: &amp;amp;TreeNode{ Val: 1, }, }, } rc := &amp;amp;TreeNode{ Val: -3, Right: &amp;amp;TreeNode{ Val: 11, }, } root := &amp;amp;TreeNode{ Val: 10, Left: lc, Right: rc, } fmt.Println(pathSum(root, 8))} 9.4 min path sum func minPathSum(grid [][]int) int { dp := make([][]int, len(grid)) for index, _ := range dp { dp[index] = make([]int, len(grid[0])) } for r_i, _ := range grid { for c_i, _ := range grid[r_i] { if r_i == 0 { if c_i &amp;gt; 0 { dp[r_i][c_i] = grid[r_i][c_i] + dp[r_i][c_i-1] } else { dp[r_i][c_i] = grid[r_i][c_i] } continue } if c_i == 0 { dp[r_i][0] = grid[r_i][0] + dp[r_i-1][0] continue } dp[r_i][c_i] = grid[r_i][c_i] + min(dp[r_i-1][c_i], dp[r_i][c_i-1]) } } return dp[len(dp)-1][len(dp[0])-1]}func min(a, b int) int { if a &amp;gt; b { return b } else { return a }} func main() { fmt.Println(minPathSum([][]int{ []int{1, 3, 1}, []int{1, 5, 1}, []int{4, 2, 1}, }))} 9.5 binary-tree maximum path sum type TreeNode struct { Val int Left *TreeNode Right *TreeNode}type BpNode struct { MaxSum_c int MaxSum_b int Val int Left *BpNode Right *BpNode}func copyTree2Bp(root *TreeNode) *BpNode { if root == nil { return nil } return &amp;amp;BpNode{ Val: root.Val, Left: copyTree2Bp(root.Left), Right: copyTree2Bp(root.Right), }}func max(a, b int) int { if a &amp;lt; b { return b } else { return a }}func bpMaxSum(bpr *BpNode) int { if bpr == nil { return 0 } max_n := max(bpr.MaxSum_c, bpr.MaxSum_b) if bpr.Left != nil { max_n = max(max_n, bpMaxSum(bpr.Left)) } if bpr.Right != nil { max_n = max(max_n, bpMaxSum(bpr.Right)) } return max_n}func maxPathSum(root *TreeNode) int { bpr := copyTree2Bp(root) maxPathSumHelper(bpr) return bpMaxSum(bpr)}func maxPathSumHelper(bpr *BpNode) ( max_sum_b int,) { if bpr == nil { return 0 } lmax_sum_b := maxPathSumHelper(bpr.Left) rmax_sum_b := maxPathSumHelper(bpr.Right) bpr.MaxSum_c = bpr.Val + max(0, lmax_sum_b) + max(0, rmax_sum_b) bpr.MaxSum_b = bpr.Val + max(0, max(lmax_sum_b, rmax_sum_b)) return bpr.MaxSum_b} func main() { root := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{ Val: 2, }, Right: &amp;amp;TreeNode{ Val: 3, }, } fmt.Println(maxPathSum(root))} 9.6 sum root to leaf numbers type TreeNode struct { Val int Left *TreeNode Right *TreeNode}func sumNumbers(root *TreeNode) int { path_arr := collectPath(root) var sum int for index, _ := range path_arr { path := path_arr[index] var sub_sum int for _, num := range path { sub_sum = num + sub_sum*10 } sum += sub_sum } return sum}func collectPath(root *TreeNode) [][]int { if root == nil { return [][]int{} } if root.Left == nil &amp;amp;&amp;amp; root.Right == nil { return [][]int{ []int{root.Val}, } } lpath_arr := collectPath(root.Left) rpath_arr := collectPath(root.Right) lpath_arr = append(lpath_arr, rpath_arr...) for index, _ := range lpath_arr { path := lpath_arr[index] path = append([]int{root.Val}, path...) lpath_arr[index] = path } return lpath_arr} func main() { root := &amp;amp;TreeNode{ Val: 1, Left: &amp;amp;TreeNode{ Val: 2, }, Right: &amp;amp;TreeNode{ Val: 3, }, } fmt.Println(sumNumbers(root))} 10 poor pigs func poorPigs(buckets int, minutesToDie int, minutesToTest int) int { time := minutesToTest/minutesToDie + 1 res := 0 for { if int(math.Pow(float64(time), float64(res))) &amp;lt; buckets { res = res + 1 } else { break } } return res} Last Updated 2017-07-17 Mon 16:15.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Org-mode的语法解读]]></title>
      <url>%2F2017%2F03%2F11%2Forg-syntax%2F</url>
      <content type="text"><![CDATA[原文Org Syntax (draft)1由 Nicolas Goaziou 编辑，维护。本文只做学习之用。 本文档描述和说明被org的解析器和导出器框架使用的语法，当然还有几个对于当前语法的意见和建议。 在 Org 语法中核心概念是： 只有 headlines, sections, planning lines 和 property drawers 四种语法结构是上下文无关的2, 3； 其他语法结构只能存在于特定 Environments 之中。 Environments 从大到小(作用范围的尺度来做分类标准,从最宽到最窄)，大致可分为三类: "Greater element", "Element" 和 "Object"。 Element 被用到了两个类的命名中，Greater 和 non-Greater, 这代表了什么呢？代表了这两类有共通之处，即它们的上下文都会被清除，重新初始化。 Paragraph 是最小的语法单元。 定义 Element 的子语法结构和 Paragraph 同级,即不能包含 Paragraph 或者被包含在 Paragraph 中。 一个 Object 可以作为一部分被一个 Element 所包含。 Greater element 的任意部分都可以是一个 Element 。 空行属于在它们之前结束的最大 Element 。例如，在列表中，之间的空行属于它们之前的那一项，但列表末尾的空行属于当前列表 Element 。 除非特别说明，大小写默认不敏感。 1 Headlines and Sections Headline 定义如下: STARS KEYWORD PRIORITY TITLE TAGS STARS 是一个从第0列开始的字符串，至少包含一个星号（如果加载了 org-inlinetask 库，则上限为 org-inlinetask-min-level ），并以空格字符结尾。 星号的个数代表标题的等级。它是标题中唯一必须的部分。 KEYWORD 是一个TODO关键字，它必须被定义在 org-todo-keywords-1 的列表。 大小写敏感。 PRIORITY 是一个优先级标示(priority cookie)。示例: [#A] 。 TITLE 可以由换行符以外的任意字符组成。 标题下的内容匹配了搜索条件，代表此标题匹配。 TAGS 由 : 分隔的多个单词组成, 单词可由任何字母数字字符， _ ， @ ， # 或 % 组成。 有效标题的示例,如下： * ** DONE *** Some e-mail **** TODO [#A] COMMENT Title :tag:a2%: 若标题中的第一个单词是 org-comment-string ，当前标题将被作为 "commented" 。 大小写敏感。 若标题中的第一个单词是 org-quote-string ，当前标题将被作为 "quoted" 。 大小写敏感。 若其标题是 org-footnote-section 将被作为 /"footnote section"/。 大小写敏感。 若 org-archive-tag 是它的标签之一，它被作为 "archived" 。 大小写敏感。 标题可直接包含一个段落（可选），再跟任意数量的更深级别的标题(递归定义)。 一个段落可直接包含任意 Greater elelment 或 Element 。 只有标题可以包含段落。 文档中的第一个标题之前的文本除外，因为它属于一个段落。 作为示例，请考虑以下文档： An introduction.&#10;&#10;* A Headline &#10;&#10; Some text.&#10;&#10;** Sub-Topic 1&#10;&#10;** Sub-Topic 2&#10;&#10;*** Additional entry &#10;&#10;** QUOTE Another Sub-Topic&#10;&#10; Some other text. 其内部结构可概括为: (document (section) (headline (section) (headline) (headline (headline)) (headline (quote-section)))) 2 Affiliated Keywords 除了inlinetasks, items, planning, clocks, node properties 和 table rows 之外，其他的任意的 Element 类型都可为其指定属性。 在选定的 Element 之前添加命名为 Affiliated keywords 的特定关键字,可指定属性的(在 Element 之前插入"affiliated keywords"，不允许两者之前存在空行)。 Affiliated keywords 是建立在以下模式之上的： "#+KEY: VALUE", "#+KEY[OPTIONAL]: VALUE" 或者 "#+ATTR_BACKEND: VALUE" 。 KEY 可以是 "CAPTION", "HEADER", "NAME", "PLOT" 或 "RESULTS" 中的任意一个. BACKEND 是一个由字母,数字，连字符或下划线组合而成的字符串。 OPTIONAL 和 VALUE 可以包含除换行符以外的任意字符。 只有"CAPTION"和"RESULTS"可以有可选值。 如果 KEY 为"CAPTION"或"HEADER"，或者其模式为"＃+ATTR_BACKEND：VALUE"，则 Affiliated keywords 可以多次出现。 "CAPTION"，"AUTHOR"，"DATE"和"TITLE"可以包含 Object 及其可选值（如果适用）。 3 Greater Elements 除非特别说明， Greater elements 可以直接包含任何其他 Element 或 除了下面之外的 Greater element ： 同样类型的 Element node properties, 只存在于property drawers 中, items, 只存在于plain lists 中。 3.1 Greater Blocks Greater blocks 由以下模式组成: #+BEGIN_NAME PARAMETERS CONTENTS #+END_NAME NAME 可以由任意非空白字符组成。 PARAMETERS 可以包含除换行符以外的任意字符，可以省略。 如果 NAME 是 CENTER ，表示当前 Greater block 是一个"center block"。 如果是 QUOTE ，表示是一个"quote block"。 如果 Block 既不是 center block ， quote block 或 block element，则是 special block 。 CONTENTS 可以包含任何 Element ，除了： Block 自己的结束行 ＃+END_NAME 。 此外，以星号开头的行必须用逗号引号。 3.2 Drawers and Property Drawers Drawer 的模式如下: :NAME: CONTENTS :END: NAME 可以包含词组字符(word-constituent characters)，连字符和下划线。 NAME 必须是"PROPERTIES"或属于 org-drawers 所定义列表。 如果 NAME 是 PROPERTIES ，则 Drawer 即为 property drawer 。 CONTENTS可以包含任何 Element ，除了 Drawer 。 在 Property drawer 中，*CONTENTS* 只能包含节点 node property Element 。其他类型 Drawer ，它可以包含任何 Element ，除了另一个 Drawer 或 Property drawer 。 It would be nice if users hadn't to register drawers names before using them in org-drawers (or through the #+DRAWERS: keyword). Anything starting with ^[ \t]*:\w+:[ \t]$ and ending with ^[ \t]*:END:[ \t]$ could be considered as a drawer. &#x2014; ngz 3.3 Dynamic Blocks Dynamic blocks 的模式是： #+BEGIN: NAME PARAMETERS CONTENTS #+END: NAME 不能包含任何空格字符。 PARAMETERS 可以包含任何字符，可以省略。 3.4 Footnote Definitions Footnote definition 的模式是： [LABEL] CONTENTS 它必须从列0开始。 LABEL 是一个数字或遵循 fn:WORD 的模式，其中word可以包含任何字组字符(word-constituent character)，连字符和下划线字符。 CONTENTS 可以包含除另一个 Footnote definition 定义之外的任何元素。 它在下一个脚注定义结束，下一个标题，两个连续的空行或缓冲区的结尾。 3.5 Inlinetasks Inlinetasks 定义为从第0列开始的 org-inlinetask-min-level 个连续星号字符,后跟空格字符。 可选地，可以使用由从第0列开始的 org-inlinetask-min-level 个连续星号字符构成的字符串来结束 Inlinetasks ，后面跟着空格和"END"字符串。 只有在加载了 org-inlinetask 库之后才能识别 Inlinetasks 。 3.6 Plain Lists and Items Item 通过从以下模式开始的行来定义： BULLET COUNTER-SET CHECK-BOX TAG 其中只有BULLET是必须的。 BULLET 是星号，连字符，加号(用于 unstored list)或者遵循模式 COUNTER. 或者 COUNTER) (用于 stored list)。 在任何情况下，BULLET后跟空格字符或换行符。 COUNTER 可以是数字或单个字母。 COUNTER-SET 遵循模式[@COUNTER]。 CHECK-BOX 是单个空格字符， X 字符或连字符，括在方括号中。 TAG 遵循 "TAG-TEXT ::"模式，其中TAG-TEXT可以包含除换行符以外的任意字符。 Item 在下一个 Item 之前结束条件: 小于或等于其起始行缩进的首行，或两个连续的空行。 其他 Greater elements 内的线的缩进不算，内联边界也不计。 Plain list 是一组具有相同缩进的连续 Item 。 它只能直接包含 Item 。 如果 Plain list 中的第一个 Item 在其 bullet 中有一个 counter ，那么 Plain list 将是一个 ordered plain-list 。 如果它包含一个 tag ，它将是一个 descriptive list 。 否则，它将是一个 unordered list 。 List 类型是互斥的。 示例，思考如下的Org文档片段： 1. item 1 2. [X] item 2 - some tag :: item 2.1 它的内部结构如下所示: (ordered-plain-list (item) (item (descriptive-plain-list (item)))) 3.7 Property Drawers Property Drawer 是一种特殊类型的 Drawer ，包含附加到标题的属性。 它们位于headline 和其planning信息之后。 HEADLINE PROPERTYDRAWER HEADLINE PLANNING PROPERTYDRAWER PROPERTYDRAWER 遵循下面的模式 :PROPERTIES: CONTENTS :END: 其中 CONTENTS 由零个或多个node properties组成。 3.8 Tables Tables 从以竖线或"+-"字符串开始的行开始，后面跟着加号或减号，假定它们前面没有相同类型的行。 这些线可以缩进。 以垂直条开始的表具有 org 类型。 否则它具有 table.el 类型。 Org Tables 结束于以竖线开始的行。 Table.el Tables 结束于不以垂直线或加号开始的行。 这样的线可以是锯齿状的。 Org Tables 只能包含 table rows 。 table.el Tables 不包含任何内容。 一个或多个"＃+TBLFM：FORMULAS"行，其中 FORMULAS 可以包含任何字符，可以在 Org Tables 之后。 4 Elements Element 不能包含任何其他元素。 只有keywords名称属于 org-element-document-properties, verse blocks , paragraphs 和 table rows 可以包含 Object 。 4.1 Babel Call Babel calls 的模式如下: #+CALL: VALUE VALUE 是可选的。 它可以包含除换行符以外的任意字符。 4.2 Blocks 像 Greater blocks 一样， Block 模式如下： #+BEGIN_NAME DATA CONTENTS #+END_NAME NAME 不能包含任何空格字符。 如果 NAME 是 COMMENT ，它将是一个"comment block"。如果它是 EXAMPLE ，它将是一个"example block"。 如果它是 EXPORT ，它将是一个"export block"。如果它是 SRC ，它将是一个"source block"。如果是 VERSE ，它将是一个"verse block"。 如果 NAME 是与加载的任何 export back-end 的名称相匹配，则块将是"export block"。 DATA 可以包含除换行符以外的任意字符。它可以省略，除非 Block 是"source block"或"export block"。 在后一种情况(export block)下，它应该由一个单词组成。 在前一种情况(source block)下，它必须遵循"LANGUAGE SWITCHES ARGUMENTS"的模式，其中 SWITCHES 和 ARGUMENTS 是可选的。 LANGUAGE 不能包含任何空格字符。 SWITCHES 由任意数量的"SWITCH"模式组成，由空行分隔。 SWITCH 模式是 "-l" FORMAT ""，其中 FORMAT 可以包含除双引号和换行符之外的任意字符, "-S"或"+ S"，其中S表示单个字母。 ARGUMENTS 可以包含除换行符以外的任意字符。 CONTENTS 可以包含任意字符, 包括换行符。 Verse block 只能包含 Org Block ，不然的话 CONTENTS 将不能被解析。 4.3 Clock, Diary Sexp and Planning Clock 模式如下: CLOCK: TIMESTAMP DURATION TIMESTAMP 和 DURATION 都是可选的。 TIMESTAMP 是一个 timestamp object 。 DURATION 遵循模式如下: =&gt; HH:MM HH是一个包含任意位数的数字。 MM是两位数字。 Diary sexp 是以第"%%（"从0列起始一行，它可以包含除了换行符之外的任意字符。 planning 遵循下面模式的 Element ： HEADLINE PLANNING 其中 HEADLINE 是标题 Element ，PLANNING是填充有INFO部分的行，其中每个都遵循以下模式： KEYWORD: TIMESTAMP KEYWORD是 org-deadline-string ， org-scheduled-string 和 org-closed-string 中的一个字符串。 TIMESTAMP是一个timestamp Object 。 特别要强调的一点，就是在PLANNING和HEADLINE之间不允许有空行。 即使 Planning element 可以存在于一个 Section 中的任何地方或者一个 Greater element 中，但是它只影响标题包含的 Section ，前提是它位在该标题之后。 4.4 Comments A "comment line" starts with a hash signe and a whitespace character or an end of line. Comments can contain any number of consecutive comment lines. 4.5 Fixed Width Areas A "fixed-width line" start with a colon character and a whitespace or an end of line. Fixed width areas can contain any number of consecutive fixed-width lines. 4.6 Horizontal Rules A horizontal rule is a line made of at least 5 consecutive hyphens. It can be indented. 4.7 Keywords Keywords 语法如下: #+KEY: VALUE KEY 可以包含任何非空字符，但不能等于"CALL"或任何 Affiliated keyword 。 VALUE 可以包含除了换行符之外的任何字符。 如果 KEY 属于 org-element-document-properties ，则 VALUE 可以包含 Object 。 4.8 LaTeX Environments LaTeX environment 的模式如下: \begin{NAME}ARGUMENTS CONTENTS \end{NAME} NAME 由字母数字或星号字符组成。 CONTENTS 可以包含除"\ end {NAME}"字符串之外的任何内容。 NAME is constituted of alpha-numeric characters and may end with an asterisk. ARGUMENTS is is any number (including zero) of ARGUMENT constructs like [DATA] or {DATA} . DATA can contain any character excepted a new line or the one ending ARGUMENT. CONTENTS can contain anything but the "\end{NAME}" string. 4.9 Node Properties Node propertie 只能存在于property drawers中。 它可以是下面模式的任意一个: :NAME: VALUE :NAME+: VALUE :NAME: :NAME+: NAME* 可以包含任何非空字符，但不能以加号结尾。 不能是空字符串。 VALUE 可以包含除换行符之外的任何内容。 4.10 Paragraphs Paragraphs 是默认 Element ，这意味着任何无法识别的上下文(unrecognized context)都是段落。 空行和其他 Element 结束 Paragraphs 。 Paragraphs 可以包含任意类型的 Object 。 4.11 Table Rows Table Row 由 vertical bar 和任意数量的table cells组成，或者由连字符后面跟 vertical ba 组成。 在第一种情况下， Tables Row 具有 standard 类型。 在第二种情况下，它具有 rule 类型。 Tables Row 只能存在于tables中。 A table rows is either constituted of a vertical bar and any number of table cells or a vertical bar followed by a hyphen. In the first case the table row has the "standard" type. In the second case, it has the "rule" type. Table rows can only exist in tables. 5 Objects 只能在以下位置找到 Object: org-element-parsed-keywords 中定义的 affiliated keywords, document properties, headline titles, inlinetask titles, item tags, paragraphs, table cells, table rows, 它只能包含 table cell objects , verse blocks. 大多数 Object 不能包含 Object 。 那些可以包含的会做特别说明的。 5.1 Entities and LaTeX Fragments Entities 遵循的模式如下： \NAME POST 其中 NAME 和 org-entities 或 org-entities-user 之间具有有效关联。 POST 是行尾，"{}""字符串或非字母字符。 它不是由空格符与NAME分隔。 where NAME has a valid association in either org-entities or org-entities-user. LaTeX Fragments 可以遵循多种模式: \NAME BRACKETS \(CONTENTS\) \[CONTENTS\] $$CONTENTS$$ PRE$CHAR$POST PRE$BORDER1 BODY BORDER2$POST NAME 仅包含字母字符，且不能和 org-entities 或 org-entities-user 具有关联。 BRACKETS 是可选的，不与 NAME 用空格分隔。 它可以包含任意数量的以下模式： [CONTENTS1] {CONTENTS2} 其中CONTENTS1可以包含除"{""}"，"[""]"以及换行符和CONTENTS2之外的任何字符可以包含除"{"，"}"和换行符之外的任何字符。 CONTENTS can contain any character but cannot contain "\)" in the second template or "\]" in the third one. PRE is either the beginning of line or a character different from $. CHAR is a non-whitespace character different from ., ,, ?, ;, ' or a double quote. POST is any of -, ., ,, ?, ;, :, ', a double quote, a whitespace character and the end of line. BORDER1 is a non-whitespace character different from ., ;, . and $. BODY can contain any character excepted $, and may not span over more than 3 lines. BORDER2 is any non-whitespace character different from ,, . and $. It would introduce incompatibilities with previous Org versions, but support for $...$ (and for symmetry, $$...$$) constructs ought to be removed. They are slow to parse, fragile, redundant and imply false positives. &#x2014; ngz 5.2 Export Snippets Export snippets 模式如下: @@NAME:VALUE@@ NAME 可以包含任何字母数字字符和连字符。 VALUE 可以包含除"@@"字符串之外的任何内容。 5.3 Footnote References Footnote References 有四种模式: [MARK] [fn:LABEL] [fn:LABEL:DEFINITION] [fn::DEFINITION] MARK 是一个数字。 LABEL 可以包含任何字组成字符，连字符和下划线。 DEFINITION 可以包含任何字符。 开关方括号必须成对出现。 它可以包含任何出现在 Paragraph 中的 Object ，甚至其他 Footnote Reference 。 如果引用遵循第三模式，则其被称为 inline footnote ，如果它跟随第四个，即如果省略 LABEL ，它是一个 anonymous footnote 。 5.4 Inline Babel Calls and Source Blocks Inline Babel call 遵循以下任何模式: call_NAME(ARGUMENTS) call_NAME[HEADER](ARGUMENTS)[HEADER] NAME can contain any character besides (, ) and "\n". HEADER can contain any character besides ] and "\n". ARGUMENTS can contain any character besides ) and "\n". Inline source blocks 遵循以下任何模式: src_LANG{BODY} src_LANG[OPTIONS]{BODY} LANG can contain any non-whitespace character. OPTIONS and BODY can contain any character but "\n". 5.5 Line Breaks A line break consists in "\\SPACE" pattern at the end of an otherwise non-empty line. SPACE can contain any number of tabs and spaces, including 0. 5.6 Links 有4种主要类型的 Link: PRE1 RADIO POST1 ("radio" link) &lt;PROTOCOL:PATH&gt; ("angle" link) PRE2 PROTOCOL:PATH2 POST2 ("plain" link) [[PATH3]DESCRIPTION] ("regular" link) PRE1 和 POST1 （如果存在）是非字母数字字符。 RADIO 是被某些radio target 匹配的字符串。 它可以只包含 entities, latex fragments, subscript 和 superscript。 PROTOCOL 属于 org-link-types 中定义的链接协议类型。 PATH 可以包含除了 ], &lt;, &gt; 和 \n 以外的任何字符。 PRE2 和 POST2 ，当它们存在时，是非字构成字符(word constituent characters)。 PATH2 可以包含除了 (, ), &lt; 和 &gt; 之外的任何非空字符。 它必须以字组成字符结尾，或任何非空格 非标点符号后面跟着 / 。 DESCRIPTION 必须括在方括号中。 它可以包含除了方括号以外的任何字符。 它可以包含除了 footnote reference, radio target 和 line break之外的任何可在 paragraph 中找到的 object 。 它不能包含另一个 link ，除非它是 plain 或者 angular link 。 DESCRIPTION 是可选的。 PATH3 根据以下模式构建: FILENAME ("file" type) PROTOCOL:PATH4 ("PROTOCOL" type) PROTOCOL://PATH4 ("PROTOCOL" type) id:ID ("id" type) #CUSTOM-ID ("custom-id" type) (CODEREF) ("coderef" type) FUZZY ("fuzzy" type) FILENAME 是一个文件名，绝对路径或相对路径。 PATH4 可以包含除方括号外的任何字符。 ID 由用连字符分隔的十六进制数字构成。 PATH4 ，*CUSTOM-ID* ，*CODEREF* 和 FUZZY 可以包含除方括号外的任何字符。 I suggest to remove angle links. If one needs spaces in PATH, she can use standard link syntax instead. I also suggest to remove org-link-types dependency in PROTOCOL and match [a-zA-Z] instead, for portability. &#x2014; ngz 5.7 Macros Macros 遵循如下模式: {{{NAME(ARGUMENTS)}}} NAME 必须以字母开头，后面可以跟随任意数量的字母数字字符，连字符和下划线。 ARGUMENTS 可以包含除"}}}" 字符串之外的任何内容。 ARGUMENTS 中的值用逗号分隔。 非分隔逗号必须用反斜杠字符转义。 5.8 Targets and Radio Targets Radio targets 的模式如下: &lt;&lt;&lt;CONTENTS&gt;&gt;&gt; CONTENTS 可以是除了 &lt;, &gt; 和 \n 之外的任何字符。 它不能以空格字符开始或结束。 作为 objects 而言，它只可以包含 entities, latex fragments, subscript 和 superscript。 Targets 的模式如下: &lt;&lt;TARGET&gt;&gt; TARGET 可以是除了 &lt;, &gt; 和 \n 之外的任何字符。 不能包含任何 Objects . 5.9 Statistics Cookies Statistics cookies 遵循任一模式: [PERCENT%] [NUM1/NUM2] PERCENT ，*NUM1* 和 NUM2 是数字或空字符串。 5.10 Subscript and Superscript Subscript 的模式是: CHAR_SCRIPT Superscript 的模式是: CHAR^SCRIPT CHAR 是任何非空格字符。 SCRIPT 可以是 * 或括在括号（respectively curly brackets）中的表达式，可能包含平衡括号（respectively curly brackets）。 SCRIPT循该如下模式: SIGN CHARS FINAL SIGN 是加号，减号或空字符串。 CHARS 是任意数量的字母数字字符，逗号，反斜杠和点，或空字符串。 FINAL 是一个字母数字字符。 SIGN ，*CHARS* 和 FINAL 之间没有空格。 5.11 Table Cells Table cells 遵循如下模式: CONTENTS SPACES| CONTENTS可以包含除垂直条之外的任何字符。 SPACES包含任意数量的空格字符，包括零。 它可用于正确对齐表格。 最后一个条可以用行中最后一个单元格的换行符替换。 5.12 Timestamps Timestamp 有七种可能的模式: &lt;%%(SEXP)&gt; (diary) &lt;DATE TIME REPEATER-OR-DELAY&gt; (active) [DATE TIME REPEATER-OR-DELAY] (inactive) &lt;DATE TIME REPEATER-OR-DELAY&gt;--&lt;DATE TIME REPEATER-OR-DELAY&gt; (active range) &lt;DATE TIME-TIME REPEATER-OR-DELAY&gt; (active range) [DATE TIME REPEATER-OR-DELAY]--[DATE TIME REPEATER-OR-DELAY] (inactive range) [DATE TIME-TIME REPEATER-OR-DELAY] (inactive range) SEXP 可以包含除了 &gt; 和 \n 之外任何字符。 DATE 模式如下: YYYY-MM-DD DAYNAME Y ，*M* 和 D 是数字。 DAYNAME可以包含除 +, -, ], &gt;, 数字 和 \n 之外的任何非空白字符。 TIME 遵循模式= H：MM〜。 H可以是一个或两个数字长，可以从0开始。 REPEATER 模式如下: MARK VALUE UNIT MARK 对于 repeater 而言，是 + (cumulate type), ++ (catch-up type) 或者 .+ (restart type) 。 在 warning delays 的请求， MARK 可以是 - (all type) 或者 -- (first type)。 VALUE 是一个数字。 UNIT 是h（小时），d（日），w（周），m（月），y（年）中的字符。 MARK ，*VALUE* 和 UNIT 不以空格字符分隔。 时间戳中可以有两个REPEATER-OR-DELAY：一个作为 repeater ，一个作为 warning delays 。 5.13 Text Markup Text markup 模式如下: PRE MARKER CONTENTS MARKER POST PRE 是一个空格字符, (, { ' 或一个双引号，它也可以是一行的开头。 MARKER 是 * (bold), = (verbatim), / (italic), + (strike-through), _ (underline), ~ (code) 中的符号。 CONTENTS 是模式如下的字符串: BORDER BODY BORDER BORDER 可以是除了 ,, ' 和双引号之外的任何非空格字符。 BODY 可以包含任何字符，但不能跨越超过3行。 BORDER 和 BODY 不被空格分隔。 当标记为 "bold", "italic", "strike-through" 或者 "underline"时， CONTENTS 可以包含段落中遇到的任何对象。 POST是一个空格字符， -, ., ,, :, !, ?, ', ), } 或双引号。 它也可以是行尾。 PRE ， MARKER ， CONTENTS ，*MARKER* 和 POST 不以空格字符分隔。 All of this is wrong if org-emphasis-regexp-components or org-emphasis-alist are modified. This should really be simplified and made persistent (i.e. no defcustom allowed). Otherwise, portability and parsing are jokes. Also, CONTENTS should be anything within code and verbatim emphasis, by definition. &#x2014; ngz &#33050;&#27880;: 1 Org Syntax (draft) 的org源码: http://orgmode.org/worg/sources/dev/org-syntax.org 因此，使用 org-element-at-point 或 org-element-context 将向上移动到父标题，并从那里自顶向下解析，直到找到原始位置周围的上下文。 2 特别说明，解析器要求在列0处的星号在不被定义为标题时用逗号来引用。 3 这也意味着只有 Headline 和 Section 能通过查看行的开头来识别。 Planning lines 和 Property drawers 可以通过查看一行或两行以上来识别。 Last Updated 2017-05-23 Tue 13:28.Render by hexo-renderer-org with Emacs 24.5.1 (Org mode 9.0.6)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>%2F2017%2F03%2F07%2Fhello-world%2F</url>
      <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
    </entry>

    
  
  
</search>
